{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set = pd.read_csv('./train_set_onehot.csv')\n",
    "# test_set = pd.read_csv('./test_set.csv')\n",
    "# test_set = test_set.rename(columns={'due_amt':'due_amt_scale'})\n",
    "\n",
    "# train_set['due_amt_scale'] = train_set['due_amt']\n",
    "# scale_cols = ['due_amt_scale', 'auditing_date_month', 'auditing_date_days',\n",
    "#                'auditing_date_dayofweek', 'due_date_month', 'due_date_dayofweek',\n",
    "#                 'rate', 'principal', 'pvi','audit_reg_delta','tag_num', 'behavior_time_month', \n",
    "#                   'behavior_time_days','behavior_time_dayofweek', 'same_behavior_count1d', 'audit_beh_delta']\n",
    "\n",
    "# # minmaxscaler = MinMaxScaler()\n",
    "# # minmaxscaler.fit(train_set[scale_cols])\n",
    "# # train_set[scale_cols] = minmaxscaler.tranform(train_set[scale_cols])\n",
    "# for col in scale_cols:\n",
    "#     desc = train_set[col].describe()\n",
    "#     train_set[col] = (train_set[col]-desc['mean'])/desc['std']\n",
    "# #     try:\n",
    "#     test_set[col] = (test_set[col]-desc['mean'])/desc['std']\n",
    "# #     except:\n",
    "# #         pass\n",
    "# train_set.columns\n",
    "\n",
    "# # train_set = train_set[['repay_amt','due_amt','due_amt_scale']+list(scale_cols.drop(['due_amt_scale']))]\n",
    "# train_set.to_csv('./train_set_onehot_scaler.csv',index=False)\n",
    "# test_set.to_csv('./test_set_onehot_scaler.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.05\n",
    "global_step = tf.Variable(0,trainable=False)\n",
    "decaylearning_rate = tf.train.exponential_decay(learning_rate,global_step,1000,0.8)\n",
    "\n",
    "n_input = 74\n",
    "n_classes = 33\n",
    "\n",
    "n_hidden_1 = 128\n",
    "n_hidden_2 = 256\n",
    "n_hidden_3 = 128\n",
    "\n",
    "x = tf.placeholder(tf.float32,[None,n_input],name='x')\n",
    "y = tf.placeholder(tf.float32,[None,n_classes],name='y')\n",
    "y_ = tf.placeholder(tf.float32,[None,n_classes],name='y_')\n",
    "\n",
    "repay_amt=tf.placeholder(tf.float32,[None,],name='repay_amt')\n",
    "due_amt=tf.placeholder(tf.float32,[None,],name='due_amt')\n",
    "\n",
    "drop_rate_1 = 0.1\n",
    "drop_rate_2 = 0.2\n",
    "drop_rate_3 = 0.1\n",
    "\n",
    "l2_decay=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.Variable(tf.truncated_normal([n_input,n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.truncated_normal([n_hidden_1,n_hidden_2])),\n",
    "    'h3': tf.Variable(tf.truncated_normal([n_hidden_2,n_hidden_3])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden_3,n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1':tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2':tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b3':tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    'out':tf.Variable(tf.truncated_normal([n_classes]))\n",
    "}\n",
    "\n",
    "def multilayer_perceptron(x,weights,biases):\n",
    "    layer_1 = tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "    layer_1 = tf.nn.leaky_relu(layer_1)\n",
    "    layer_1_drop = tf.nn.dropout(layer_1,rate=drop_rate_1)\n",
    "    \n",
    "    layer_2 = tf.add(tf.matmul(layer_1,weights['h2']),biases['b2'])\n",
    "    layer_2 = tf.nn.leaky_relu(layer_2)\n",
    "    layer_2_drop = tf.nn.dropout(layer_2,rate=drop_rate_2)\n",
    "    \n",
    "    layer_3 = tf.add(tf.matmul(layer_2,weights['h3']),biases['b3'])\n",
    "    layer_3 = tf.nn.leaky_relu(layer_3)\n",
    "    layer_3_drop = tf.nn.dropout(layer_3,rate=drop_rate_3)\n",
    "    \n",
    "    out_layer = tf.add(tf.matmul(layer_3,weights['out']),biases['out'],name='output')\n",
    "    \n",
    "    return out_layer\n",
    "\n",
    "pred = multilayer_perceptron(x,weights,biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred,labels=y))\n",
    "\n",
    "y_pred = tf.nn.softmax(logits=pred)\n",
    "y_pred = tf.clip_by_value(y_pred, 1e-10, 1.0 - 1e-10)\n",
    "cost = tf.reduce_mean(-y * ((1 - y_pred) ** 2.0) * tf.log(y_pred))\n",
    "\n",
    "l2_regular=l2_decay*tf.add_n([tf.nn.l2_loss(var) for var in tf.trainable_variables()])\n",
    "rmse=tf.sqrt(tf.reduce_mean(tf.pow(tf.reduce_sum(tf.nn.softmax(pred)*y_,-1)*due_amt-repay_amt,2)))\n",
    "total_loss=cost+l2_regular\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(decaylearning_rate).minimize(total_loss,global_step=global_step)\n",
    "\n",
    "tf.summary.scalar('cost',cost)\n",
    "tf.summary.scalar('l2_regular',l2_regular)\n",
    "tf.summary.scalar('rmse',rmse)\n",
    "tf.summary.scalar('total_loss',total_loss)\n",
    "summary=tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 25\n",
    "batch_size = 1000\n",
    "file='./train_set_onehot.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver=tf.train.Saver(max_to_keep=1)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0][step 100] logloss:0.586810 l2_regular:0.015767 rmse:396.786774 total_loss:0.602577 acc:0.159000\n",
      "[epoch 0][step 200] logloss:0.669843 l2_regular:0.001650 rmse:482.090576 total_loss:0.671492 acc:0.040000\n",
      "[epoch 0][step 300] logloss:0.631467 l2_regular:0.002816 rmse:598.264526 total_loss:0.634283 acc:0.095000\n",
      "[epoch 0][step 400] logloss:0.500289 l2_regular:0.001050 rmse:345.478760 total_loss:0.501339 acc:0.283000\n",
      "[epoch 0][step 500] logloss:0.568669 l2_regular:0.000807 rmse:381.914948 total_loss:0.569476 acc:0.185000\n",
      "[epoch 0][step 600] logloss:0.697753 l2_regular:0.283959 rmse:407.686584 total_loss:0.981712 acc:0.000000\n",
      "[epoch 0][step 700] logloss:0.694962 l2_regular:0.066983 rmse:510.595306 total_loss:0.761945 acc:0.004000\n",
      "[epoch 0][step 800] logloss:0.666354 l2_regular:0.034607 rmse:626.535400 total_loss:0.700961 acc:0.045000\n",
      "[epoch 0][step 900] logloss:0.697753 l2_regular:0.021919 rmse:585.164124 total_loss:0.719672 acc:0.000000\n",
      "[epoch 0][step 1000] logloss:0.692869 l2_regular:0.015273 rmse:464.747375 total_loss:0.708142 acc:0.007000\n",
      "[epoch 0][step 1100] logloss:0.683100 l2_regular:0.011300 rmse:632.086243 total_loss:0.694401 acc:0.021000\n",
      "[epoch 0][step 1200] logloss:0.697753 l2_regular:0.008724 rmse:734.504578 total_loss:0.706477 acc:0.000000\n",
      "[epoch 0][step 1300] logloss:0.663563 l2_regular:0.006951 rmse:502.260803 total_loss:0.670514 acc:0.049000\n",
      "[epoch 0][step 1400] logloss:0.682402 l2_regular:0.005672 rmse:646.473755 total_loss:0.688075 acc:0.022000\n",
      "[epoch 0][step 1500] logloss:0.697753 l2_regular:0.004714 rmse:663.593323 total_loss:0.702467 acc:0.000000\n",
      "[epoch 0][step 1600] logloss:0.697753 l2_regular:0.003974 rmse:583.957825 total_loss:0.701727 acc:0.000000\n",
      "[epoch 0][step 1700] logloss:0.688682 l2_regular:0.003388 rmse:463.005066 total_loss:0.692070 acc:0.013000\n",
      "[epoch 0][step 1800] logloss:0.697753 l2_regular:0.002915 rmse:467.951813 total_loss:0.700668 acc:0.000000\n",
      "[epoch 0][step 1900] logloss:0.671238 l2_regular:0.002526 rmse:475.633728 total_loss:0.673764 acc:0.038000\n",
      "[epoch 0][step 2000] logloss:0.660074 l2_regular:0.002203 rmse:574.614258 total_loss:0.662277 acc:0.054000\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "[epoch 0][step 2100] logloss:0.648213 l2_regular:0.001931 rmse:838.281921 total_loss:0.650144 acc:0.071000\n",
      "[epoch 0][step 2200] logloss:0.685891 l2_regular:0.001702 rmse:637.668518 total_loss:0.687593 acc:0.017000\n",
      "[epoch 0][step 2300] logloss:0.694962 l2_regular:0.001506 rmse:472.441956 total_loss:0.696468 acc:0.004000\n",
      "[epoch 0][step 2400] logloss:0.683100 l2_regular:0.001337 rmse:546.820862 total_loss:0.684438 acc:0.021000\n",
      "[epoch 0][step 2500] logloss:0.696358 l2_regular:0.001192 rmse:552.351624 total_loss:0.697550 acc:0.002000\n",
      "[epoch 0][step 2600] logloss:0.667052 l2_regular:0.001066 rmse:537.759949 total_loss:0.668118 acc:0.044000\n",
      "[epoch 0][step 2700] logloss:0.697753 l2_regular:0.000957 rmse:476.067230 total_loss:0.698710 acc:0.000000\n",
      "[epoch 0][step 2800] logloss:0.658679 l2_regular:0.005166 rmse:562.534546 total_loss:0.663845 acc:0.056000\n",
      "[epoch 0][step 2900] logloss:0.697753 l2_regular:0.032554 rmse:577.828674 total_loss:0.730307 acc:0.000000\n",
      "[epoch 0][step 3000] logloss:0.627280 l2_regular:0.022395 rmse:553.202759 total_loss:0.649675 acc:0.101000\n",
      "[epoch 0][step 3100] logloss:0.690776 l2_regular:0.017218 rmse:697.918945 total_loss:0.707994 acc:0.010000\n",
      "[epoch 0][step 3200] logloss:0.687287 l2_regular:0.013917 rmse:789.208801 total_loss:0.701203 acc:0.015000\n",
      "[epoch 0][step 3300] logloss:0.683798 l2_regular:0.011600 rmse:679.255066 total_loss:0.695398 acc:0.020000\n",
      "[epoch 0][step 3400] logloss:0.694962 l2_regular:0.009876 rmse:615.784058 total_loss:0.704838 acc:0.004000\n",
      "[epoch 0][step 3500] logloss:0.695660 l2_regular:0.008542 rmse:540.280640 total_loss:0.704202 acc:0.003000\n",
      "[epoch 0][step 3600] logloss:0.676820 l2_regular:0.007478 rmse:522.546021 total_loss:0.684299 acc:0.030000\n",
      "[epoch 0][step 3700] logloss:0.671936 l2_regular:0.006610 rmse:449.076813 total_loss:0.678546 acc:0.037000\n",
      "[epoch 0][step 3800] logloss:0.671238 l2_regular:0.005889 rmse:504.181366 total_loss:0.677127 acc:0.038000\n",
      "[epoch 0][step 3900] logloss:0.689380 l2_regular:0.005280 rmse:496.094208 total_loss:0.694660 acc:0.012000\n",
      "[epoch 0][step 4000] logloss:0.697753 l2_regular:0.004759 rmse:409.381226 total_loss:0.702512 acc:0.000000\n",
      "[epoch 0][step 4100] logloss:0.696358 l2_regular:0.004308 rmse:520.714722 total_loss:0.700665 acc:0.002000\n",
      "[epoch 0][step 4200] logloss:0.693567 l2_regular:0.003913 rmse:516.991028 total_loss:0.697480 acc:0.006000\n",
      "[epoch 0][step 4300] logloss:0.696358 l2_regular:0.003565 rmse:531.580872 total_loss:0.699923 acc:0.002000\n",
      "[epoch 0][step 4400] logloss:0.694264 l2_regular:0.003256 rmse:708.978027 total_loss:0.697520 acc:0.005000\n",
      "[epoch 0][step 4500] logloss:0.690776 l2_regular:0.002979 rmse:550.098816 total_loss:0.693754 acc:0.010000\n",
      "[epoch 0][step 4600] logloss:0.697753 l2_regular:0.002729 rmse:693.484436 total_loss:0.700482 acc:0.000000\n",
      "[epoch 0][step 4700] logloss:0.676123 l2_regular:0.002503 rmse:615.382202 total_loss:0.678626 acc:0.031000\n",
      "[epoch 0][step 4800] logloss:0.697055 l2_regular:0.002297 rmse:641.268372 total_loss:0.699352 acc:0.001000\n",
      "[epoch 0][step 4900] logloss:0.692171 l2_regular:0.002109 rmse:454.720978 total_loss:0.694280 acc:0.008000\n",
      "[epoch 0][step 5000] logloss:0.691473 l2_regular:0.001937 rmse:612.083923 total_loss:0.693410 acc:0.009000\n",
      "[epoch 0][step 5100] logloss:0.697753 l2_regular:0.001779 rmse:529.277405 total_loss:0.699532 acc:0.000000\n",
      "[epoch 0][step 5200] logloss:0.653795 l2_regular:0.001633 rmse:413.448059 total_loss:0.655428 acc:0.063000\n",
      "[epoch 0][step 5300] logloss:0.674727 l2_regular:0.001499 rmse:517.199890 total_loss:0.676226 acc:0.033000\n",
      "[epoch 0][step 5400] logloss:0.675425 l2_regular:0.001376 rmse:603.690613 total_loss:0.676801 acc:0.032000\n",
      "[epoch 0][step 5500] logloss:0.697753 l2_regular:0.001261 rmse:494.380371 total_loss:0.699014 acc:0.000000\n",
      "[epoch 0][step 5600] logloss:0.696358 l2_regular:0.001156 rmse:612.943970 total_loss:0.697513 acc:0.002000\n",
      "[epoch 0][step 5700] logloss:0.697753 l2_regular:0.001058 rmse:480.092377 total_loss:0.698811 acc:0.000000\n",
      "[epoch 0][step 5800] logloss:0.678216 l2_regular:0.000968 rmse:635.123169 total_loss:0.679184 acc:0.028000\n",
      "[epoch 0][step 5900] logloss:0.694962 l2_regular:0.000885 rmse:493.536926 total_loss:0.695847 acc:0.004000\n",
      "[epoch 0][step 6000] logloss:0.697753 l2_regular:0.000808 rmse:494.815704 total_loss:0.698561 acc:0.000000\n",
      "[epoch 0][step 6100] logloss:0.694264 l2_regular:0.000737 rmse:454.970520 total_loss:0.695001 acc:0.005000\n",
      "[epoch 0][step 6200] logloss:0.638444 l2_regular:0.000829 rmse:539.867065 total_loss:0.639273 acc:0.085000\n",
      "[epoch 0][step 6300] logloss:0.642631 l2_regular:0.000673 rmse:563.068909 total_loss:0.643304 acc:0.079000\n",
      "[epoch 0][step 6400] logloss:0.632862 l2_regular:0.000585 rmse:571.600647 total_loss:0.633447 acc:0.093000\n",
      "[epoch 0][step 6500] logloss:0.651701 l2_regular:0.000635 rmse:601.437927 total_loss:0.652336 acc:0.066000\n",
      "[epoch 0][step 6600] logloss:0.665656 l2_regular:0.000479 rmse:638.965942 total_loss:0.666135 acc:0.046000\n",
      "[epoch 0][step 6700] logloss:0.288657 l2_regular:0.000766 rmse:610.292603 total_loss:0.289423 acc:0.000000\n",
      "[epoch 0][step 6800] logloss:0.648910 l2_regular:0.026134 rmse:649.624023 total_loss:0.675044 acc:0.070000\n",
      "[epoch 0][step 6900] logloss:0.602859 l2_regular:0.015877 rmse:400.727295 total_loss:0.618736 acc:0.136000\n",
      "[epoch 0][step 7000] logloss:0.610534 l2_regular:0.011135 rmse:640.696045 total_loss:0.621669 acc:0.125000\n",
      "[epoch 0][step 7100] logloss:0.630769 l2_regular:0.008414 rmse:1000.971985 total_loss:0.639183 acc:0.096000\n",
      "[epoch 0][step 7200] logloss:0.614023 l2_regular:0.006674 rmse:659.422791 total_loss:0.620696 acc:0.120000\n",
      "[epoch 0][step 7300] logloss:0.583322 l2_regular:0.005479 rmse:457.141479 total_loss:0.588800 acc:0.164000\n",
      "[epoch 0][step 7400] logloss:0.644724 l2_regular:0.004614 rmse:477.484985 total_loss:0.649337 acc:0.076000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0][step 7500] logloss:0.674029 l2_regular:0.003961 rmse:574.348572 total_loss:0.677991 acc:0.034000\n",
      "[epoch 0][step 7600] logloss:0.575646 l2_regular:0.013774 rmse:473.534973 total_loss:0.589420 acc:0.175000\n",
      "[epoch 0][step 7700] logloss:0.627978 l2_regular:0.010708 rmse:604.558594 total_loss:0.638686 acc:0.100000\n",
      "[epoch 0][step 7800] logloss:0.639840 l2_regular:0.008834 rmse:845.780457 total_loss:0.648673 acc:0.083000\n",
      "[epoch 0][step 7900] logloss:0.651701 l2_regular:0.007514 rmse:765.330200 total_loss:0.659215 acc:0.066000\n",
      "[epoch 0][step 8000] logloss:0.625884 l2_regular:0.006515 rmse:437.908783 total_loss:0.632399 acc:0.103000\n",
      "[epoch 0][step 8100] logloss:0.628676 l2_regular:0.005723 rmse:463.584045 total_loss:0.634399 acc:0.099000\n",
      "[epoch 0][step 8200] logloss:0.610534 l2_regular:0.005076 rmse:432.016205 total_loss:0.615610 acc:0.125000\n",
      "[epoch 0][step 8300] logloss:0.628676 l2_regular:0.004535 rmse:387.095367 total_loss:0.633211 acc:0.099000\n",
      "--------------epoch 0 finished —> total batch:8351---------------\n",
      "[epoch 1][step 8400] logloss:0.676123 l2_regular:0.004075 rmse:415.275940 total_loss:0.680198 acc:0.031000\n",
      "[epoch 1][step 8500] logloss:0.625884 l2_regular:0.003679 rmse:575.187805 total_loss:0.629563 acc:0.103000\n",
      "[epoch 1][step 8600] logloss:0.584019 l2_regular:0.003333 rmse:736.119751 total_loss:0.587353 acc:0.163000\n",
      "[epoch 1][step 8700] logloss:0.687287 l2_regular:0.003030 rmse:691.567078 total_loss:0.690317 acc:0.015000\n",
      "[epoch 1][step 8800] logloss:0.677518 l2_regular:0.002761 rmse:1006.935364 total_loss:0.680280 acc:0.029000\n",
      "[epoch 1][step 8900] logloss:0.583322 l2_regular:0.002522 rmse:526.468628 total_loss:0.585844 acc:0.164000\n",
      "[epoch 1][step 9000] logloss:0.618907 l2_regular:0.002309 rmse:375.048676 total_loss:0.621216 acc:0.113000\n",
      "[epoch 1][step 9100] logloss:0.637746 l2_regular:0.002116 rmse:754.991333 total_loss:0.639863 acc:0.086000\n",
      "[epoch 1][step 9200] logloss:0.682402 l2_regular:0.001943 rmse:523.091125 total_loss:0.684345 acc:0.022000\n",
      "[epoch 1][step 9300] logloss:0.638444 l2_regular:0.001786 rmse:519.663269 total_loss:0.640230 acc:0.085000\n",
      "[epoch 1][step 9400] logloss:0.637049 l2_regular:0.001644 rmse:430.474670 total_loss:0.638692 acc:0.087000\n",
      "[epoch 1][step 9500] logloss:0.647515 l2_regular:0.001514 rmse:569.847351 total_loss:0.649029 acc:0.072000\n",
      "[epoch 1][step 9600] logloss:0.632862 l2_regular:0.001396 rmse:392.783875 total_loss:0.634258 acc:0.093000\n",
      "[epoch 1][step 9700] logloss:0.637049 l2_regular:0.001288 rmse:450.895874 total_loss:0.638337 acc:0.087000\n",
      "[epoch 1][step 9800] logloss:0.658679 l2_regular:0.001189 rmse:519.946899 total_loss:0.659868 acc:0.056000\n",
      "[epoch 1][step 9900] logloss:0.584019 l2_regular:0.001099 rmse:417.596588 total_loss:0.585118 acc:0.163000\n",
      "[epoch 1][step 10000] logloss:0.604952 l2_regular:0.001016 rmse:510.760193 total_loss:0.605968 acc:0.133000\n",
      "[epoch 1][step 10100] logloss:0.627978 l2_regular:0.000939 rmse:554.882996 total_loss:0.628917 acc:0.100000\n",
      "[epoch 1][step 10200] logloss:0.643328 l2_regular:0.000869 rmse:668.621704 total_loss:0.644198 acc:0.078000\n",
      "[epoch 1][step 10300] logloss:0.608441 l2_regular:0.000805 rmse:459.032715 total_loss:0.609245 acc:0.128000\n",
      "[epoch 1][step 10400] logloss:0.633560 l2_regular:0.000745 rmse:472.682037 total_loss:0.634305 acc:0.092000\n",
      "[epoch 1][step 10500] logloss:0.629373 l2_regular:0.000690 rmse:752.457458 total_loss:0.630063 acc:0.098000\n",
      "[epoch 1][step 10600] logloss:0.669145 l2_regular:0.000639 rmse:589.602844 total_loss:0.669784 acc:0.041000\n",
      "[epoch 1][step 10700] logloss:0.648213 l2_regular:0.000592 rmse:346.642883 total_loss:0.648805 acc:0.071000\n",
      "[epoch 1][step 10800] logloss:0.647515 l2_regular:0.000549 rmse:439.973267 total_loss:0.648064 acc:0.072000\n",
      "[epoch 1][step 10900] logloss:0.632862 l2_regular:0.000509 rmse:542.280029 total_loss:0.633371 acc:0.093000\n",
      "[epoch 1][step 11000] logloss:0.674029 l2_regular:0.000472 rmse:421.616760 total_loss:0.674502 acc:0.034000\n",
      "[epoch 1][step 11100] logloss:0.619605 l2_regular:0.000438 rmse:754.396179 total_loss:0.620043 acc:0.112000\n",
      "[epoch 1][step 11200] logloss:0.571460 l2_regular:0.000406 rmse:521.132568 total_loss:0.571866 acc:0.181000\n",
      "[epoch 1][step 11300] logloss:0.649608 l2_regular:0.000377 rmse:485.717102 total_loss:0.649985 acc:0.069000\n",
      "[epoch 1][step 11400] logloss:0.577740 l2_regular:0.000350 rmse:445.757294 total_loss:0.578089 acc:0.172000\n",
      "[epoch 1][step 11500] logloss:0.651701 l2_regular:0.000324 rmse:690.996582 total_loss:0.652026 acc:0.066000\n",
      "[epoch 1][step 11600] logloss:0.621698 l2_regular:0.000301 rmse:484.802216 total_loss:0.621999 acc:0.109000\n",
      "[epoch 1][step 11700] logloss:0.670541 l2_regular:0.000279 rmse:558.239014 total_loss:0.670820 acc:0.039000\n",
      "[epoch 1][step 11800] logloss:0.578437 l2_regular:0.006440 rmse:408.196350 total_loss:0.584878 acc:0.171000\n",
      "[epoch 1][step 11900] logloss:0.558900 l2_regular:0.004897 rmse:467.191681 total_loss:0.563797 acc:0.199000\n",
      "[epoch 1][step 12000] logloss:0.584019 l2_regular:0.003791 rmse:514.053772 total_loss:0.587810 acc:0.163000\n",
      "[epoch 1][step 12100] logloss:0.598672 l2_regular:0.003104 rmse:332.553711 total_loss:0.601776 acc:0.142000\n",
      "[epoch 1][step 12200] logloss:0.543550 l2_regular:0.002623 rmse:413.532074 total_loss:0.546173 acc:0.221000\n",
      "[epoch 1][step 12300] logloss:0.559598 l2_regular:0.002264 rmse:612.118164 total_loss:0.561862 acc:0.198000\n",
      "[epoch 1][step 12400] logloss:0.512151 l2_regular:0.001984 rmse:403.759399 total_loss:0.514135 acc:0.266000\n",
      "[epoch 1][step 12500] logloss:0.551923 l2_regular:0.001758 rmse:450.129730 total_loss:0.553680 acc:0.209000\n",
      "[epoch 1][step 12600] logloss:0.535177 l2_regular:0.001571 rmse:362.755157 total_loss:0.536747 acc:0.233000\n",
      "[epoch 1][step 12700] logloss:0.537968 l2_regular:0.001413 rmse:541.175781 total_loss:0.539381 acc:0.229000\n",
      "[epoch 1][step 12800] logloss:0.551923 l2_regular:0.001279 rmse:482.868652 total_loss:0.553201 acc:0.209000\n",
      "[epoch 1][step 12900] logloss:0.476565 l2_regular:0.001162 rmse:479.084106 total_loss:0.477727 acc:0.317000\n",
      "[epoch 1][step 13000] logloss:0.604952 l2_regular:0.001060 rmse:448.593170 total_loss:0.606012 acc:0.133000\n",
      "[epoch 1][step 13100] logloss:0.605650 l2_regular:0.000970 rmse:439.992645 total_loss:0.606620 acc:0.132000\n",
      "[epoch 1][step 13200] logloss:0.563087 l2_regular:0.000891 rmse:527.907837 total_loss:0.563978 acc:0.193000\n",
      "[epoch 1][step 13300] logloss:0.532386 l2_regular:0.000820 rmse:487.254242 total_loss:0.533206 acc:0.237000\n",
      "[epoch 1][step 13400] logloss:0.570762 l2_regular:0.000757 rmse:728.024658 total_loss:0.571519 acc:0.182000\n",
      "[epoch 1][step 13500] logloss:0.547038 l2_regular:0.000701 rmse:507.830109 total_loss:0.547739 acc:0.216000\n",
      "[epoch 1][step 13600] logloss:0.538665 l2_regular:0.000650 rmse:600.116821 total_loss:0.539315 acc:0.228000\n",
      "[epoch 1][step 13700] logloss:0.609836 l2_regular:0.000604 rmse:547.254028 total_loss:0.610440 acc:0.126000\n",
      "[epoch 1][step 13800] logloss:0.488427 l2_regular:0.000562 rmse:563.205688 total_loss:0.488989 acc:0.300000\n",
      "[epoch 1][step 13900] logloss:0.586810 l2_regular:0.000524 rmse:471.090790 total_loss:0.587335 acc:0.159000\n",
      "[epoch 1][step 14000] logloss:0.479356 l2_regular:0.000490 rmse:390.259918 total_loss:0.479846 acc:0.313000\n",
      "[epoch 1][step 14100] logloss:0.526803 l2_regular:0.000458 rmse:482.791901 total_loss:0.527262 acc:0.245000\n",
      "[epoch 1][step 14200] logloss:0.503080 l2_regular:0.000430 rmse:493.763275 total_loss:0.503510 acc:0.279000\n",
      "[epoch 1][step 14300] logloss:0.563087 l2_regular:0.000403 rmse:472.716278 total_loss:0.563490 acc:0.193000\n",
      "[epoch 1][step 14400] logloss:0.564482 l2_regular:0.000379 rmse:517.330322 total_loss:0.564861 acc:0.191000\n",
      "[epoch 1][step 14500] logloss:0.577740 l2_regular:0.000357 rmse:515.349182 total_loss:0.578096 acc:0.172000\n",
      "[epoch 1][step 14600] logloss:0.520524 l2_regular:0.000336 rmse:433.242004 total_loss:0.520860 acc:0.254000\n",
      "[epoch 1][step 14700] logloss:0.524710 l2_regular:0.000317 rmse:572.463379 total_loss:0.525028 acc:0.248000\n",
      "[epoch 1][step 14800] logloss:0.535874 l2_regular:0.000300 rmse:411.757996 total_loss:0.536174 acc:0.232000\n",
      "[epoch 1][step 14900] logloss:0.632862 l2_regular:0.006978 rmse:495.005554 total_loss:0.639840 acc:0.093000\n",
      "[epoch 1][step 15000] logloss:0.626582 l2_regular:0.004846 rmse:562.870728 total_loss:0.631428 acc:0.102000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1][step 15100] logloss:0.637049 l2_regular:0.003844 rmse:579.736938 total_loss:0.640892 acc:0.087000\n",
      "[epoch 1][step 15200] logloss:0.634955 l2_regular:0.003204 rmse:505.737305 total_loss:0.638159 acc:0.090000\n",
      "[epoch 1][step 15300] logloss:0.644026 l2_regular:0.002747 rmse:471.862671 total_loss:0.646773 acc:0.077000\n",
      "[epoch 1][step 15400] logloss:0.628676 l2_regular:0.002398 rmse:514.526062 total_loss:0.631074 acc:0.099000\n",
      "[epoch 1][step 15500] logloss:0.580531 l2_regular:0.002122 rmse:536.923279 total_loss:0.582652 acc:0.168000\n",
      "[epoch 1][step 15600] logloss:0.577740 l2_regular:0.001895 rmse:563.116272 total_loss:0.579635 acc:0.172000\n",
      "[epoch 1][step 15700] logloss:0.643328 l2_regular:0.001706 rmse:597.243042 total_loss:0.645034 acc:0.078000\n",
      "[epoch 1][step 15800] logloss:0.668447 l2_regular:0.001544 rmse:804.056152 total_loss:0.669992 acc:0.042000\n",
      "[epoch 1][step 15900] logloss:0.625884 l2_regular:0.001405 rmse:502.379944 total_loss:0.627289 acc:0.103000\n",
      "[epoch 1][step 16000] logloss:0.650306 l2_regular:0.001283 rmse:501.196899 total_loss:0.651589 acc:0.068000\n",
      "[epoch 1][step 16100] logloss:0.673332 l2_regular:0.001177 rmse:560.424072 total_loss:0.674508 acc:0.035000\n",
      "[epoch 1][step 16200] logloss:0.639840 l2_regular:0.001082 rmse:501.755554 total_loss:0.640921 acc:0.083000\n",
      "[epoch 1][step 16300] logloss:0.662168 l2_regular:0.000997 rmse:423.794434 total_loss:0.663165 acc:0.051000\n",
      "[epoch 1][step 16400] logloss:0.671936 l2_regular:0.000921 rmse:437.615601 total_loss:0.672857 acc:0.037000\n",
      "[epoch 1][step 16500] logloss:0.616116 l2_regular:0.000853 rmse:461.091858 total_loss:0.616969 acc:0.117000\n",
      "[epoch 1][step 16600] logloss:0.640537 l2_regular:0.000791 rmse:513.306763 total_loss:0.641328 acc:0.082000\n",
      "[epoch 1][step 16700] logloss:0.661470 l2_regular:0.000735 rmse:524.074768 total_loss:0.662205 acc:0.052000\n",
      "--------------epoch 1 finished —> total batch:8351---------------\n",
      "[epoch 2][step 16800] logloss:0.609836 l2_regular:0.000684 rmse:441.460175 total_loss:0.610520 acc:0.126000\n",
      "[epoch 2][step 16900] logloss:0.604254 l2_regular:0.000637 rmse:608.860352 total_loss:0.604891 acc:0.134000\n",
      "[epoch 2][step 17000] logloss:0.639840 l2_regular:0.000594 rmse:379.790497 total_loss:0.640434 acc:0.083000\n",
      "[epoch 2][step 17100] logloss:0.637746 l2_regular:0.000555 rmse:637.673828 total_loss:0.638301 acc:0.086000\n",
      "[epoch 2][step 17200] logloss:0.627280 l2_regular:0.000519 rmse:565.436279 total_loss:0.627799 acc:0.101000\n",
      "[epoch 2][step 17300] logloss:0.666354 l2_regular:0.000486 rmse:444.326935 total_loss:0.666840 acc:0.045000\n",
      "[epoch 2][step 17400] logloss:0.586113 l2_regular:0.000455 rmse:431.758118 total_loss:0.586568 acc:0.160000\n",
      "[epoch 2][step 17500] logloss:0.639840 l2_regular:0.000427 rmse:576.373779 total_loss:0.640266 acc:0.083000\n",
      "[epoch 2][step 17600] logloss:0.660772 l2_regular:0.000401 rmse:427.951721 total_loss:0.661173 acc:0.053000\n",
      "[epoch 2][step 17700] logloss:0.660074 l2_regular:0.000377 rmse:520.522339 total_loss:0.660451 acc:0.054000\n",
      "[epoch 2][step 17800] logloss:0.632862 l2_regular:0.000354 rmse:650.698059 total_loss:0.633216 acc:0.093000\n",
      "[epoch 2][step 17900] logloss:0.660074 l2_regular:0.000334 rmse:495.911743 total_loss:0.660408 acc:0.054000\n",
      "[epoch 2][step 18000] logloss:0.567971 l2_regular:0.002571 rmse:710.060547 total_loss:0.570542 acc:0.186000\n",
      "[epoch 2][step 18100] logloss:0.524013 l2_regular:0.002249 rmse:491.993927 total_loss:0.526261 acc:0.249000\n",
      "[epoch 2][step 18200] logloss:0.557505 l2_regular:0.002019 rmse:445.506134 total_loss:0.559523 acc:0.201000\n",
      "[epoch 2][step 18300] logloss:0.544945 l2_regular:0.001836 rmse:364.812653 total_loss:0.546782 acc:0.219000\n",
      "[epoch 2][step 18400] logloss:0.526804 l2_regular:0.001685 rmse:388.369171 total_loss:0.528489 acc:0.245000\n",
      "[epoch 2][step 18500] logloss:0.583322 l2_regular:0.001556 rmse:629.834778 total_loss:0.584877 acc:0.164000\n",
      "[epoch 2][step 18600] logloss:0.478659 l2_regular:0.001443 rmse:373.407257 total_loss:0.480102 acc:0.314000\n",
      "[epoch 2][step 18700] logloss:0.502382 l2_regular:0.001344 rmse:438.955017 total_loss:0.503726 acc:0.280000\n",
      "[epoch 2][step 18800] logloss:0.502382 l2_regular:0.001256 rmse:532.218079 total_loss:0.503638 acc:0.280000\n",
      "[epoch 2][step 18900] logloss:0.604952 l2_regular:0.001176 rmse:511.765381 total_loss:0.606128 acc:0.133000\n",
      "[epoch 2][step 19000] logloss:0.603556 l2_regular:0.001105 rmse:533.632874 total_loss:0.604661 acc:0.135000\n",
      "[epoch 2][step 19100] logloss:0.430514 l2_regular:0.001039 rmse:366.221832 total_loss:0.431553 acc:0.383000\n",
      "[epoch 2][step 19200] logloss:0.554016 l2_regular:0.000980 rmse:521.571045 total_loss:0.554996 acc:0.206000\n",
      "[epoch 2][step 19300] logloss:0.560993 l2_regular:0.000925 rmse:371.316833 total_loss:0.561919 acc:0.196000\n",
      "[epoch 2][step 19400] logloss:0.487032 l2_regular:0.000875 rmse:517.091003 total_loss:0.487907 acc:0.302000\n",
      "[epoch 2][step 19500] logloss:0.516337 l2_regular:0.000829 rmse:318.147308 total_loss:0.517166 acc:0.260000\n",
      "[epoch 2][step 19600] logloss:0.517733 l2_regular:0.000786 rmse:331.960541 total_loss:0.518519 acc:0.258000\n",
      "[epoch 2][step 19700] logloss:0.485636 l2_regular:0.000746 rmse:295.644318 total_loss:0.486382 acc:0.304000\n",
      "[epoch 2][step 19800] logloss:0.544945 l2_regular:0.000709 rmse:735.673950 total_loss:0.545654 acc:0.219000\n",
      "[epoch 2][step 19900] logloss:0.586113 l2_regular:0.000675 rmse:300.228821 total_loss:0.586787 acc:0.160000\n",
      "[epoch 2][step 20000] logloss:0.552620 l2_regular:0.000642 rmse:423.062317 total_loss:0.553263 acc:0.208000\n",
      "[epoch 2][step 20100] logloss:0.563784 l2_regular:0.000612 rmse:415.888428 total_loss:0.564397 acc:0.192000\n",
      "[epoch 2][step 20200] logloss:0.577042 l2_regular:0.000584 rmse:402.555573 total_loss:0.577626 acc:0.173000\n",
      "[epoch 2][step 20300] logloss:0.518431 l2_regular:0.000558 rmse:412.856018 total_loss:0.518988 acc:0.257000\n",
      "[epoch 2][step 20400] logloss:0.530990 l2_regular:0.000533 rmse:402.329254 total_loss:0.531523 acc:0.239000\n",
      "[epoch 2][step 20500] logloss:0.571460 l2_regular:0.000509 rmse:316.342804 total_loss:0.571969 acc:0.181000\n",
      "[epoch 2][step 20600] logloss:0.554016 l2_regular:0.000487 rmse:475.774750 total_loss:0.554503 acc:0.206000\n",
      "[epoch 2][step 20700] logloss:0.507266 l2_regular:0.000463 rmse:393.395905 total_loss:0.507729 acc:0.273000\n",
      "[epoch 2][step 20800] logloss:0.579135 l2_regular:0.000443 rmse:360.096893 total_loss:0.579578 acc:0.170000\n",
      "[epoch 2][step 20900] logloss:0.503778 l2_regular:0.000425 rmse:466.615509 total_loss:0.504202 acc:0.278000\n",
      "[epoch 2][step 21000] logloss:0.065811 l2_regular:0.000728 rmse:451.361450 total_loss:0.066539 acc:0.190000\n",
      "[epoch 2][step 21100] logloss:0.068975 l2_regular:0.000832 rmse:492.567719 total_loss:0.069807 acc:0.159000\n",
      "[epoch 2][step 21200] logloss:0.065534 l2_regular:0.000844 rmse:426.275787 total_loss:0.066378 acc:0.259000\n",
      "[epoch 2][step 21300] logloss:0.086731 l2_regular:0.000856 rmse:508.838593 total_loss:0.087587 acc:0.150000\n",
      "[epoch 2][step 21400] logloss:0.070967 l2_regular:0.000860 rmse:532.762817 total_loss:0.071828 acc:0.184000\n",
      "[epoch 2][step 21500] logloss:0.057264 l2_regular:0.000851 rmse:429.187805 total_loss:0.058116 acc:0.162000\n",
      "[epoch 2][step 21600] logloss:0.055344 l2_regular:0.000842 rmse:388.900574 total_loss:0.056186 acc:0.220000\n",
      "[epoch 2][step 21700] logloss:0.073003 l2_regular:0.000847 rmse:539.064270 total_loss:0.073849 acc:0.216000\n",
      "[epoch 2][step 21800] logloss:0.068819 l2_regular:0.000847 rmse:398.549347 total_loss:0.069665 acc:0.196000\n",
      "[epoch 2][step 21900] logloss:0.061678 l2_regular:0.000845 rmse:609.398254 total_loss:0.062523 acc:0.241000\n",
      "[epoch 2][step 22000] logloss:0.067918 l2_regular:0.000834 rmse:407.679169 total_loss:0.068752 acc:0.241000\n",
      "[epoch 2][step 22100] logloss:0.064104 l2_regular:0.000835 rmse:415.573242 total_loss:0.064938 acc:0.220000\n",
      "[epoch 2][step 22200] logloss:0.057321 l2_regular:0.000831 rmse:422.156738 total_loss:0.058152 acc:0.241000\n",
      "[epoch 2][step 22300] logloss:0.060128 l2_regular:0.000833 rmse:562.955566 total_loss:0.060962 acc:0.233000\n",
      "[epoch 2][step 22400] logloss:0.073710 l2_regular:0.000829 rmse:377.548309 total_loss:0.074539 acc:0.198000\n",
      "[epoch 2][step 22500] logloss:0.076992 l2_regular:0.000826 rmse:542.547363 total_loss:0.077818 acc:0.107000\n",
      "[epoch 2][step 22600] logloss:0.057814 l2_regular:0.000839 rmse:421.659546 total_loss:0.058653 acc:0.224000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2][step 22700] logloss:0.064534 l2_regular:0.000830 rmse:468.563110 total_loss:0.065364 acc:0.218000\n",
      "[epoch 2][step 22800] logloss:0.064839 l2_regular:0.000828 rmse:418.296814 total_loss:0.065667 acc:0.194000\n",
      "[epoch 2][step 22900] logloss:0.065191 l2_regular:0.000830 rmse:412.724854 total_loss:0.066021 acc:0.242000\n",
      "[epoch 2][step 23000] logloss:0.062639 l2_regular:0.000816 rmse:452.251190 total_loss:0.063455 acc:0.170000\n",
      "[epoch 2][step 23100] logloss:0.058420 l2_regular:0.000812 rmse:511.651184 total_loss:0.059232 acc:0.245000\n",
      "[epoch 2][step 23200] logloss:0.069384 l2_regular:0.000804 rmse:405.855469 total_loss:0.070188 acc:0.305000\n",
      "[epoch 2][step 23300] logloss:0.067139 l2_regular:0.000806 rmse:596.757507 total_loss:0.067945 acc:0.269000\n",
      "[epoch 2][step 23400] logloss:0.049830 l2_regular:0.000803 rmse:344.729553 total_loss:0.050634 acc:0.285000\n",
      "[epoch 2][step 23500] logloss:0.067476 l2_regular:0.000809 rmse:376.499847 total_loss:0.068285 acc:0.201000\n",
      "[epoch 2][step 23600] logloss:0.068414 l2_regular:0.000806 rmse:416.699463 total_loss:0.069220 acc:0.262000\n",
      "[epoch 2][step 23700] logloss:0.061353 l2_regular:0.000808 rmse:401.087402 total_loss:0.062160 acc:0.205000\n",
      "[epoch 2][step 23800] logloss:0.086130 l2_regular:0.000819 rmse:439.420532 total_loss:0.086948 acc:0.113000\n",
      "[epoch 2][step 23900] logloss:0.062677 l2_regular:0.000812 rmse:479.983459 total_loss:0.063489 acc:0.239000\n",
      "[epoch 2][step 24000] logloss:0.061048 l2_regular:0.000814 rmse:404.160156 total_loss:0.061863 acc:0.255000\n",
      "[epoch 2][step 24100] logloss:0.065404 l2_regular:0.000816 rmse:503.043335 total_loss:0.066220 acc:0.169000\n",
      "[epoch 2][step 24200] logloss:0.056501 l2_regular:0.000807 rmse:341.640869 total_loss:0.057308 acc:0.186000\n",
      "[epoch 2][step 24300] logloss:0.055786 l2_regular:0.000798 rmse:750.374939 total_loss:0.056584 acc:0.267000\n",
      "[epoch 2][step 24400] logloss:0.061876 l2_regular:0.000795 rmse:462.255524 total_loss:0.062671 acc:0.218000\n",
      "[epoch 2][step 24500] logloss:0.061093 l2_regular:0.000785 rmse:521.880005 total_loss:0.061877 acc:0.304000\n",
      "[epoch 2][step 24600] logloss:0.075595 l2_regular:0.000776 rmse:678.161072 total_loss:0.076370 acc:0.154000\n",
      "[epoch 2][step 24700] logloss:0.062814 l2_regular:0.000776 rmse:691.825012 total_loss:0.063590 acc:0.220000\n",
      "[epoch 2][step 24800] logloss:0.061165 l2_regular:0.000767 rmse:485.208862 total_loss:0.061932 acc:0.294000\n",
      "[epoch 2][step 24900] logloss:0.072530 l2_regular:0.000766 rmse:545.296814 total_loss:0.073296 acc:0.134000\n",
      "[epoch 2][step 25000] logloss:0.058215 l2_regular:0.000761 rmse:484.787170 total_loss:0.058976 acc:0.194000\n",
      "--------------epoch 2 finished —> total batch:8351---------------\n",
      "[epoch 3][step 25100] logloss:0.053925 l2_regular:0.000752 rmse:541.081238 total_loss:0.054677 acc:0.349000\n",
      "[epoch 3][step 25200] logloss:0.070864 l2_regular:0.000750 rmse:481.303986 total_loss:0.071614 acc:0.206000\n",
      "[epoch 3][step 25300] logloss:0.062265 l2_regular:0.000742 rmse:392.369141 total_loss:0.063007 acc:0.207000\n",
      "[epoch 3][step 25400] logloss:0.063552 l2_regular:0.000739 rmse:499.050690 total_loss:0.064291 acc:0.274000\n",
      "[epoch 3][step 25500] logloss:0.055918 l2_regular:0.000734 rmse:424.731628 total_loss:0.056652 acc:0.233000\n",
      "[epoch 3][step 25600] logloss:0.063612 l2_regular:0.000733 rmse:623.172180 total_loss:0.064345 acc:0.171000\n",
      "[epoch 3][step 25700] logloss:0.059974 l2_regular:0.000735 rmse:385.270660 total_loss:0.060709 acc:0.250000\n",
      "[epoch 3][step 25800] logloss:0.065460 l2_regular:0.000736 rmse:564.680664 total_loss:0.066196 acc:0.105000\n",
      "[epoch 3][step 25900] logloss:0.065517 l2_regular:0.000736 rmse:469.147705 total_loss:0.066253 acc:0.169000\n",
      "[epoch 3][step 26000] logloss:0.063340 l2_regular:0.000728 rmse:577.029297 total_loss:0.064068 acc:0.174000\n",
      "[epoch 3][step 26100] logloss:0.055671 l2_regular:0.000722 rmse:441.066956 total_loss:0.056392 acc:0.267000\n",
      "[epoch 3][step 26200] logloss:0.049513 l2_regular:0.000725 rmse:413.776703 total_loss:0.050238 acc:0.272000\n",
      "[epoch 3][step 26300] logloss:0.048313 l2_regular:0.000723 rmse:589.091858 total_loss:0.049036 acc:0.308000\n",
      "[epoch 3][step 26400] logloss:0.061652 l2_regular:0.000715 rmse:462.159271 total_loss:0.062368 acc:0.245000\n",
      "[epoch 3][step 26500] logloss:0.055394 l2_regular:0.000709 rmse:309.180420 total_loss:0.056103 acc:0.154000\n",
      "[epoch 3][step 26600] logloss:0.052728 l2_regular:0.000707 rmse:420.004364 total_loss:0.053436 acc:0.213000\n",
      "[epoch 3][step 26700] logloss:0.056901 l2_regular:0.000706 rmse:410.793793 total_loss:0.057607 acc:0.191000\n",
      "[epoch 3][step 26800] logloss:0.066065 l2_regular:0.000708 rmse:719.677124 total_loss:0.066773 acc:0.275000\n",
      "[epoch 3][step 26900] logloss:0.053969 l2_regular:0.000703 rmse:436.729279 total_loss:0.054672 acc:0.205000\n",
      "[epoch 3][step 27000] logloss:0.057275 l2_regular:0.000699 rmse:558.575439 total_loss:0.057974 acc:0.241000\n",
      "[epoch 3][step 27100] logloss:0.059032 l2_regular:0.000694 rmse:353.693573 total_loss:0.059725 acc:0.263000\n",
      "[epoch 3][step 27200] logloss:0.063642 l2_regular:0.000686 rmse:795.925781 total_loss:0.064328 acc:0.292000\n",
      "[epoch 3][step 27300] logloss:0.054943 l2_regular:0.000688 rmse:518.177795 total_loss:0.055630 acc:0.138000\n",
      "[epoch 3][step 27400] logloss:0.063520 l2_regular:0.000684 rmse:419.507294 total_loss:0.064204 acc:0.190000\n",
      "[epoch 3][step 27500] logloss:0.058533 l2_regular:0.000682 rmse:533.149109 total_loss:0.059215 acc:0.282000\n",
      "[epoch 3][step 27600] logloss:0.055746 l2_regular:0.000684 rmse:514.741333 total_loss:0.056430 acc:0.344000\n",
      "[epoch 3][step 27700] logloss:0.062390 l2_regular:0.000683 rmse:396.736328 total_loss:0.063072 acc:0.250000\n",
      "[epoch 3][step 27800] logloss:0.055632 l2_regular:0.000679 rmse:593.146118 total_loss:0.056312 acc:0.269000\n",
      "[epoch 3][step 27900] logloss:0.064789 l2_regular:0.000673 rmse:312.155273 total_loss:0.065462 acc:0.194000\n",
      "[epoch 3][step 28000] logloss:0.058764 l2_regular:0.000669 rmse:559.260132 total_loss:0.059434 acc:0.259000\n",
      "[epoch 3][step 28100] logloss:0.056940 l2_regular:0.000666 rmse:635.015259 total_loss:0.057606 acc:0.276000\n",
      "[epoch 3][step 28200] logloss:0.057766 l2_regular:0.000662 rmse:456.252258 total_loss:0.058427 acc:0.152000\n",
      "[epoch 3][step 28300] logloss:0.059431 l2_regular:0.000662 rmse:409.745911 total_loss:0.060093 acc:0.256000\n",
      "[epoch 3][step 28400] logloss:0.061584 l2_regular:0.000663 rmse:575.796082 total_loss:0.062247 acc:0.185000\n",
      "[epoch 3][step 28500] logloss:0.057870 l2_regular:0.000660 rmse:404.279175 total_loss:0.058530 acc:0.406000\n",
      "[epoch 3][step 28600] logloss:0.055575 l2_regular:0.000658 rmse:569.606079 total_loss:0.056233 acc:0.194000\n",
      "[epoch 3][step 28700] logloss:0.068042 l2_regular:0.000654 rmse:646.675171 total_loss:0.068697 acc:0.285000\n",
      "[epoch 3][step 28800] logloss:0.069540 l2_regular:0.000653 rmse:442.154480 total_loss:0.070193 acc:0.193000\n",
      "[epoch 3][step 28900] logloss:0.062114 l2_regular:0.000650 rmse:515.588928 total_loss:0.062764 acc:0.285000\n",
      "[epoch 3][step 29000] logloss:0.078746 l2_regular:0.000650 rmse:695.301819 total_loss:0.079396 acc:0.174000\n",
      "[epoch 3][step 29100] logloss:0.052097 l2_regular:0.000645 rmse:425.875153 total_loss:0.052741 acc:0.343000\n",
      "[epoch 3][step 29200] logloss:0.069594 l2_regular:0.000644 rmse:563.457520 total_loss:0.070238 acc:0.166000\n",
      "[epoch 3][step 29300] logloss:0.051145 l2_regular:0.000645 rmse:305.541656 total_loss:0.051790 acc:0.176000\n",
      "[epoch 3][step 29400] logloss:0.055234 l2_regular:0.000646 rmse:515.686523 total_loss:0.055880 acc:0.319000\n",
      "[epoch 3][step 29500] logloss:0.059527 l2_regular:0.000643 rmse:426.809906 total_loss:0.060170 acc:0.213000\n",
      "[epoch 3][step 29600] logloss:0.066601 l2_regular:0.000641 rmse:446.288879 total_loss:0.067243 acc:0.221000\n",
      "[epoch 3][step 29700] logloss:0.057942 l2_regular:0.000638 rmse:503.415222 total_loss:0.058580 acc:0.285000\n",
      "[epoch 3][step 29800] logloss:0.069217 l2_regular:0.000638 rmse:743.679260 total_loss:0.069854 acc:0.194000\n",
      "[epoch 3][step 29900] logloss:0.058632 l2_regular:0.000639 rmse:423.764191 total_loss:0.059270 acc:0.232000\n",
      "[epoch 3][step 30000] logloss:0.054792 l2_regular:0.000635 rmse:410.721741 total_loss:0.055428 acc:0.151000\n",
      "[epoch 3][step 30100] logloss:0.065957 l2_regular:0.000636 rmse:462.534424 total_loss:0.066592 acc:0.157000\n",
      "[epoch 3][step 30200] logloss:0.053894 l2_regular:0.000635 rmse:522.053467 total_loss:0.054529 acc:0.290000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3][step 30300] logloss:0.055889 l2_regular:0.000635 rmse:414.817078 total_loss:0.056524 acc:0.259000\n",
      "[epoch 3][step 30400] logloss:0.052537 l2_regular:0.000634 rmse:420.348877 total_loss:0.053171 acc:0.231000\n",
      "[epoch 3][step 30500] logloss:0.058462 l2_regular:0.000633 rmse:550.691467 total_loss:0.059094 acc:0.223000\n",
      "[epoch 3][step 30600] logloss:0.055548 l2_regular:0.000632 rmse:351.753265 total_loss:0.056180 acc:0.308000\n",
      "[epoch 3][step 30700] logloss:0.076586 l2_regular:0.000629 rmse:491.221680 total_loss:0.077215 acc:0.134000\n",
      "[epoch 3][step 30800] logloss:0.059195 l2_regular:0.000627 rmse:477.698792 total_loss:0.059821 acc:0.353000\n",
      "[epoch 3][step 30900] logloss:0.050011 l2_regular:0.000627 rmse:470.596588 total_loss:0.050638 acc:0.355000\n",
      "[epoch 3][step 31000] logloss:0.069186 l2_regular:0.000626 rmse:470.835693 total_loss:0.069812 acc:0.221000\n",
      "[epoch 3][step 31100] logloss:0.050054 l2_regular:0.000625 rmse:549.355164 total_loss:0.050679 acc:0.369000\n",
      "[epoch 3][step 31200] logloss:0.050367 l2_regular:0.000626 rmse:508.137604 total_loss:0.050993 acc:0.348000\n",
      "[epoch 3][step 31300] logloss:0.072986 l2_regular:0.000623 rmse:662.342102 total_loss:0.073609 acc:0.254000\n",
      "[epoch 3][step 31400] logloss:0.065899 l2_regular:0.000622 rmse:411.386353 total_loss:0.066521 acc:0.218000\n",
      "[epoch 3][step 31500] logloss:0.061375 l2_regular:0.000622 rmse:466.171356 total_loss:0.061997 acc:0.230000\n",
      "[epoch 3][step 31600] logloss:0.055288 l2_regular:0.000621 rmse:370.775513 total_loss:0.055909 acc:0.237000\n",
      "[epoch 3][step 31700] logloss:0.067340 l2_regular:0.000621 rmse:343.744690 total_loss:0.067961 acc:0.118000\n",
      "[epoch 3][step 31800] logloss:0.066960 l2_regular:0.000621 rmse:730.782227 total_loss:0.067581 acc:0.178000\n",
      "[epoch 3][step 31900] logloss:0.055311 l2_regular:0.000621 rmse:373.045013 total_loss:0.055932 acc:0.267000\n",
      "[epoch 3][step 32000] logloss:0.053486 l2_regular:0.000619 rmse:429.305939 total_loss:0.054106 acc:0.264000\n",
      "[epoch 3][step 32100] logloss:0.057255 l2_regular:0.000620 rmse:359.602539 total_loss:0.057875 acc:0.297000\n",
      "[epoch 3][step 32200] logloss:0.071302 l2_regular:0.000622 rmse:514.257629 total_loss:0.071923 acc:0.216000\n",
      "[epoch 3][step 32300] logloss:0.067114 l2_regular:0.000622 rmse:529.445068 total_loss:0.067736 acc:0.113000\n",
      "[epoch 3][step 32400] logloss:0.060988 l2_regular:0.000622 rmse:455.817841 total_loss:0.061610 acc:0.182000\n",
      "[epoch 3][step 32500] logloss:0.061843 l2_regular:0.000622 rmse:394.543060 total_loss:0.062466 acc:0.198000\n",
      "[epoch 3][step 32600] logloss:0.054017 l2_regular:0.000619 rmse:463.435120 total_loss:0.054636 acc:0.262000\n",
      "[epoch 3][step 32700] logloss:0.061483 l2_regular:0.000618 rmse:490.311401 total_loss:0.062101 acc:0.243000\n",
      "[epoch 3][step 32800] logloss:0.066069 l2_regular:0.000618 rmse:487.845001 total_loss:0.066686 acc:0.257000\n",
      "[epoch 3][step 32900] logloss:0.056908 l2_regular:0.000617 rmse:386.616089 total_loss:0.057525 acc:0.229000\n",
      "[epoch 3][step 33000] logloss:0.052191 l2_regular:0.000616 rmse:404.411224 total_loss:0.052807 acc:0.254000\n",
      "[epoch 3][step 33100] logloss:0.050319 l2_regular:0.000615 rmse:347.287048 total_loss:0.050935 acc:0.264000\n",
      "[epoch 3][step 33200] logloss:0.061188 l2_regular:0.000615 rmse:430.755402 total_loss:0.061804 acc:0.280000\n",
      "[epoch 3][step 33300] logloss:0.050662 l2_regular:0.000615 rmse:443.937256 total_loss:0.051277 acc:0.382000\n",
      "[epoch 3][step 33400] logloss:0.061863 l2_regular:0.000614 rmse:497.713715 total_loss:0.062477 acc:0.173000\n",
      "--------------epoch 3 finished —> total batch:8351---------------\n",
      "[epoch 4][step 33500] logloss:0.049322 l2_regular:0.000613 rmse:408.838837 total_loss:0.049936 acc:0.266000\n",
      "[epoch 4][step 33600] logloss:0.061161 l2_regular:0.000613 rmse:426.077332 total_loss:0.061774 acc:0.236000\n",
      "[epoch 4][step 33700] logloss:0.057825 l2_regular:0.000613 rmse:493.740295 total_loss:0.058438 acc:0.170000\n",
      "[epoch 4][step 33800] logloss:0.067755 l2_regular:0.000612 rmse:365.660919 total_loss:0.068367 acc:0.142000\n",
      "[epoch 4][step 33900] logloss:0.060315 l2_regular:0.000612 rmse:336.930298 total_loss:0.060927 acc:0.148000\n",
      "[epoch 4][step 34000] logloss:0.057009 l2_regular:0.000613 rmse:742.031616 total_loss:0.057623 acc:0.340000\n",
      "[epoch 4][step 34100] logloss:0.055792 l2_regular:0.000613 rmse:521.762390 total_loss:0.056405 acc:0.258000\n",
      "[epoch 4][step 34200] logloss:0.063424 l2_regular:0.000614 rmse:378.939209 total_loss:0.064038 acc:0.236000\n",
      "[epoch 4][step 34300] logloss:0.060944 l2_regular:0.000613 rmse:704.369263 total_loss:0.061557 acc:0.199000\n",
      "[epoch 4][step 34400] logloss:0.056725 l2_regular:0.000612 rmse:486.536438 total_loss:0.057337 acc:0.236000\n",
      "[epoch 4][step 34500] logloss:0.051864 l2_regular:0.000612 rmse:418.134094 total_loss:0.052476 acc:0.324000\n",
      "[epoch 4][step 34600] logloss:0.057603 l2_regular:0.000614 rmse:664.872559 total_loss:0.058217 acc:0.173000\n",
      "[epoch 4][step 34700] logloss:0.053880 l2_regular:0.000614 rmse:416.039185 total_loss:0.054494 acc:0.213000\n",
      "[epoch 4][step 34800] logloss:0.066429 l2_regular:0.000614 rmse:411.253204 total_loss:0.067042 acc:0.226000\n",
      "[epoch 4][step 34900] logloss:0.054587 l2_regular:0.000612 rmse:408.448334 total_loss:0.055200 acc:0.267000\n",
      "[epoch 4][step 35000] logloss:0.065146 l2_regular:0.000613 rmse:542.615601 total_loss:0.065759 acc:0.257000\n",
      "[epoch 4][step 35100] logloss:0.062571 l2_regular:0.000613 rmse:497.015656 total_loss:0.063184 acc:0.265000\n",
      "[epoch 4][step 35200] logloss:0.055093 l2_regular:0.000615 rmse:473.909882 total_loss:0.055708 acc:0.209000\n",
      "[epoch 4][step 35300] logloss:0.062457 l2_regular:0.000614 rmse:407.665466 total_loss:0.063071 acc:0.181000\n",
      "[epoch 4][step 35400] logloss:0.060517 l2_regular:0.000614 rmse:515.759827 total_loss:0.061130 acc:0.198000\n",
      "[epoch 4][step 35500] logloss:0.069331 l2_regular:0.000613 rmse:366.287842 total_loss:0.069944 acc:0.187000\n",
      "[epoch 4][step 35600] logloss:0.048517 l2_regular:0.000612 rmse:393.615082 total_loss:0.049129 acc:0.301000\n",
      "[epoch 4][step 35700] logloss:0.066402 l2_regular:0.000612 rmse:601.692688 total_loss:0.067014 acc:0.243000\n",
      "[epoch 4][step 35800] logloss:0.058252 l2_regular:0.000612 rmse:620.631836 total_loss:0.058863 acc:0.278000\n",
      "[epoch 4][step 35900] logloss:0.072529 l2_regular:0.000612 rmse:540.447998 total_loss:0.073141 acc:0.159000\n",
      "[epoch 4][step 36000] logloss:0.062514 l2_regular:0.000613 rmse:439.533875 total_loss:0.063127 acc:0.227000\n",
      "[epoch 4][step 36100] logloss:0.068327 l2_regular:0.000613 rmse:359.512146 total_loss:0.068939 acc:0.155000\n",
      "[epoch 4][step 36200] logloss:0.066641 l2_regular:0.000612 rmse:487.282898 total_loss:0.067253 acc:0.180000\n",
      "[epoch 4][step 36300] logloss:0.050504 l2_regular:0.000612 rmse:366.982086 total_loss:0.051117 acc:0.189000\n",
      "[epoch 4][step 36400] logloss:0.062491 l2_regular:0.000611 rmse:329.207550 total_loss:0.063103 acc:0.163000\n",
      "[epoch 4][step 36500] logloss:0.055908 l2_regular:0.000611 rmse:376.181366 total_loss:0.056519 acc:0.338000\n",
      "[epoch 4][step 36600] logloss:0.060567 l2_regular:0.000610 rmse:522.244568 total_loss:0.061177 acc:0.167000\n",
      "[epoch 4][step 36700] logloss:0.055617 l2_regular:0.000610 rmse:601.475403 total_loss:0.056227 acc:0.345000\n",
      "[epoch 4][step 36800] logloss:0.054452 l2_regular:0.000611 rmse:403.963165 total_loss:0.055063 acc:0.261000\n",
      "[epoch 4][step 36900] logloss:0.055891 l2_regular:0.000611 rmse:340.207153 total_loss:0.056502 acc:0.341000\n",
      "[epoch 4][step 37000] logloss:0.062186 l2_regular:0.000611 rmse:520.942505 total_loss:0.062797 acc:0.221000\n",
      "[epoch 4][step 37100] logloss:0.055834 l2_regular:0.000610 rmse:562.201477 total_loss:0.056445 acc:0.227000\n",
      "[epoch 4][step 37200] logloss:0.063394 l2_regular:0.000611 rmse:454.796906 total_loss:0.064004 acc:0.173000\n",
      "[epoch 4][step 37300] logloss:0.059577 l2_regular:0.000610 rmse:369.834381 total_loss:0.060187 acc:0.218000\n",
      "[epoch 4][step 37400] logloss:0.061842 l2_regular:0.000610 rmse:527.489563 total_loss:0.062452 acc:0.230000\n",
      "[epoch 4][step 37500] logloss:0.067216 l2_regular:0.000610 rmse:416.019989 total_loss:0.067825 acc:0.231000\n",
      "[epoch 4][step 37600] logloss:0.066469 l2_regular:0.000610 rmse:380.236206 total_loss:0.067079 acc:0.196000\n",
      "[epoch 4][step 37700] logloss:0.065556 l2_regular:0.000610 rmse:364.383240 total_loss:0.066166 acc:0.271000\n",
      "[epoch 4][step 37800] logloss:0.065952 l2_regular:0.000610 rmse:407.363251 total_loss:0.066562 acc:0.157000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4][step 37900] logloss:0.052688 l2_regular:0.000610 rmse:446.694183 total_loss:0.053298 acc:0.320000\n",
      "[epoch 4][step 38000] logloss:0.067940 l2_regular:0.000610 rmse:558.470276 total_loss:0.068550 acc:0.235000\n",
      "[epoch 4][step 38100] logloss:0.063162 l2_regular:0.000609 rmse:340.977234 total_loss:0.063771 acc:0.192000\n",
      "[epoch 4][step 38200] logloss:0.056706 l2_regular:0.000609 rmse:328.598083 total_loss:0.057315 acc:0.223000\n",
      "[epoch 4][step 38300] logloss:0.063700 l2_regular:0.000609 rmse:445.765594 total_loss:0.064309 acc:0.156000\n",
      "[epoch 4][step 38400] logloss:0.064218 l2_regular:0.000609 rmse:417.112183 total_loss:0.064827 acc:0.205000\n",
      "[epoch 4][step 38500] logloss:0.053102 l2_regular:0.000609 rmse:505.523254 total_loss:0.053711 acc:0.275000\n",
      "[epoch 4][step 38600] logloss:0.050083 l2_regular:0.000610 rmse:395.679108 total_loss:0.050692 acc:0.241000\n",
      "[epoch 4][step 38700] logloss:0.060361 l2_regular:0.000610 rmse:533.690857 total_loss:0.060971 acc:0.232000\n",
      "[epoch 4][step 38800] logloss:0.059029 l2_regular:0.000610 rmse:355.449890 total_loss:0.059640 acc:0.259000\n",
      "[epoch 4][step 38900] logloss:0.057980 l2_regular:0.000610 rmse:827.079041 total_loss:0.058590 acc:0.281000\n",
      "[epoch 4][step 39000] logloss:0.066002 l2_regular:0.000610 rmse:591.647156 total_loss:0.066612 acc:0.211000\n",
      "[epoch 4][step 39100] logloss:0.065186 l2_regular:0.000610 rmse:332.399017 total_loss:0.065796 acc:0.363000\n",
      "[epoch 4][step 39200] logloss:0.069436 l2_regular:0.000609 rmse:445.509094 total_loss:0.070045 acc:0.162000\n",
      "[epoch 4][step 39300] logloss:0.052111 l2_regular:0.000609 rmse:377.869080 total_loss:0.052720 acc:0.265000\n",
      "[epoch 4][step 39400] logloss:0.060865 l2_regular:0.000609 rmse:372.083099 total_loss:0.061474 acc:0.167000\n",
      "[epoch 4][step 39500] logloss:0.059183 l2_regular:0.000609 rmse:430.589264 total_loss:0.059792 acc:0.243000\n",
      "[epoch 4][step 39600] logloss:0.065103 l2_regular:0.000610 rmse:581.655090 total_loss:0.065712 acc:0.144000\n",
      "[epoch 4][step 39700] logloss:0.054509 l2_regular:0.000609 rmse:412.150970 total_loss:0.055117 acc:0.252000\n",
      "[epoch 4][step 39800] logloss:0.067085 l2_regular:0.000609 rmse:459.765686 total_loss:0.067693 acc:0.254000\n",
      "[epoch 4][step 39900] logloss:0.059633 l2_regular:0.000609 rmse:463.273254 total_loss:0.060241 acc:0.249000\n",
      "[epoch 4][step 40000] logloss:0.057043 l2_regular:0.000609 rmse:405.944916 total_loss:0.057652 acc:0.274000\n",
      "[epoch 4][step 40100] logloss:0.069650 l2_regular:0.000608 rmse:424.733490 total_loss:0.070259 acc:0.151000\n",
      "[epoch 4][step 40200] logloss:0.063683 l2_regular:0.000609 rmse:423.491241 total_loss:0.064292 acc:0.164000\n",
      "[epoch 4][step 40300] logloss:0.062352 l2_regular:0.000609 rmse:369.550018 total_loss:0.062961 acc:0.244000\n",
      "[epoch 4][step 40400] logloss:0.066851 l2_regular:0.000609 rmse:348.952148 total_loss:0.067460 acc:0.184000\n",
      "[epoch 4][step 40500] logloss:0.062878 l2_regular:0.000609 rmse:420.654877 total_loss:0.063487 acc:0.334000\n",
      "[epoch 4][step 40600] logloss:0.058034 l2_regular:0.000609 rmse:436.573944 total_loss:0.058643 acc:0.266000\n",
      "[epoch 4][step 40700] logloss:0.053102 l2_regular:0.000609 rmse:451.206268 total_loss:0.053712 acc:0.165000\n",
      "[epoch 4][step 40800] logloss:0.066953 l2_regular:0.000609 rmse:497.305298 total_loss:0.067562 acc:0.302000\n",
      "[epoch 4][step 40900] logloss:0.067312 l2_regular:0.000609 rmse:575.888428 total_loss:0.067921 acc:0.207000\n",
      "[epoch 4][step 41000] logloss:0.066409 l2_regular:0.000609 rmse:515.853210 total_loss:0.067018 acc:0.197000\n",
      "[epoch 4][step 41100] logloss:0.052540 l2_regular:0.000609 rmse:421.393646 total_loss:0.053149 acc:0.273000\n",
      "[epoch 4][step 41200] logloss:0.059392 l2_regular:0.000609 rmse:570.547668 total_loss:0.060001 acc:0.274000\n",
      "[epoch 4][step 41300] logloss:0.060309 l2_regular:0.000608 rmse:449.230499 total_loss:0.060917 acc:0.212000\n",
      "[epoch 4][step 41400] logloss:0.055002 l2_regular:0.000608 rmse:404.766083 total_loss:0.055610 acc:0.293000\n",
      "[epoch 4][step 41500] logloss:0.059248 l2_regular:0.000608 rmse:414.404358 total_loss:0.059856 acc:0.174000\n",
      "[epoch 4][step 41600] logloss:0.065986 l2_regular:0.000608 rmse:663.609619 total_loss:0.066594 acc:0.192000\n",
      "[epoch 4][step 41700] logloss:0.059688 l2_regular:0.000608 rmse:359.643585 total_loss:0.060296 acc:0.241000\n",
      "--------------epoch 4 finished —> total batch:8351---------------\n",
      "[epoch 5][step 41800] logloss:0.065001 l2_regular:0.000608 rmse:326.850586 total_loss:0.065609 acc:0.181000\n",
      "[epoch 5][step 41900] logloss:0.060208 l2_regular:0.000608 rmse:393.727295 total_loss:0.060816 acc:0.189000\n",
      "[epoch 5][step 42000] logloss:0.057786 l2_regular:0.000608 rmse:489.322632 total_loss:0.058394 acc:0.265000\n",
      "[epoch 5][step 42100] logloss:0.059624 l2_regular:0.000608 rmse:500.186493 total_loss:0.060231 acc:0.242000\n",
      "[epoch 5][step 42200] logloss:0.053793 l2_regular:0.000608 rmse:462.410461 total_loss:0.054400 acc:0.305000\n",
      "[epoch 5][step 42300] logloss:0.050540 l2_regular:0.000608 rmse:439.879333 total_loss:0.051147 acc:0.175000\n",
      "[epoch 5][step 42400] logloss:0.067033 l2_regular:0.000608 rmse:487.523041 total_loss:0.067641 acc:0.200000\n",
      "[epoch 5][step 42500] logloss:0.066020 l2_regular:0.000608 rmse:377.844635 total_loss:0.066628 acc:0.202000\n",
      "[epoch 5][step 42600] logloss:0.065152 l2_regular:0.000608 rmse:433.928925 total_loss:0.065761 acc:0.270000\n",
      "[epoch 5][step 42700] logloss:0.069468 l2_regular:0.000608 rmse:420.526733 total_loss:0.070076 acc:0.179000\n",
      "[epoch 5][step 42800] logloss:0.060007 l2_regular:0.000608 rmse:439.362305 total_loss:0.060615 acc:0.273000\n",
      "[epoch 5][step 42900] logloss:0.053555 l2_regular:0.000608 rmse:364.704407 total_loss:0.054164 acc:0.314000\n",
      "[epoch 5][step 43000] logloss:0.049801 l2_regular:0.000609 rmse:526.679932 total_loss:0.050409 acc:0.237000\n",
      "[epoch 5][step 43100] logloss:0.067284 l2_regular:0.000608 rmse:386.104553 total_loss:0.067893 acc:0.179000\n",
      "[epoch 5][step 43200] logloss:0.063942 l2_regular:0.000608 rmse:531.057556 total_loss:0.064551 acc:0.248000\n",
      "[epoch 5][step 43300] logloss:0.061709 l2_regular:0.000608 rmse:370.268982 total_loss:0.062317 acc:0.247000\n",
      "[epoch 5][step 43400] logloss:0.046074 l2_regular:0.000608 rmse:569.409851 total_loss:0.046682 acc:0.381000\n",
      "[epoch 5][step 43500] logloss:0.065185 l2_regular:0.000609 rmse:567.181885 total_loss:0.065793 acc:0.270000\n",
      "[epoch 5][step 43600] logloss:0.061825 l2_regular:0.000609 rmse:444.684235 total_loss:0.062433 acc:0.178000\n",
      "[epoch 5][step 43700] logloss:0.052177 l2_regular:0.000609 rmse:380.752625 total_loss:0.052786 acc:0.156000\n",
      "[epoch 5][step 43800] logloss:0.056313 l2_regular:0.000609 rmse:468.597290 total_loss:0.056922 acc:0.349000\n",
      "[epoch 5][step 43900] logloss:0.067935 l2_regular:0.000608 rmse:447.425751 total_loss:0.068544 acc:0.176000\n",
      "[epoch 5][step 44000] logloss:0.062712 l2_regular:0.000608 rmse:427.720276 total_loss:0.063320 acc:0.210000\n",
      "[epoch 5][step 44100] logloss:0.055584 l2_regular:0.000608 rmse:314.133270 total_loss:0.056192 acc:0.218000\n",
      "[epoch 5][step 44200] logloss:0.066446 l2_regular:0.000608 rmse:440.824341 total_loss:0.067054 acc:0.253000\n",
      "[epoch 5][step 44300] logloss:0.053285 l2_regular:0.000608 rmse:404.303711 total_loss:0.053894 acc:0.403000\n",
      "[epoch 5][step 44400] logloss:0.060975 l2_regular:0.000608 rmse:503.766052 total_loss:0.061583 acc:0.170000\n",
      "[epoch 5][step 44500] logloss:0.057748 l2_regular:0.000608 rmse:522.973877 total_loss:0.058356 acc:0.236000\n",
      "[epoch 5][step 44600] logloss:0.058059 l2_regular:0.000608 rmse:490.656219 total_loss:0.058667 acc:0.313000\n",
      "[epoch 5][step 44700] logloss:0.060919 l2_regular:0.000608 rmse:493.019470 total_loss:0.061527 acc:0.277000\n",
      "[epoch 5][step 44800] logloss:0.065031 l2_regular:0.000608 rmse:450.576965 total_loss:0.065639 acc:0.269000\n",
      "[epoch 5][step 44900] logloss:0.056887 l2_regular:0.000608 rmse:446.052032 total_loss:0.057495 acc:0.296000\n",
      "[epoch 5][step 45000] logloss:0.053653 l2_regular:0.000608 rmse:505.563232 total_loss:0.054261 acc:0.299000\n",
      "[epoch 5][step 45100] logloss:0.061068 l2_regular:0.000608 rmse:563.037354 total_loss:0.061676 acc:0.265000\n",
      "[epoch 5][step 45200] logloss:0.067364 l2_regular:0.000608 rmse:322.100525 total_loss:0.067972 acc:0.271000\n",
      "[epoch 5][step 45300] logloss:0.071028 l2_regular:0.000608 rmse:608.616211 total_loss:0.071636 acc:0.167000\n",
      "[epoch 5][step 45400] logloss:0.064618 l2_regular:0.000608 rmse:401.260193 total_loss:0.065226 acc:0.200000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5][step 45500] logloss:0.062335 l2_regular:0.000608 rmse:546.443115 total_loss:0.062943 acc:0.211000\n",
      "[epoch 5][step 45600] logloss:0.052904 l2_regular:0.000608 rmse:467.633484 total_loss:0.053512 acc:0.294000\n",
      "[epoch 5][step 45700] logloss:0.062083 l2_regular:0.000608 rmse:495.297974 total_loss:0.062691 acc:0.278000\n",
      "[epoch 5][step 45800] logloss:0.054688 l2_regular:0.000608 rmse:942.002808 total_loss:0.055296 acc:0.268000\n",
      "[epoch 5][step 45900] logloss:0.058176 l2_regular:0.000608 rmse:549.833374 total_loss:0.058784 acc:0.260000\n",
      "[epoch 5][step 46000] logloss:0.063101 l2_regular:0.000608 rmse:464.497131 total_loss:0.063709 acc:0.169000\n",
      "[epoch 5][step 46100] logloss:0.066493 l2_regular:0.000608 rmse:516.244202 total_loss:0.067101 acc:0.226000\n",
      "[epoch 5][step 46200] logloss:0.057009 l2_regular:0.000608 rmse:460.242706 total_loss:0.057617 acc:0.259000\n",
      "[epoch 5][step 46300] logloss:0.057726 l2_regular:0.000608 rmse:453.091125 total_loss:0.058334 acc:0.277000\n",
      "[epoch 5][step 46400] logloss:0.062282 l2_regular:0.000608 rmse:679.268188 total_loss:0.062889 acc:0.325000\n",
      "[epoch 5][step 46500] logloss:0.054595 l2_regular:0.000608 rmse:439.114777 total_loss:0.055202 acc:0.216000\n",
      "[epoch 5][step 46600] logloss:0.065196 l2_regular:0.000608 rmse:498.276764 total_loss:0.065803 acc:0.285000\n",
      "[epoch 5][step 46700] logloss:0.063626 l2_regular:0.000608 rmse:501.772186 total_loss:0.064233 acc:0.233000\n",
      "[epoch 5][step 46800] logloss:0.057707 l2_regular:0.000608 rmse:454.644196 total_loss:0.058315 acc:0.225000\n",
      "[epoch 5][step 46900] logloss:0.056570 l2_regular:0.000608 rmse:495.546509 total_loss:0.057178 acc:0.252000\n",
      "[epoch 5][step 47000] logloss:0.059589 l2_regular:0.000608 rmse:476.181366 total_loss:0.060196 acc:0.217000\n",
      "[epoch 5][step 47100] logloss:0.057359 l2_regular:0.000608 rmse:634.580322 total_loss:0.057967 acc:0.202000\n",
      "[epoch 5][step 47200] logloss:0.067612 l2_regular:0.000608 rmse:506.515076 total_loss:0.068220 acc:0.264000\n",
      "[epoch 5][step 47300] logloss:0.060295 l2_regular:0.000608 rmse:585.135010 total_loss:0.060903 acc:0.178000\n",
      "[epoch 5][step 47400] logloss:0.068281 l2_regular:0.000608 rmse:429.859833 total_loss:0.068889 acc:0.192000\n",
      "[epoch 5][step 47500] logloss:0.056982 l2_regular:0.000608 rmse:445.170990 total_loss:0.057590 acc:0.268000\n",
      "[epoch 5][step 47600] logloss:0.060095 l2_regular:0.000608 rmse:632.303833 total_loss:0.060703 acc:0.183000\n",
      "[epoch 5][step 47700] logloss:0.055323 l2_regular:0.000608 rmse:521.796631 total_loss:0.055931 acc:0.265000\n",
      "[epoch 5][step 47800] logloss:0.065287 l2_regular:0.000608 rmse:401.576294 total_loss:0.065895 acc:0.168000\n",
      "[epoch 5][step 47900] logloss:0.055934 l2_regular:0.000608 rmse:401.291718 total_loss:0.056542 acc:0.357000\n",
      "[epoch 5][step 48000] logloss:0.056498 l2_regular:0.000608 rmse:392.446960 total_loss:0.057106 acc:0.232000\n",
      "[epoch 5][step 48100] logloss:0.057373 l2_regular:0.000608 rmse:459.276733 total_loss:0.057981 acc:0.307000\n",
      "[epoch 5][step 48200] logloss:0.059363 l2_regular:0.000608 rmse:465.695160 total_loss:0.059971 acc:0.268000\n",
      "[epoch 5][step 48300] logloss:0.056425 l2_regular:0.000608 rmse:429.385071 total_loss:0.057033 acc:0.163000\n",
      "[epoch 5][step 48400] logloss:0.061644 l2_regular:0.000608 rmse:496.411682 total_loss:0.062252 acc:0.200000\n",
      "[epoch 5][step 48500] logloss:0.067222 l2_regular:0.000608 rmse:482.093231 total_loss:0.067830 acc:0.220000\n",
      "[epoch 5][step 48600] logloss:0.063280 l2_regular:0.000608 rmse:438.192230 total_loss:0.063887 acc:0.159000\n",
      "[epoch 5][step 48700] logloss:0.058364 l2_regular:0.000608 rmse:483.713135 total_loss:0.058971 acc:0.210000\n",
      "[epoch 5][step 48800] logloss:0.054040 l2_regular:0.000608 rmse:413.220062 total_loss:0.054647 acc:0.275000\n",
      "[epoch 5][step 48900] logloss:0.057534 l2_regular:0.000608 rmse:514.683411 total_loss:0.058142 acc:0.297000\n",
      "[epoch 5][step 49000] logloss:0.060182 l2_regular:0.000608 rmse:534.225769 total_loss:0.060790 acc:0.329000\n",
      "[epoch 5][step 49100] logloss:0.054337 l2_regular:0.000608 rmse:407.756744 total_loss:0.054945 acc:0.180000\n",
      "[epoch 5][step 49200] logloss:0.060868 l2_regular:0.000608 rmse:652.491089 total_loss:0.061476 acc:0.274000\n",
      "[epoch 5][step 49300] logloss:0.060191 l2_regular:0.000608 rmse:378.286438 total_loss:0.060799 acc:0.230000\n",
      "[epoch 5][step 49400] logloss:0.067009 l2_regular:0.000608 rmse:502.761017 total_loss:0.067617 acc:0.151000\n",
      "[epoch 5][step 49500] logloss:0.054705 l2_regular:0.000608 rmse:581.168030 total_loss:0.055313 acc:0.161000\n",
      "[epoch 5][step 49600] logloss:0.059245 l2_regular:0.000608 rmse:516.541382 total_loss:0.059853 acc:0.385000\n",
      "[epoch 5][step 49700] logloss:0.066407 l2_regular:0.000608 rmse:560.317078 total_loss:0.067015 acc:0.192000\n",
      "[epoch 5][step 49800] logloss:0.049547 l2_regular:0.000608 rmse:534.931885 total_loss:0.050155 acc:0.273000\n",
      "[epoch 5][step 49900] logloss:0.053587 l2_regular:0.000608 rmse:447.224487 total_loss:0.054195 acc:0.272000\n",
      "[epoch 5][step 50000] logloss:0.063257 l2_regular:0.000608 rmse:443.242828 total_loss:0.063865 acc:0.226000\n",
      "[epoch 5][step 50100] logloss:0.066915 l2_regular:0.000608 rmse:402.308655 total_loss:0.067523 acc:0.156000\n",
      "--------------epoch 5 finished —> total batch:8351---------------\n",
      "[epoch 6][step 50200] logloss:0.051154 l2_regular:0.000608 rmse:515.345642 total_loss:0.051762 acc:0.286000\n",
      "[epoch 6][step 50300] logloss:0.060216 l2_regular:0.000608 rmse:697.570618 total_loss:0.060823 acc:0.276000\n",
      "[epoch 6][step 50400] logloss:0.053194 l2_regular:0.000608 rmse:398.733551 total_loss:0.053802 acc:0.273000\n",
      "[epoch 6][step 50500] logloss:0.053595 l2_regular:0.000608 rmse:430.054535 total_loss:0.054203 acc:0.334000\n",
      "[epoch 6][step 50600] logloss:0.061917 l2_regular:0.000608 rmse:500.649689 total_loss:0.062524 acc:0.196000\n",
      "[epoch 6][step 50700] logloss:0.059342 l2_regular:0.000608 rmse:428.471039 total_loss:0.059949 acc:0.245000\n",
      "[epoch 6][step 50800] logloss:0.061239 l2_regular:0.000608 rmse:432.154480 total_loss:0.061847 acc:0.228000\n",
      "[epoch 6][step 50900] logloss:0.072581 l2_regular:0.000608 rmse:761.147034 total_loss:0.073189 acc:0.210000\n",
      "[epoch 6][step 51000] logloss:0.068334 l2_regular:0.000608 rmse:583.619019 total_loss:0.068942 acc:0.227000\n",
      "[epoch 6][step 51100] logloss:0.058630 l2_regular:0.000608 rmse:439.642975 total_loss:0.059238 acc:0.237000\n",
      "[epoch 6][step 51200] logloss:0.067097 l2_regular:0.000608 rmse:447.297699 total_loss:0.067705 acc:0.255000\n",
      "[epoch 6][step 51300] logloss:0.070190 l2_regular:0.000608 rmse:513.216614 total_loss:0.070798 acc:0.180000\n",
      "[epoch 6][step 51400] logloss:0.066920 l2_regular:0.000608 rmse:380.081848 total_loss:0.067528 acc:0.316000\n",
      "[epoch 6][step 51500] logloss:0.056545 l2_regular:0.000608 rmse:473.315033 total_loss:0.057153 acc:0.171000\n",
      "[epoch 6][step 51600] logloss:0.061993 l2_regular:0.000608 rmse:401.938110 total_loss:0.062601 acc:0.233000\n",
      "[epoch 6][step 51700] logloss:0.050057 l2_regular:0.000608 rmse:470.405182 total_loss:0.050664 acc:0.243000\n",
      "[epoch 6][step 51800] logloss:0.053892 l2_regular:0.000608 rmse:444.366180 total_loss:0.054500 acc:0.217000\n",
      "[epoch 6][step 51900] logloss:0.064286 l2_regular:0.000608 rmse:496.368805 total_loss:0.064894 acc:0.259000\n",
      "[epoch 6][step 52000] logloss:0.065127 l2_regular:0.000608 rmse:492.549683 total_loss:0.065734 acc:0.208000\n",
      "[epoch 6][step 52100] logloss:0.057091 l2_regular:0.000608 rmse:551.905640 total_loss:0.057699 acc:0.213000\n",
      "[epoch 6][step 52200] logloss:0.057957 l2_regular:0.000608 rmse:677.915833 total_loss:0.058565 acc:0.301000\n",
      "[epoch 6][step 52300] logloss:0.068012 l2_regular:0.000608 rmse:770.479431 total_loss:0.068620 acc:0.167000\n",
      "[epoch 6][step 52400] logloss:0.059059 l2_regular:0.000608 rmse:452.829590 total_loss:0.059667 acc:0.226000\n",
      "[epoch 6][step 52500] logloss:0.070042 l2_regular:0.000608 rmse:812.950378 total_loss:0.070650 acc:0.285000\n",
      "[epoch 6][step 52600] logloss:0.066617 l2_regular:0.000608 rmse:441.048828 total_loss:0.067225 acc:0.297000\n",
      "[epoch 6][step 52700] logloss:0.064012 l2_regular:0.000608 rmse:390.706024 total_loss:0.064620 acc:0.229000\n",
      "[epoch 6][step 52800] logloss:0.059718 l2_regular:0.000608 rmse:533.197571 total_loss:0.060326 acc:0.308000\n",
      "[epoch 6][step 52900] logloss:0.063782 l2_regular:0.000608 rmse:616.348633 total_loss:0.064390 acc:0.229000\n",
      "[epoch 6][step 53000] logloss:0.058357 l2_regular:0.000608 rmse:583.460876 total_loss:0.058965 acc:0.329000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6][step 53100] logloss:0.055564 l2_regular:0.000608 rmse:431.827271 total_loss:0.056172 acc:0.198000\n",
      "[epoch 6][step 53200] logloss:0.060115 l2_regular:0.000608 rmse:453.515259 total_loss:0.060723 acc:0.265000\n",
      "[epoch 6][step 53300] logloss:0.057780 l2_regular:0.000608 rmse:467.001892 total_loss:0.058388 acc:0.276000\n",
      "[epoch 6][step 53400] logloss:0.058660 l2_regular:0.000608 rmse:378.534790 total_loss:0.059267 acc:0.209000\n",
      "[epoch 6][step 53500] logloss:0.065193 l2_regular:0.000608 rmse:574.566833 total_loss:0.065801 acc:0.165000\n",
      "[epoch 6][step 53600] logloss:0.063359 l2_regular:0.000608 rmse:430.461121 total_loss:0.063967 acc:0.197000\n",
      "[epoch 6][step 53700] logloss:0.053196 l2_regular:0.000608 rmse:616.009460 total_loss:0.053804 acc:0.287000\n",
      "[epoch 6][step 53800] logloss:0.060798 l2_regular:0.000608 rmse:609.387634 total_loss:0.061406 acc:0.211000\n",
      "[epoch 6][step 53900] logloss:0.060590 l2_regular:0.000608 rmse:427.972443 total_loss:0.061198 acc:0.203000\n",
      "[epoch 6][step 54000] logloss:0.049670 l2_regular:0.000608 rmse:481.350311 total_loss:0.050278 acc:0.248000\n",
      "[epoch 6][step 54100] logloss:0.053666 l2_regular:0.000608 rmse:413.240479 total_loss:0.054274 acc:0.166000\n",
      "[epoch 6][step 54200] logloss:0.061671 l2_regular:0.000608 rmse:532.015808 total_loss:0.062279 acc:0.215000\n",
      "[epoch 6][step 54300] logloss:0.053038 l2_regular:0.000608 rmse:403.896637 total_loss:0.053646 acc:0.255000\n",
      "[epoch 6][step 54400] logloss:0.066475 l2_regular:0.000608 rmse:469.014252 total_loss:0.067083 acc:0.226000\n",
      "[epoch 6][step 54500] logloss:0.055236 l2_regular:0.000608 rmse:622.870667 total_loss:0.055844 acc:0.226000\n",
      "[epoch 6][step 54600] logloss:0.057886 l2_regular:0.000608 rmse:392.410950 total_loss:0.058494 acc:0.257000\n",
      "[epoch 6][step 54700] logloss:0.067860 l2_regular:0.000608 rmse:523.083130 total_loss:0.068468 acc:0.275000\n",
      "[epoch 6][step 54800] logloss:0.057109 l2_regular:0.000608 rmse:477.283997 total_loss:0.057717 acc:0.263000\n",
      "[epoch 6][step 54900] logloss:0.052631 l2_regular:0.000608 rmse:593.190247 total_loss:0.053239 acc:0.281000\n",
      "[epoch 6][step 55000] logloss:0.059204 l2_regular:0.000608 rmse:434.311737 total_loss:0.059812 acc:0.314000\n",
      "[epoch 6][step 55100] logloss:0.066690 l2_regular:0.000608 rmse:454.659760 total_loss:0.067298 acc:0.197000\n",
      "[epoch 6][step 55200] logloss:0.062332 l2_regular:0.000608 rmse:346.032196 total_loss:0.062940 acc:0.244000\n",
      "[epoch 6][step 55300] logloss:0.061865 l2_regular:0.000608 rmse:523.372192 total_loss:0.062473 acc:0.325000\n",
      "[epoch 6][step 55400] logloss:0.060474 l2_regular:0.000608 rmse:488.234161 total_loss:0.061081 acc:0.205000\n",
      "[epoch 6][step 55500] logloss:0.053258 l2_regular:0.000608 rmse:397.032776 total_loss:0.053866 acc:0.256000\n",
      "[epoch 6][step 55600] logloss:0.061127 l2_regular:0.000608 rmse:456.906067 total_loss:0.061735 acc:0.232000\n",
      "[epoch 6][step 55700] logloss:0.061732 l2_regular:0.000608 rmse:439.054047 total_loss:0.062340 acc:0.207000\n",
      "[epoch 6][step 55800] logloss:0.061280 l2_regular:0.000608 rmse:698.759216 total_loss:0.061887 acc:0.238000\n",
      "[epoch 6][step 55900] logloss:0.053187 l2_regular:0.000608 rmse:593.232300 total_loss:0.053795 acc:0.311000\n",
      "[epoch 6][step 56000] logloss:0.060633 l2_regular:0.000608 rmse:445.874115 total_loss:0.061241 acc:0.205000\n",
      "[epoch 6][step 56100] logloss:0.062562 l2_regular:0.000608 rmse:476.447540 total_loss:0.063170 acc:0.270000\n",
      "[epoch 6][step 56200] logloss:0.062502 l2_regular:0.000608 rmse:417.772614 total_loss:0.063110 acc:0.232000\n",
      "[epoch 6][step 56300] logloss:0.061485 l2_regular:0.000608 rmse:599.678284 total_loss:0.062093 acc:0.225000\n",
      "[epoch 6][step 56400] logloss:0.060048 l2_regular:0.000608 rmse:488.637299 total_loss:0.060656 acc:0.354000\n",
      "[epoch 6][step 56500] logloss:0.058364 l2_regular:0.000608 rmse:364.467316 total_loss:0.058972 acc:0.280000\n",
      "[epoch 6][step 56600] logloss:0.058867 l2_regular:0.000608 rmse:536.596985 total_loss:0.059474 acc:0.228000\n",
      "[epoch 6][step 56700] logloss:0.061280 l2_regular:0.000608 rmse:568.490112 total_loss:0.061887 acc:0.277000\n",
      "[epoch 6][step 56800] logloss:0.063922 l2_regular:0.000608 rmse:549.527039 total_loss:0.064530 acc:0.282000\n",
      "[epoch 6][step 56900] logloss:0.062488 l2_regular:0.000608 rmse:411.979187 total_loss:0.063096 acc:0.192000\n",
      "[epoch 6][step 57000] logloss:0.056284 l2_regular:0.000608 rmse:379.221771 total_loss:0.056892 acc:0.241000\n",
      "[epoch 6][step 57100] logloss:0.055448 l2_regular:0.000608 rmse:498.609161 total_loss:0.056056 acc:0.267000\n",
      "[epoch 6][step 57200] logloss:0.061239 l2_regular:0.000608 rmse:519.882324 total_loss:0.061847 acc:0.154000\n",
      "[epoch 6][step 57300] logloss:0.054480 l2_regular:0.000608 rmse:403.388611 total_loss:0.055088 acc:0.368000\n",
      "[epoch 6][step 57400] logloss:0.061249 l2_regular:0.000608 rmse:405.784210 total_loss:0.061857 acc:0.286000\n",
      "[epoch 6][step 57500] logloss:0.065798 l2_regular:0.000608 rmse:472.257507 total_loss:0.066406 acc:0.217000\n",
      "[epoch 6][step 57600] logloss:0.056806 l2_regular:0.000608 rmse:421.152618 total_loss:0.057413 acc:0.287000\n",
      "[epoch 6][step 57700] logloss:0.062304 l2_regular:0.000608 rmse:535.652222 total_loss:0.062912 acc:0.224000\n",
      "[epoch 6][step 57800] logloss:0.046559 l2_regular:0.000608 rmse:381.529327 total_loss:0.047166 acc:0.439000\n",
      "[epoch 6][step 57900] logloss:0.071086 l2_regular:0.000608 rmse:530.724915 total_loss:0.071694 acc:0.155000\n",
      "[epoch 6][step 58000] logloss:0.056494 l2_regular:0.000608 rmse:431.049316 total_loss:0.057102 acc:0.341000\n",
      "[epoch 6][step 58100] logloss:0.060629 l2_regular:0.000608 rmse:423.948700 total_loss:0.061237 acc:0.231000\n",
      "[epoch 6][step 58200] logloss:0.059473 l2_regular:0.000608 rmse:426.484009 total_loss:0.060081 acc:0.261000\n",
      "[epoch 6][step 58300] logloss:0.057502 l2_regular:0.000608 rmse:735.264282 total_loss:0.058110 acc:0.211000\n",
      "[epoch 6][step 58400] logloss:0.066630 l2_regular:0.000608 rmse:369.468353 total_loss:0.067238 acc:0.205000\n",
      "--------------epoch 6 finished —> total batch:8351---------------\n",
      "[epoch 7][step 58500] logloss:0.059673 l2_regular:0.000608 rmse:330.254150 total_loss:0.060281 acc:0.234000\n",
      "[epoch 7][step 58600] logloss:0.053349 l2_regular:0.000608 rmse:414.660828 total_loss:0.053956 acc:0.265000\n",
      "[epoch 7][step 58700] logloss:0.059662 l2_regular:0.000608 rmse:508.151123 total_loss:0.060270 acc:0.297000\n",
      "[epoch 7][step 58800] logloss:0.059643 l2_regular:0.000608 rmse:429.506226 total_loss:0.060251 acc:0.223000\n",
      "[epoch 7][step 58900] logloss:0.059174 l2_regular:0.000608 rmse:497.013641 total_loss:0.059782 acc:0.181000\n",
      "[epoch 7][step 59000] logloss:0.065067 l2_regular:0.000608 rmse:342.835571 total_loss:0.065675 acc:0.238000\n",
      "[epoch 7][step 59100] logloss:0.056203 l2_regular:0.000608 rmse:485.378418 total_loss:0.056811 acc:0.265000\n",
      "[epoch 7][step 59200] logloss:0.062954 l2_regular:0.000608 rmse:397.175934 total_loss:0.063562 acc:0.305000\n",
      "[epoch 7][step 59300] logloss:0.056794 l2_regular:0.000608 rmse:450.916962 total_loss:0.057402 acc:0.343000\n",
      "[epoch 7][step 59400] logloss:0.055576 l2_regular:0.000608 rmse:707.781250 total_loss:0.056183 acc:0.335000\n",
      "[epoch 7][step 59500] logloss:0.051858 l2_regular:0.000608 rmse:475.512878 total_loss:0.052466 acc:0.402000\n",
      "[epoch 7][step 59600] logloss:0.053631 l2_regular:0.000608 rmse:386.242798 total_loss:0.054238 acc:0.230000\n",
      "[epoch 7][step 59700] logloss:0.054520 l2_regular:0.000608 rmse:400.487640 total_loss:0.055127 acc:0.295000\n",
      "[epoch 7][step 59800] logloss:0.061011 l2_regular:0.000608 rmse:386.566406 total_loss:0.061619 acc:0.210000\n",
      "[epoch 7][step 59900] logloss:0.060827 l2_regular:0.000608 rmse:684.732361 total_loss:0.061435 acc:0.276000\n",
      "[epoch 7][step 60000] logloss:0.055598 l2_regular:0.000608 rmse:498.478088 total_loss:0.056205 acc:0.224000\n",
      "[epoch 7][step 60100] logloss:0.061420 l2_regular:0.000608 rmse:466.063934 total_loss:0.062027 acc:0.163000\n",
      "[epoch 7][step 60200] logloss:0.062558 l2_regular:0.000608 rmse:549.207947 total_loss:0.063166 acc:0.315000\n",
      "[epoch 7][step 60300] logloss:0.060251 l2_regular:0.000608 rmse:937.838928 total_loss:0.060859 acc:0.242000\n",
      "[epoch 7][step 60400] logloss:0.052618 l2_regular:0.000608 rmse:379.609100 total_loss:0.053226 acc:0.219000\n",
      "[epoch 7][step 60500] logloss:0.061185 l2_regular:0.000608 rmse:479.338440 total_loss:0.061793 acc:0.184000\n",
      "[epoch 7][step 60600] logloss:0.062797 l2_regular:0.000608 rmse:575.962158 total_loss:0.063405 acc:0.297000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7][step 60700] logloss:0.058765 l2_regular:0.000608 rmse:534.368164 total_loss:0.059373 acc:0.265000\n",
      "[epoch 7][step 60800] logloss:0.045570 l2_regular:0.000608 rmse:382.042175 total_loss:0.046178 acc:0.281000\n",
      "[epoch 7][step 60900] logloss:0.066431 l2_regular:0.000608 rmse:480.491638 total_loss:0.067038 acc:0.252000\n",
      "[epoch 7][step 61000] logloss:0.057764 l2_regular:0.000608 rmse:448.293823 total_loss:0.058372 acc:0.188000\n",
      "[epoch 7][step 61100] logloss:0.061244 l2_regular:0.000608 rmse:557.655334 total_loss:0.061851 acc:0.186000\n",
      "[epoch 7][step 61200] logloss:0.064051 l2_regular:0.000608 rmse:466.264069 total_loss:0.064659 acc:0.279000\n",
      "[epoch 7][step 61300] logloss:0.059028 l2_regular:0.000608 rmse:574.521973 total_loss:0.059636 acc:0.214000\n",
      "[epoch 7][step 61400] logloss:0.057728 l2_regular:0.000608 rmse:481.857971 total_loss:0.058335 acc:0.194000\n",
      "[epoch 7][step 61500] logloss:0.058294 l2_regular:0.000608 rmse:447.072845 total_loss:0.058902 acc:0.292000\n",
      "[epoch 7][step 61600] logloss:0.061309 l2_regular:0.000608 rmse:506.071289 total_loss:0.061917 acc:0.300000\n",
      "[epoch 7][step 61700] logloss:0.054900 l2_regular:0.000608 rmse:432.398224 total_loss:0.055508 acc:0.337000\n",
      "[epoch 7][step 61800] logloss:0.059622 l2_regular:0.000608 rmse:528.883972 total_loss:0.060230 acc:0.286000\n",
      "[epoch 7][step 61900] logloss:0.052390 l2_regular:0.000608 rmse:461.597321 total_loss:0.052998 acc:0.327000\n",
      "[epoch 7][step 62000] logloss:0.064418 l2_regular:0.000608 rmse:408.455719 total_loss:0.065026 acc:0.160000\n",
      "[epoch 7][step 62100] logloss:0.061022 l2_regular:0.000608 rmse:333.826324 total_loss:0.061630 acc:0.195000\n",
      "[epoch 7][step 62200] logloss:0.053947 l2_regular:0.000608 rmse:517.889404 total_loss:0.054555 acc:0.298000\n",
      "[epoch 7][step 62300] logloss:0.053342 l2_regular:0.000608 rmse:389.274536 total_loss:0.053950 acc:0.303000\n",
      "[epoch 7][step 62400] logloss:0.063662 l2_regular:0.000608 rmse:430.482666 total_loss:0.064270 acc:0.295000\n",
      "[epoch 7][step 62500] logloss:0.065885 l2_regular:0.000608 rmse:457.612091 total_loss:0.066493 acc:0.209000\n",
      "[epoch 7][step 62600] logloss:0.065528 l2_regular:0.000608 rmse:373.564667 total_loss:0.066136 acc:0.204000\n",
      "[epoch 7][step 62700] logloss:0.063812 l2_regular:0.000608 rmse:536.081360 total_loss:0.064420 acc:0.243000\n",
      "[epoch 7][step 62800] logloss:0.060323 l2_regular:0.000608 rmse:522.318970 total_loss:0.060931 acc:0.184000\n",
      "[epoch 7][step 62900] logloss:0.072932 l2_regular:0.000608 rmse:902.217102 total_loss:0.073540 acc:0.133000\n",
      "[epoch 7][step 63000] logloss:0.058597 l2_regular:0.000608 rmse:436.738525 total_loss:0.059205 acc:0.142000\n",
      "[epoch 7][step 63100] logloss:0.059200 l2_regular:0.000608 rmse:404.632874 total_loss:0.059808 acc:0.247000\n",
      "[epoch 7][step 63200] logloss:0.056996 l2_regular:0.000608 rmse:522.311096 total_loss:0.057604 acc:0.208000\n",
      "[epoch 7][step 63300] logloss:0.070210 l2_regular:0.000608 rmse:524.190552 total_loss:0.070818 acc:0.259000\n",
      "[epoch 7][step 63400] logloss:0.063677 l2_regular:0.000608 rmse:385.278656 total_loss:0.064285 acc:0.265000\n",
      "[epoch 7][step 63500] logloss:0.053161 l2_regular:0.000608 rmse:570.729187 total_loss:0.053769 acc:0.402000\n",
      "[epoch 7][step 63600] logloss:0.077187 l2_regular:0.000608 rmse:378.648499 total_loss:0.077795 acc:0.197000\n",
      "[epoch 7][step 63700] logloss:0.063909 l2_regular:0.000608 rmse:444.559723 total_loss:0.064517 acc:0.203000\n",
      "[epoch 7][step 63800] logloss:0.060292 l2_regular:0.000608 rmse:404.000641 total_loss:0.060900 acc:0.233000\n",
      "[epoch 7][step 63900] logloss:0.063768 l2_regular:0.000608 rmse:511.437592 total_loss:0.064375 acc:0.203000\n",
      "[epoch 7][step 64000] logloss:0.049461 l2_regular:0.000608 rmse:429.721985 total_loss:0.050069 acc:0.285000\n",
      "[epoch 7][step 64100] logloss:0.057410 l2_regular:0.000608 rmse:454.283722 total_loss:0.058018 acc:0.160000\n",
      "[epoch 7][step 64200] logloss:0.060565 l2_regular:0.000608 rmse:559.994141 total_loss:0.061173 acc:0.272000\n",
      "[epoch 7][step 64300] logloss:0.069381 l2_regular:0.000608 rmse:380.801270 total_loss:0.069989 acc:0.164000\n",
      "[epoch 7][step 64400] logloss:0.055953 l2_regular:0.000608 rmse:413.716248 total_loss:0.056561 acc:0.290000\n",
      "[epoch 7][step 64500] logloss:0.065119 l2_regular:0.000608 rmse:409.655273 total_loss:0.065727 acc:0.218000\n",
      "[epoch 7][step 64600] logloss:0.055230 l2_regular:0.000608 rmse:478.064484 total_loss:0.055837 acc:0.322000\n",
      "[epoch 7][step 64700] logloss:0.058677 l2_regular:0.000608 rmse:630.842468 total_loss:0.059285 acc:0.267000\n",
      "[epoch 7][step 64800] logloss:0.059323 l2_regular:0.000608 rmse:413.334259 total_loss:0.059931 acc:0.208000\n",
      "[epoch 7][step 64900] logloss:0.057838 l2_regular:0.000608 rmse:432.288574 total_loss:0.058446 acc:0.223000\n",
      "[epoch 7][step 65000] logloss:0.054156 l2_regular:0.000608 rmse:583.298218 total_loss:0.054764 acc:0.296000\n",
      "[epoch 7][step 65100] logloss:0.048874 l2_regular:0.000608 rmse:646.151733 total_loss:0.049482 acc:0.241000\n",
      "[epoch 7][step 65200] logloss:0.068701 l2_regular:0.000608 rmse:961.459900 total_loss:0.069309 acc:0.210000\n",
      "[epoch 7][step 65300] logloss:0.052962 l2_regular:0.000608 rmse:598.922058 total_loss:0.053570 acc:0.258000\n",
      "[epoch 7][step 65400] logloss:0.054065 l2_regular:0.000608 rmse:350.053497 total_loss:0.054673 acc:0.324000\n",
      "[epoch 7][step 65500] logloss:0.049316 l2_regular:0.000608 rmse:650.309448 total_loss:0.049924 acc:0.335000\n",
      "[epoch 7][step 65600] logloss:0.058150 l2_regular:0.000608 rmse:517.349426 total_loss:0.058758 acc:0.244000\n",
      "[epoch 7][step 65700] logloss:0.049364 l2_regular:0.000608 rmse:499.888489 total_loss:0.049972 acc:0.297000\n",
      "[epoch 7][step 65800] logloss:0.055629 l2_regular:0.000608 rmse:389.788116 total_loss:0.056237 acc:0.249000\n",
      "[epoch 7][step 65900] logloss:0.064991 l2_regular:0.000608 rmse:387.827515 total_loss:0.065599 acc:0.284000\n",
      "[epoch 7][step 66000] logloss:0.075561 l2_regular:0.000608 rmse:458.970154 total_loss:0.076168 acc:0.164000\n",
      "[epoch 7][step 66100] logloss:0.063394 l2_regular:0.000608 rmse:502.928314 total_loss:0.064002 acc:0.196000\n",
      "[epoch 7][step 66200] logloss:0.063429 l2_regular:0.000608 rmse:419.134888 total_loss:0.064037 acc:0.226000\n",
      "[epoch 7][step 66300] logloss:0.067160 l2_regular:0.000608 rmse:390.562469 total_loss:0.067768 acc:0.183000\n",
      "[epoch 7][step 66400] logloss:0.062746 l2_regular:0.000608 rmse:392.142914 total_loss:0.063354 acc:0.208000\n",
      "[epoch 7][step 66500] logloss:0.066627 l2_regular:0.000608 rmse:420.462311 total_loss:0.067234 acc:0.277000\n",
      "[epoch 7][step 66600] logloss:0.058201 l2_regular:0.000608 rmse:439.456757 total_loss:0.058809 acc:0.292000\n",
      "[epoch 7][step 66700] logloss:0.071827 l2_regular:0.000608 rmse:555.370361 total_loss:0.072434 acc:0.171000\n",
      "[epoch 7][step 66800] logloss:0.060374 l2_regular:0.000608 rmse:425.679565 total_loss:0.060982 acc:0.218000\n",
      "--------------epoch 7 finished —> total batch:8351---------------\n",
      "[epoch 8][step 66900] logloss:0.063965 l2_regular:0.000608 rmse:502.640076 total_loss:0.064573 acc:0.203000\n",
      "[epoch 8][step 67000] logloss:0.065193 l2_regular:0.000608 rmse:454.470825 total_loss:0.065801 acc:0.201000\n",
      "[epoch 8][step 67100] logloss:0.052182 l2_regular:0.000608 rmse:523.785461 total_loss:0.052790 acc:0.220000\n",
      "[epoch 8][step 67200] logloss:0.057935 l2_regular:0.000608 rmse:444.932495 total_loss:0.058543 acc:0.176000\n",
      "[epoch 8][step 67300] logloss:0.064889 l2_regular:0.000608 rmse:393.495209 total_loss:0.065497 acc:0.192000\n",
      "[epoch 8][step 67400] logloss:0.057338 l2_regular:0.000608 rmse:424.186066 total_loss:0.057946 acc:0.300000\n",
      "[epoch 8][step 67500] logloss:0.060960 l2_regular:0.000608 rmse:378.037933 total_loss:0.061568 acc:0.202000\n",
      "[epoch 8][step 67600] logloss:0.060306 l2_regular:0.000608 rmse:587.765869 total_loss:0.060913 acc:0.243000\n",
      "[epoch 8][step 67700] logloss:0.060753 l2_regular:0.000608 rmse:517.370789 total_loss:0.061361 acc:0.294000\n",
      "[epoch 8][step 67800] logloss:0.058446 l2_regular:0.000608 rmse:368.934906 total_loss:0.059054 acc:0.249000\n",
      "[epoch 8][step 67900] logloss:0.053785 l2_regular:0.000608 rmse:371.515686 total_loss:0.054393 acc:0.222000\n",
      "[epoch 8][step 68000] logloss:0.055737 l2_regular:0.000608 rmse:422.821686 total_loss:0.056345 acc:0.187000\n",
      "[epoch 8][step 68100] logloss:0.050454 l2_regular:0.000608 rmse:490.110992 total_loss:0.051061 acc:0.283000\n",
      "[epoch 8][step 68200] logloss:0.055145 l2_regular:0.000608 rmse:512.715149 total_loss:0.055752 acc:0.270000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8][step 68300] logloss:0.068626 l2_regular:0.000608 rmse:567.879944 total_loss:0.069234 acc:0.193000\n",
      "[epoch 8][step 68400] logloss:0.052674 l2_regular:0.000608 rmse:602.604858 total_loss:0.053282 acc:0.304000\n",
      "[epoch 8][step 68500] logloss:0.057727 l2_regular:0.000608 rmse:372.602142 total_loss:0.058335 acc:0.245000\n",
      "[epoch 8][step 68600] logloss:0.061406 l2_regular:0.000608 rmse:503.690643 total_loss:0.062013 acc:0.220000\n",
      "[epoch 8][step 68700] logloss:0.044955 l2_regular:0.000608 rmse:689.660706 total_loss:0.045563 acc:0.336000\n",
      "[epoch 8][step 68800] logloss:0.059805 l2_regular:0.000608 rmse:435.741425 total_loss:0.060413 acc:0.174000\n",
      "[epoch 8][step 68900] logloss:0.059269 l2_regular:0.000608 rmse:590.065186 total_loss:0.059876 acc:0.244000\n",
      "[epoch 8][step 69000] logloss:0.053929 l2_regular:0.000608 rmse:270.571106 total_loss:0.054537 acc:0.333000\n",
      "[epoch 8][step 69100] logloss:0.060076 l2_regular:0.000608 rmse:350.389984 total_loss:0.060684 acc:0.265000\n",
      "[epoch 8][step 69200] logloss:0.059227 l2_regular:0.000608 rmse:436.426819 total_loss:0.059835 acc:0.248000\n",
      "[epoch 8][step 69300] logloss:0.056912 l2_regular:0.000608 rmse:361.327271 total_loss:0.057520 acc:0.176000\n",
      "[epoch 8][step 69400] logloss:0.060545 l2_regular:0.000608 rmse:486.058746 total_loss:0.061153 acc:0.222000\n",
      "[epoch 8][step 69500] logloss:0.059606 l2_regular:0.000608 rmse:500.474548 total_loss:0.060214 acc:0.196000\n",
      "[epoch 8][step 69600] logloss:0.058061 l2_regular:0.000608 rmse:539.324951 total_loss:0.058669 acc:0.342000\n",
      "[epoch 8][step 69700] logloss:0.069139 l2_regular:0.000608 rmse:346.011078 total_loss:0.069747 acc:0.187000\n",
      "[epoch 8][step 69800] logloss:0.060833 l2_regular:0.000608 rmse:505.400452 total_loss:0.061440 acc:0.305000\n",
      "[epoch 8][step 69900] logloss:0.069890 l2_regular:0.000608 rmse:458.032166 total_loss:0.070498 acc:0.227000\n",
      "[epoch 8][step 70000] logloss:0.047806 l2_regular:0.000608 rmse:521.805969 total_loss:0.048414 acc:0.317000\n",
      "[epoch 8][step 70100] logloss:0.054617 l2_regular:0.000608 rmse:614.871399 total_loss:0.055225 acc:0.250000\n",
      "[epoch 8][step 70200] logloss:0.054991 l2_regular:0.000608 rmse:348.538483 total_loss:0.055599 acc:0.211000\n",
      "[epoch 8][step 70300] logloss:0.056399 l2_regular:0.000608 rmse:450.860046 total_loss:0.057007 acc:0.338000\n",
      "[epoch 8][step 70400] logloss:0.066692 l2_regular:0.000608 rmse:519.994080 total_loss:0.067299 acc:0.225000\n",
      "[epoch 8][step 70500] logloss:0.053851 l2_regular:0.000608 rmse:543.484131 total_loss:0.054459 acc:0.252000\n",
      "[epoch 8][step 70600] logloss:0.058689 l2_regular:0.000608 rmse:697.996887 total_loss:0.059297 acc:0.334000\n",
      "[epoch 8][step 70700] logloss:0.052431 l2_regular:0.000608 rmse:448.237732 total_loss:0.053038 acc:0.256000\n",
      "[epoch 8][step 70800] logloss:0.061452 l2_regular:0.000608 rmse:444.283234 total_loss:0.062060 acc:0.186000\n",
      "[epoch 8][step 70900] logloss:0.062018 l2_regular:0.000608 rmse:617.045105 total_loss:0.062625 acc:0.206000\n",
      "[epoch 8][step 71000] logloss:0.068267 l2_regular:0.000608 rmse:434.066498 total_loss:0.068874 acc:0.256000\n",
      "[epoch 8][step 71100] logloss:0.054952 l2_regular:0.000608 rmse:708.144653 total_loss:0.055560 acc:0.275000\n",
      "[epoch 8][step 71200] logloss:0.055022 l2_regular:0.000608 rmse:616.918884 total_loss:0.055629 acc:0.256000\n",
      "[epoch 8][step 71300] logloss:0.063935 l2_regular:0.000608 rmse:452.448212 total_loss:0.064543 acc:0.260000\n",
      "[epoch 8][step 71400] logloss:0.057398 l2_regular:0.000608 rmse:637.863525 total_loss:0.058006 acc:0.203000\n",
      "[epoch 8][step 71500] logloss:0.053054 l2_regular:0.000608 rmse:420.997803 total_loss:0.053662 acc:0.277000\n",
      "[epoch 8][step 71600] logloss:0.068838 l2_regular:0.000608 rmse:385.858490 total_loss:0.069445 acc:0.205000\n",
      "[epoch 8][step 71700] logloss:0.056140 l2_regular:0.000608 rmse:502.639954 total_loss:0.056748 acc:0.267000\n",
      "[epoch 8][step 71800] logloss:0.067538 l2_regular:0.000608 rmse:660.378357 total_loss:0.068146 acc:0.180000\n",
      "[epoch 8][step 71900] logloss:0.047414 l2_regular:0.000608 rmse:546.838501 total_loss:0.048022 acc:0.240000\n",
      "[epoch 8][step 72000] logloss:0.062239 l2_regular:0.000608 rmse:456.304108 total_loss:0.062847 acc:0.266000\n",
      "[epoch 8][step 72100] logloss:0.057221 l2_regular:0.000608 rmse:427.343048 total_loss:0.057828 acc:0.229000\n",
      "[epoch 8][step 72200] logloss:0.061921 l2_regular:0.000608 rmse:442.999817 total_loss:0.062529 acc:0.191000\n",
      "[epoch 8][step 72300] logloss:0.063374 l2_regular:0.000608 rmse:425.964752 total_loss:0.063981 acc:0.261000\n",
      "[epoch 8][step 72400] logloss:0.064879 l2_regular:0.000608 rmse:1120.038208 total_loss:0.065487 acc:0.268000\n",
      "[epoch 8][step 72500] logloss:0.074561 l2_regular:0.000608 rmse:492.854065 total_loss:0.075169 acc:0.159000\n",
      "[epoch 8][step 72600] logloss:0.054188 l2_regular:0.000608 rmse:461.885559 total_loss:0.054796 acc:0.202000\n",
      "[epoch 8][step 72700] logloss:0.059791 l2_regular:0.000608 rmse:401.640259 total_loss:0.060398 acc:0.200000\n",
      "[epoch 8][step 72800] logloss:0.068687 l2_regular:0.000608 rmse:342.891815 total_loss:0.069294 acc:0.172000\n",
      "[epoch 8][step 72900] logloss:0.061292 l2_regular:0.000608 rmse:450.279419 total_loss:0.061900 acc:0.126000\n",
      "[epoch 8][step 73000] logloss:0.058520 l2_regular:0.000608 rmse:454.321625 total_loss:0.059128 acc:0.242000\n",
      "[epoch 8][step 73100] logloss:0.064881 l2_regular:0.000608 rmse:456.940460 total_loss:0.065489 acc:0.126000\n",
      "[epoch 8][step 73200] logloss:0.067967 l2_regular:0.000608 rmse:491.902802 total_loss:0.068575 acc:0.135000\n",
      "[epoch 8][step 73300] logloss:0.066223 l2_regular:0.000608 rmse:499.751160 total_loss:0.066831 acc:0.279000\n",
      "[epoch 8][step 73400] logloss:0.055162 l2_regular:0.000608 rmse:601.198914 total_loss:0.055770 acc:0.269000\n",
      "[epoch 8][step 73500] logloss:0.053682 l2_regular:0.000608 rmse:414.828491 total_loss:0.054290 acc:0.279000\n",
      "[epoch 8][step 73600] logloss:0.052634 l2_regular:0.000608 rmse:408.086273 total_loss:0.053242 acc:0.309000\n",
      "[epoch 8][step 73700] logloss:0.069011 l2_regular:0.000608 rmse:423.969147 total_loss:0.069619 acc:0.201000\n",
      "[epoch 8][step 73800] logloss:0.056121 l2_regular:0.000608 rmse:507.845978 total_loss:0.056728 acc:0.274000\n",
      "[epoch 8][step 73900] logloss:0.058515 l2_regular:0.000608 rmse:416.276855 total_loss:0.059123 acc:0.287000\n",
      "[epoch 8][step 74000] logloss:0.056051 l2_regular:0.000608 rmse:593.093689 total_loss:0.056658 acc:0.274000\n",
      "[epoch 8][step 74100] logloss:0.061371 l2_regular:0.000608 rmse:418.390320 total_loss:0.061979 acc:0.211000\n",
      "[epoch 8][step 74200] logloss:0.065982 l2_regular:0.000608 rmse:436.167297 total_loss:0.066590 acc:0.270000\n",
      "[epoch 8][step 74300] logloss:0.067595 l2_regular:0.000608 rmse:376.958069 total_loss:0.068203 acc:0.226000\n",
      "[epoch 8][step 74400] logloss:0.061702 l2_regular:0.000608 rmse:495.797760 total_loss:0.062310 acc:0.162000\n",
      "[epoch 8][step 74500] logloss:0.054901 l2_regular:0.000608 rmse:487.426849 total_loss:0.055508 acc:0.218000\n",
      "[epoch 8][step 74600] logloss:0.061408 l2_regular:0.000608 rmse:377.823914 total_loss:0.062015 acc:0.290000\n",
      "[epoch 8][step 74700] logloss:0.067501 l2_regular:0.000608 rmse:556.225464 total_loss:0.068109 acc:0.232000\n",
      "[epoch 8][step 74800] logloss:0.058793 l2_regular:0.000608 rmse:497.990387 total_loss:0.059401 acc:0.234000\n",
      "[epoch 8][step 74900] logloss:0.063202 l2_regular:0.000608 rmse:450.975403 total_loss:0.063810 acc:0.224000\n",
      "[epoch 8][step 75000] logloss:0.064040 l2_regular:0.000608 rmse:430.324524 total_loss:0.064648 acc:0.234000\n",
      "[epoch 8][step 75100] logloss:0.056443 l2_regular:0.000608 rmse:367.513580 total_loss:0.057051 acc:0.237000\n",
      "--------------epoch 8 finished —> total batch:8351---------------\n",
      "[epoch 9][step 75200] logloss:0.064464 l2_regular:0.000608 rmse:446.115723 total_loss:0.065071 acc:0.289000\n",
      "[epoch 9][step 75300] logloss:0.051506 l2_regular:0.000608 rmse:487.040710 total_loss:0.052114 acc:0.282000\n",
      "[epoch 9][step 75400] logloss:0.061848 l2_regular:0.000608 rmse:725.839111 total_loss:0.062456 acc:0.207000\n",
      "[epoch 9][step 75500] logloss:0.057991 l2_regular:0.000608 rmse:484.692566 total_loss:0.058599 acc:0.247000\n",
      "[epoch 9][step 75600] logloss:0.058718 l2_regular:0.000608 rmse:395.955902 total_loss:0.059326 acc:0.230000\n",
      "[epoch 9][step 75700] logloss:0.054760 l2_regular:0.000608 rmse:518.018677 total_loss:0.055368 acc:0.273000\n",
      "[epoch 9][step 75800] logloss:0.053864 l2_regular:0.000608 rmse:606.347168 total_loss:0.054472 acc:0.237000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9][step 75900] logloss:0.059454 l2_regular:0.000608 rmse:295.510315 total_loss:0.060061 acc:0.222000\n",
      "[epoch 9][step 76000] logloss:0.059051 l2_regular:0.000608 rmse:445.147034 total_loss:0.059658 acc:0.310000\n",
      "[epoch 9][step 76100] logloss:0.061383 l2_regular:0.000608 rmse:564.930664 total_loss:0.061991 acc:0.326000\n",
      "[epoch 9][step 76200] logloss:0.066874 l2_regular:0.000608 rmse:408.972321 total_loss:0.067482 acc:0.189000\n",
      "[epoch 9][step 76300] logloss:0.053441 l2_regular:0.000608 rmse:424.072784 total_loss:0.054049 acc:0.258000\n",
      "[epoch 9][step 76400] logloss:0.059505 l2_regular:0.000608 rmse:449.040833 total_loss:0.060112 acc:0.278000\n",
      "[epoch 9][step 76500] logloss:0.059216 l2_regular:0.000608 rmse:558.729370 total_loss:0.059824 acc:0.213000\n",
      "[epoch 9][step 76600] logloss:0.065330 l2_regular:0.000608 rmse:439.271210 total_loss:0.065937 acc:0.170000\n",
      "[epoch 9][step 76700] logloss:0.055193 l2_regular:0.000608 rmse:523.729187 total_loss:0.055801 acc:0.267000\n",
      "[epoch 9][step 76800] logloss:0.072213 l2_regular:0.000608 rmse:387.962463 total_loss:0.072821 acc:0.251000\n",
      "[epoch 9][step 76900] logloss:0.054836 l2_regular:0.000608 rmse:526.701416 total_loss:0.055443 acc:0.199000\n",
      "[epoch 9][step 77000] logloss:0.054865 l2_regular:0.000608 rmse:396.844543 total_loss:0.055473 acc:0.286000\n",
      "[epoch 9][step 77100] logloss:0.068230 l2_regular:0.000608 rmse:480.180115 total_loss:0.068838 acc:0.233000\n",
      "[epoch 9][step 77200] logloss:0.059109 l2_regular:0.000608 rmse:476.792999 total_loss:0.059716 acc:0.316000\n",
      "[epoch 9][step 77300] logloss:0.069046 l2_regular:0.000608 rmse:493.322021 total_loss:0.069654 acc:0.252000\n",
      "[epoch 9][step 77400] logloss:0.059137 l2_regular:0.000608 rmse:515.212769 total_loss:0.059745 acc:0.235000\n",
      "[epoch 9][step 77500] logloss:0.063863 l2_regular:0.000608 rmse:595.619690 total_loss:0.064471 acc:0.229000\n",
      "[epoch 9][step 77600] logloss:0.071316 l2_regular:0.000608 rmse:340.410034 total_loss:0.071924 acc:0.141000\n",
      "[epoch 9][step 77700] logloss:0.057010 l2_regular:0.000608 rmse:353.619110 total_loss:0.057618 acc:0.218000\n",
      "[epoch 9][step 77800] logloss:0.057963 l2_regular:0.000608 rmse:433.888458 total_loss:0.058571 acc:0.300000\n",
      "[epoch 9][step 77900] logloss:0.063845 l2_regular:0.000608 rmse:475.905396 total_loss:0.064452 acc:0.196000\n",
      "[epoch 9][step 78000] logloss:0.061058 l2_regular:0.000608 rmse:666.385437 total_loss:0.061666 acc:0.221000\n",
      "[epoch 9][step 78100] logloss:0.062757 l2_regular:0.000608 rmse:370.309845 total_loss:0.063365 acc:0.221000\n",
      "[epoch 9][step 78200] logloss:0.069072 l2_regular:0.000608 rmse:461.552124 total_loss:0.069680 acc:0.204000\n",
      "[epoch 9][step 78300] logloss:0.067918 l2_regular:0.000608 rmse:458.135895 total_loss:0.068526 acc:0.185000\n",
      "[epoch 9][step 78400] logloss:0.065465 l2_regular:0.000608 rmse:495.967621 total_loss:0.066073 acc:0.245000\n",
      "[epoch 9][step 78500] logloss:0.057975 l2_regular:0.000608 rmse:444.656738 total_loss:0.058583 acc:0.340000\n",
      "[epoch 9][step 78600] logloss:0.069557 l2_regular:0.000608 rmse:562.988892 total_loss:0.070165 acc:0.182000\n",
      "[epoch 9][step 78700] logloss:0.065509 l2_regular:0.000608 rmse:551.923767 total_loss:0.066117 acc:0.169000\n",
      "[epoch 9][step 78800] logloss:0.054939 l2_regular:0.000608 rmse:492.026062 total_loss:0.055547 acc:0.297000\n",
      "[epoch 9][step 78900] logloss:0.064821 l2_regular:0.000608 rmse:442.803101 total_loss:0.065429 acc:0.276000\n",
      "[epoch 9][step 79000] logloss:0.052540 l2_regular:0.000608 rmse:437.812195 total_loss:0.053148 acc:0.358000\n",
      "[epoch 9][step 79100] logloss:0.063864 l2_regular:0.000608 rmse:512.289612 total_loss:0.064472 acc:0.253000\n",
      "[epoch 9][step 79200] logloss:0.066456 l2_regular:0.000608 rmse:320.999268 total_loss:0.067063 acc:0.213000\n",
      "[epoch 9][step 79300] logloss:0.059270 l2_regular:0.000608 rmse:409.772949 total_loss:0.059878 acc:0.219000\n",
      "[epoch 9][step 79400] logloss:0.049670 l2_regular:0.000608 rmse:369.649933 total_loss:0.050278 acc:0.354000\n",
      "[epoch 9][step 79500] logloss:0.057982 l2_regular:0.000608 rmse:381.760986 total_loss:0.058590 acc:0.224000\n",
      "[epoch 9][step 79600] logloss:0.052629 l2_regular:0.000608 rmse:538.017212 total_loss:0.053237 acc:0.306000\n",
      "[epoch 9][step 79700] logloss:0.058973 l2_regular:0.000608 rmse:595.734985 total_loss:0.059581 acc:0.256000\n",
      "[epoch 9][step 79800] logloss:0.057179 l2_regular:0.000608 rmse:439.782196 total_loss:0.057787 acc:0.277000\n",
      "[epoch 9][step 79900] logloss:0.064241 l2_regular:0.000608 rmse:800.582825 total_loss:0.064849 acc:0.283000\n",
      "[epoch 9][step 80000] logloss:0.061498 l2_regular:0.000608 rmse:629.706360 total_loss:0.062106 acc:0.369000\n",
      "[epoch 9][step 80100] logloss:0.069477 l2_regular:0.000608 rmse:452.555786 total_loss:0.070085 acc:0.122000\n",
      "[epoch 9][step 80200] logloss:0.055763 l2_regular:0.000608 rmse:480.726227 total_loss:0.056371 acc:0.305000\n",
      "[epoch 9][step 80300] logloss:0.052135 l2_regular:0.000608 rmse:586.542847 total_loss:0.052743 acc:0.267000\n",
      "[epoch 9][step 80400] logloss:0.050195 l2_regular:0.000608 rmse:463.532349 total_loss:0.050803 acc:0.316000\n",
      "[epoch 9][step 80500] logloss:0.059096 l2_regular:0.000608 rmse:677.966492 total_loss:0.059703 acc:0.271000\n",
      "[epoch 9][step 80600] logloss:0.064187 l2_regular:0.000608 rmse:661.769653 total_loss:0.064795 acc:0.265000\n",
      "[epoch 9][step 80700] logloss:0.059540 l2_regular:0.000608 rmse:399.434418 total_loss:0.060148 acc:0.303000\n",
      "[epoch 9][step 80800] logloss:0.057007 l2_regular:0.000608 rmse:419.475067 total_loss:0.057615 acc:0.294000\n",
      "[epoch 9][step 80900] logloss:0.060583 l2_regular:0.000608 rmse:524.990662 total_loss:0.061191 acc:0.258000\n",
      "[epoch 9][step 81000] logloss:0.055807 l2_regular:0.000608 rmse:377.981018 total_loss:0.056415 acc:0.308000\n",
      "[epoch 9][step 81100] logloss:0.051599 l2_regular:0.000608 rmse:611.768250 total_loss:0.052207 acc:0.350000\n",
      "[epoch 9][step 81200] logloss:0.063049 l2_regular:0.000608 rmse:684.655273 total_loss:0.063657 acc:0.160000\n",
      "[epoch 9][step 81300] logloss:0.061351 l2_regular:0.000608 rmse:628.696899 total_loss:0.061958 acc:0.294000\n",
      "[epoch 9][step 81400] logloss:0.068012 l2_regular:0.000608 rmse:546.192078 total_loss:0.068620 acc:0.321000\n",
      "[epoch 9][step 81500] logloss:0.058895 l2_regular:0.000608 rmse:485.019409 total_loss:0.059502 acc:0.234000\n",
      "[epoch 9][step 81600] logloss:0.062470 l2_regular:0.000608 rmse:385.568756 total_loss:0.063078 acc:0.209000\n",
      "[epoch 9][step 81700] logloss:0.048827 l2_regular:0.000608 rmse:478.506836 total_loss:0.049435 acc:0.257000\n",
      "[epoch 9][step 81800] logloss:0.060022 l2_regular:0.000608 rmse:350.398132 total_loss:0.060630 acc:0.322000\n",
      "[epoch 9][step 81900] logloss:0.054445 l2_regular:0.000608 rmse:435.940125 total_loss:0.055053 acc:0.337000\n",
      "[epoch 9][step 82000] logloss:0.057165 l2_regular:0.000608 rmse:594.438232 total_loss:0.057772 acc:0.313000\n",
      "[epoch 9][step 82100] logloss:0.053927 l2_regular:0.000608 rmse:493.711945 total_loss:0.054535 acc:0.241000\n",
      "[epoch 9][step 82200] logloss:0.058944 l2_regular:0.000608 rmse:523.505920 total_loss:0.059552 acc:0.296000\n",
      "[epoch 9][step 82300] logloss:0.061147 l2_regular:0.000608 rmse:384.054779 total_loss:0.061754 acc:0.220000\n",
      "[epoch 9][step 82400] logloss:0.054237 l2_regular:0.000608 rmse:489.780304 total_loss:0.054845 acc:0.389000\n",
      "[epoch 9][step 82500] logloss:0.052451 l2_regular:0.000608 rmse:425.729492 total_loss:0.053059 acc:0.246000\n",
      "[epoch 9][step 82600] logloss:0.057095 l2_regular:0.000608 rmse:422.450409 total_loss:0.057703 acc:0.284000\n",
      "[epoch 9][step 82700] logloss:0.053511 l2_regular:0.000608 rmse:722.102112 total_loss:0.054119 acc:0.234000\n",
      "[epoch 9][step 82800] logloss:0.056888 l2_regular:0.000608 rmse:576.642944 total_loss:0.057496 acc:0.160000\n",
      "[epoch 9][step 82900] logloss:0.057957 l2_regular:0.000608 rmse:590.821411 total_loss:0.058565 acc:0.316000\n",
      "[epoch 9][step 83000] logloss:0.063067 l2_regular:0.000608 rmse:626.489990 total_loss:0.063675 acc:0.248000\n",
      "[epoch 9][step 83100] logloss:0.057980 l2_regular:0.000608 rmse:619.712463 total_loss:0.058588 acc:0.333000\n",
      "[epoch 9][step 83200] logloss:0.056710 l2_regular:0.000608 rmse:550.451416 total_loss:0.057318 acc:0.248000\n",
      "[epoch 9][step 83300] logloss:0.061305 l2_regular:0.000608 rmse:452.389496 total_loss:0.061913 acc:0.152000\n",
      "[epoch 9][step 83400] logloss:0.070258 l2_regular:0.000608 rmse:482.544586 total_loss:0.070866 acc:0.158000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9][step 83500] logloss:0.054709 l2_regular:0.000608 rmse:418.048828 total_loss:0.055317 acc:0.273000\n",
      "--------------epoch 9 finished —> total batch:8351---------------\n",
      "[epoch 10][step 83600] logloss:0.058825 l2_regular:0.000608 rmse:325.027496 total_loss:0.059432 acc:0.319000\n",
      "[epoch 10][step 83700] logloss:0.055394 l2_regular:0.000608 rmse:371.213043 total_loss:0.056002 acc:0.224000\n",
      "[epoch 10][step 83800] logloss:0.069576 l2_regular:0.000608 rmse:531.396729 total_loss:0.070184 acc:0.187000\n",
      "[epoch 10][step 83900] logloss:0.062681 l2_regular:0.000608 rmse:394.557587 total_loss:0.063289 acc:0.262000\n",
      "[epoch 10][step 84000] logloss:0.058945 l2_regular:0.000608 rmse:433.788055 total_loss:0.059553 acc:0.159000\n",
      "[epoch 10][step 84100] logloss:0.060534 l2_regular:0.000608 rmse:480.839508 total_loss:0.061142 acc:0.253000\n",
      "[epoch 10][step 84200] logloss:0.061411 l2_regular:0.000608 rmse:741.168152 total_loss:0.062019 acc:0.241000\n",
      "[epoch 10][step 84300] logloss:0.053470 l2_regular:0.000608 rmse:531.810974 total_loss:0.054078 acc:0.266000\n",
      "[epoch 10][step 84400] logloss:0.071355 l2_regular:0.000608 rmse:744.584351 total_loss:0.071963 acc:0.114000\n",
      "[epoch 10][step 84500] logloss:0.050658 l2_regular:0.000608 rmse:668.014832 total_loss:0.051265 acc:0.290000\n",
      "[epoch 10][step 84600] logloss:0.056472 l2_regular:0.000608 rmse:459.123566 total_loss:0.057080 acc:0.250000\n",
      "[epoch 10][step 84700] logloss:0.054739 l2_regular:0.000608 rmse:494.417389 total_loss:0.055347 acc:0.227000\n",
      "[epoch 10][step 84800] logloss:0.050262 l2_regular:0.000608 rmse:595.825989 total_loss:0.050870 acc:0.281000\n",
      "[epoch 10][step 84900] logloss:0.065275 l2_regular:0.000608 rmse:527.113647 total_loss:0.065883 acc:0.242000\n",
      "[epoch 10][step 85000] logloss:0.059137 l2_regular:0.000608 rmse:566.259705 total_loss:0.059745 acc:0.197000\n",
      "[epoch 10][step 85100] logloss:0.085252 l2_regular:0.000608 rmse:447.867249 total_loss:0.085860 acc:0.234000\n",
      "[epoch 10][step 85200] logloss:0.052250 l2_regular:0.000608 rmse:527.924438 total_loss:0.052858 acc:0.241000\n",
      "[epoch 10][step 85300] logloss:0.054990 l2_regular:0.000608 rmse:495.314178 total_loss:0.055598 acc:0.275000\n",
      "[epoch 10][step 85400] logloss:0.063465 l2_regular:0.000608 rmse:494.895782 total_loss:0.064073 acc:0.276000\n",
      "[epoch 10][step 85500] logloss:0.056513 l2_regular:0.000608 rmse:495.276337 total_loss:0.057121 acc:0.231000\n",
      "[epoch 10][step 85600] logloss:0.062838 l2_regular:0.000608 rmse:368.176514 total_loss:0.063446 acc:0.189000\n",
      "[epoch 10][step 85700] logloss:0.058092 l2_regular:0.000608 rmse:468.786530 total_loss:0.058700 acc:0.324000\n",
      "[epoch 10][step 85800] logloss:0.053646 l2_regular:0.000608 rmse:342.105042 total_loss:0.054254 acc:0.236000\n",
      "[epoch 10][step 85900] logloss:0.051086 l2_regular:0.000608 rmse:374.283600 total_loss:0.051694 acc:0.353000\n",
      "[epoch 10][step 86000] logloss:0.059375 l2_regular:0.000608 rmse:454.593262 total_loss:0.059983 acc:0.228000\n",
      "[epoch 10][step 86100] logloss:0.058970 l2_regular:0.000608 rmse:579.260803 total_loss:0.059578 acc:0.314000\n",
      "[epoch 10][step 86200] logloss:0.063628 l2_regular:0.000608 rmse:410.293396 total_loss:0.064235 acc:0.193000\n",
      "[epoch 10][step 86300] logloss:0.067319 l2_regular:0.000608 rmse:466.938507 total_loss:0.067927 acc:0.233000\n",
      "[epoch 10][step 86400] logloss:0.065496 l2_regular:0.000608 rmse:357.308044 total_loss:0.066104 acc:0.190000\n",
      "[epoch 10][step 86500] logloss:0.060712 l2_regular:0.000608 rmse:461.910400 total_loss:0.061320 acc:0.312000\n",
      "[epoch 10][step 86600] logloss:0.067866 l2_regular:0.000608 rmse:447.073883 total_loss:0.068473 acc:0.283000\n",
      "[epoch 10][step 86700] logloss:0.058379 l2_regular:0.000608 rmse:477.796478 total_loss:0.058987 acc:0.248000\n",
      "[epoch 10][step 86800] logloss:0.065658 l2_regular:0.000608 rmse:587.416809 total_loss:0.066266 acc:0.189000\n",
      "[epoch 10][step 86900] logloss:0.058549 l2_regular:0.000608 rmse:387.403503 total_loss:0.059157 acc:0.338000\n",
      "[epoch 10][step 87000] logloss:0.062966 l2_regular:0.000608 rmse:503.964355 total_loss:0.063574 acc:0.224000\n",
      "[epoch 10][step 87100] logloss:0.066653 l2_regular:0.000608 rmse:528.949341 total_loss:0.067261 acc:0.210000\n",
      "[epoch 10][step 87200] logloss:0.063197 l2_regular:0.000608 rmse:492.058319 total_loss:0.063804 acc:0.261000\n",
      "[epoch 10][step 87300] logloss:0.054884 l2_regular:0.000608 rmse:418.298279 total_loss:0.055492 acc:0.209000\n",
      "[epoch 10][step 87400] logloss:0.062811 l2_regular:0.000608 rmse:486.855774 total_loss:0.063419 acc:0.167000\n",
      "[epoch 10][step 87500] logloss:0.074675 l2_regular:0.000608 rmse:723.131714 total_loss:0.075283 acc:0.185000\n",
      "[epoch 10][step 87600] logloss:0.057217 l2_regular:0.000608 rmse:501.790497 total_loss:0.057824 acc:0.307000\n",
      "[epoch 10][step 87700] logloss:0.060064 l2_regular:0.000608 rmse:497.744934 total_loss:0.060672 acc:0.193000\n",
      "[epoch 10][step 87800] logloss:0.063817 l2_regular:0.000608 rmse:464.813477 total_loss:0.064425 acc:0.175000\n",
      "[epoch 10][step 87900] logloss:0.058590 l2_regular:0.000608 rmse:427.686279 total_loss:0.059197 acc:0.220000\n",
      "[epoch 10][step 88000] logloss:0.059689 l2_regular:0.000608 rmse:557.766785 total_loss:0.060297 acc:0.192000\n",
      "[epoch 10][step 88100] logloss:0.058833 l2_regular:0.000608 rmse:614.609863 total_loss:0.059441 acc:0.223000\n",
      "[epoch 10][step 88200] logloss:0.060404 l2_regular:0.000608 rmse:370.049133 total_loss:0.061011 acc:0.345000\n",
      "[epoch 10][step 88300] logloss:0.063237 l2_regular:0.000608 rmse:445.960419 total_loss:0.063845 acc:0.226000\n",
      "[epoch 10][step 88400] logloss:0.076993 l2_regular:0.000608 rmse:344.423523 total_loss:0.077601 acc:0.285000\n",
      "[epoch 10][step 88500] logloss:0.073918 l2_regular:0.000608 rmse:407.184784 total_loss:0.074526 acc:0.204000\n",
      "[epoch 10][step 88600] logloss:0.069736 l2_regular:0.000608 rmse:453.309479 total_loss:0.070344 acc:0.246000\n",
      "[epoch 10][step 88700] logloss:0.051388 l2_regular:0.000608 rmse:426.865326 total_loss:0.051996 acc:0.281000\n",
      "[epoch 10][step 88800] logloss:0.062297 l2_regular:0.000608 rmse:702.122192 total_loss:0.062904 acc:0.177000\n",
      "[epoch 10][step 88900] logloss:0.052047 l2_regular:0.000608 rmse:428.872925 total_loss:0.052655 acc:0.280000\n",
      "[epoch 10][step 89000] logloss:0.060929 l2_regular:0.000608 rmse:585.164001 total_loss:0.061537 acc:0.166000\n",
      "[epoch 10][step 89100] logloss:0.057106 l2_regular:0.000608 rmse:446.843475 total_loss:0.057714 acc:0.247000\n",
      "[epoch 10][step 89200] logloss:0.055806 l2_regular:0.000608 rmse:482.728455 total_loss:0.056414 acc:0.288000\n",
      "[epoch 10][step 89300] logloss:0.061387 l2_regular:0.000608 rmse:471.390991 total_loss:0.061995 acc:0.137000\n",
      "[epoch 10][step 89400] logloss:0.069832 l2_regular:0.000608 rmse:476.036591 total_loss:0.070439 acc:0.182000\n",
      "[epoch 10][step 89500] logloss:0.061236 l2_regular:0.000608 rmse:548.934937 total_loss:0.061844 acc:0.314000\n",
      "[epoch 10][step 89600] logloss:0.069018 l2_regular:0.000608 rmse:417.446381 total_loss:0.069626 acc:0.168000\n",
      "[epoch 10][step 89700] logloss:0.055557 l2_regular:0.000608 rmse:574.026794 total_loss:0.056165 acc:0.277000\n",
      "[epoch 10][step 89800] logloss:0.052527 l2_regular:0.000608 rmse:608.444336 total_loss:0.053135 acc:0.334000\n",
      "[epoch 10][step 89900] logloss:0.056820 l2_regular:0.000608 rmse:471.660431 total_loss:0.057428 acc:0.321000\n",
      "[epoch 10][step 90000] logloss:0.063089 l2_regular:0.000608 rmse:471.166412 total_loss:0.063697 acc:0.279000\n",
      "[epoch 10][step 90100] logloss:0.072507 l2_regular:0.000608 rmse:427.474457 total_loss:0.073115 acc:0.203000\n",
      "[epoch 10][step 90200] logloss:0.057763 l2_regular:0.000608 rmse:646.185913 total_loss:0.058370 acc:0.217000\n",
      "[epoch 10][step 90300] logloss:0.062637 l2_regular:0.000608 rmse:481.052582 total_loss:0.063245 acc:0.247000\n",
      "[epoch 10][step 90400] logloss:0.070894 l2_regular:0.000608 rmse:435.376221 total_loss:0.071502 acc:0.230000\n",
      "[epoch 10][step 90500] logloss:0.058705 l2_regular:0.000608 rmse:712.967346 total_loss:0.059313 acc:0.222000\n",
      "[epoch 10][step 90600] logloss:0.061257 l2_regular:0.000608 rmse:337.542297 total_loss:0.061864 acc:0.202000\n",
      "[epoch 10][step 90700] logloss:0.053558 l2_regular:0.000608 rmse:549.828186 total_loss:0.054166 acc:0.231000\n",
      "[epoch 10][step 90800] logloss:0.055389 l2_regular:0.000608 rmse:368.725189 total_loss:0.055997 acc:0.203000\n",
      "[epoch 10][step 90900] logloss:0.065969 l2_regular:0.000608 rmse:462.160767 total_loss:0.066576 acc:0.160000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10][step 91000] logloss:0.064409 l2_regular:0.000608 rmse:412.704987 total_loss:0.065017 acc:0.250000\n",
      "[epoch 10][step 91100] logloss:0.070799 l2_regular:0.000608 rmse:448.150482 total_loss:0.071406 acc:0.208000\n",
      "[epoch 10][step 91200] logloss:0.062218 l2_regular:0.000608 rmse:373.451874 total_loss:0.062826 acc:0.227000\n",
      "[epoch 10][step 91300] logloss:0.050685 l2_regular:0.000608 rmse:491.028076 total_loss:0.051293 acc:0.213000\n",
      "[epoch 10][step 91400] logloss:0.054581 l2_regular:0.000608 rmse:397.654846 total_loss:0.055189 acc:0.299000\n",
      "[epoch 10][step 91500] logloss:0.066402 l2_regular:0.000608 rmse:485.135895 total_loss:0.067010 acc:0.255000\n",
      "[epoch 10][step 91600] logloss:0.069927 l2_regular:0.000608 rmse:431.442810 total_loss:0.070535 acc:0.229000\n",
      "[epoch 10][step 91700] logloss:0.052178 l2_regular:0.000608 rmse:584.449829 total_loss:0.052786 acc:0.345000\n",
      "[epoch 10][step 91800] logloss:0.072069 l2_regular:0.000608 rmse:390.958099 total_loss:0.072677 acc:0.186000\n",
      "--------------epoch 10 finished —> total batch:8351---------------\n",
      "[epoch 11][step 91900] logloss:0.068755 l2_regular:0.000608 rmse:402.694519 total_loss:0.069363 acc:0.286000\n",
      "[epoch 11][step 92000] logloss:0.055818 l2_regular:0.000608 rmse:469.120392 total_loss:0.056425 acc:0.206000\n",
      "[epoch 11][step 92100] logloss:0.056136 l2_regular:0.000608 rmse:320.491516 total_loss:0.056743 acc:0.385000\n",
      "[epoch 11][step 92200] logloss:0.060486 l2_regular:0.000608 rmse:469.158600 total_loss:0.061094 acc:0.232000\n",
      "[epoch 11][step 92300] logloss:0.066955 l2_regular:0.000608 rmse:366.489838 total_loss:0.067563 acc:0.217000\n",
      "[epoch 11][step 92400] logloss:0.065633 l2_regular:0.000608 rmse:375.694824 total_loss:0.066241 acc:0.129000\n",
      "[epoch 11][step 92500] logloss:0.059088 l2_regular:0.000608 rmse:552.012146 total_loss:0.059696 acc:0.269000\n",
      "[epoch 11][step 92600] logloss:0.071771 l2_regular:0.000608 rmse:553.022095 total_loss:0.072379 acc:0.166000\n",
      "[epoch 11][step 92700] logloss:0.053878 l2_regular:0.000608 rmse:437.357727 total_loss:0.054486 acc:0.239000\n",
      "[epoch 11][step 92800] logloss:0.062551 l2_regular:0.000608 rmse:535.012756 total_loss:0.063159 acc:0.304000\n",
      "[epoch 11][step 92900] logloss:0.051109 l2_regular:0.000608 rmse:395.309937 total_loss:0.051717 acc:0.266000\n",
      "[epoch 11][step 93000] logloss:0.060177 l2_regular:0.000608 rmse:464.098389 total_loss:0.060785 acc:0.176000\n",
      "[epoch 11][step 93100] logloss:0.054020 l2_regular:0.000608 rmse:473.054474 total_loss:0.054628 acc:0.266000\n",
      "[epoch 11][step 93200] logloss:0.050169 l2_regular:0.000608 rmse:493.665497 total_loss:0.050777 acc:0.258000\n",
      "[epoch 11][step 93300] logloss:0.064551 l2_regular:0.000608 rmse:500.117889 total_loss:0.065158 acc:0.208000\n",
      "[epoch 11][step 93400] logloss:0.063139 l2_regular:0.000608 rmse:426.255432 total_loss:0.063747 acc:0.195000\n",
      "[epoch 11][step 93500] logloss:0.075105 l2_regular:0.000608 rmse:635.114624 total_loss:0.075713 acc:0.186000\n",
      "[epoch 11][step 93600] logloss:0.051249 l2_regular:0.000608 rmse:388.794922 total_loss:0.051857 acc:0.268000\n",
      "[epoch 11][step 93700] logloss:0.058203 l2_regular:0.000608 rmse:544.041321 total_loss:0.058811 acc:0.233000\n",
      "[epoch 11][step 93800] logloss:0.052280 l2_regular:0.000608 rmse:510.247742 total_loss:0.052887 acc:0.156000\n",
      "[epoch 11][step 93900] logloss:0.080875 l2_regular:0.000608 rmse:468.903656 total_loss:0.081483 acc:0.214000\n",
      "[epoch 11][step 94000] logloss:0.061210 l2_regular:0.000608 rmse:399.166504 total_loss:0.061818 acc:0.162000\n",
      "[epoch 11][step 94100] logloss:0.062695 l2_regular:0.000608 rmse:624.823608 total_loss:0.063302 acc:0.295000\n",
      "[epoch 11][step 94200] logloss:0.071239 l2_regular:0.000608 rmse:447.756409 total_loss:0.071847 acc:0.224000\n",
      "[epoch 11][step 94300] logloss:0.051871 l2_regular:0.000608 rmse:413.039185 total_loss:0.052479 acc:0.267000\n",
      "[epoch 11][step 94400] logloss:0.060838 l2_regular:0.000608 rmse:414.519073 total_loss:0.061446 acc:0.240000\n",
      "[epoch 11][step 94500] logloss:0.059289 l2_regular:0.000608 rmse:420.906219 total_loss:0.059897 acc:0.233000\n",
      "[epoch 11][step 94600] logloss:0.062893 l2_regular:0.000608 rmse:403.546204 total_loss:0.063500 acc:0.232000\n",
      "[epoch 11][step 94700] logloss:0.069575 l2_regular:0.000608 rmse:419.728790 total_loss:0.070183 acc:0.239000\n",
      "[epoch 11][step 94800] logloss:0.056147 l2_regular:0.000608 rmse:467.074341 total_loss:0.056754 acc:0.374000\n",
      "[epoch 11][step 94900] logloss:0.058815 l2_regular:0.000608 rmse:431.728790 total_loss:0.059423 acc:0.252000\n",
      "[epoch 11][step 95000] logloss:0.072603 l2_regular:0.000608 rmse:421.335938 total_loss:0.073211 acc:0.184000\n",
      "[epoch 11][step 95100] logloss:0.060782 l2_regular:0.000608 rmse:574.865723 total_loss:0.061390 acc:0.260000\n",
      "[epoch 11][step 95200] logloss:0.046163 l2_regular:0.000608 rmse:475.842987 total_loss:0.046770 acc:0.410000\n",
      "[epoch 11][step 95300] logloss:0.057117 l2_regular:0.000608 rmse:485.849304 total_loss:0.057725 acc:0.271000\n",
      "[epoch 11][step 95400] logloss:0.056213 l2_regular:0.000608 rmse:411.622772 total_loss:0.056821 acc:0.296000\n",
      "[epoch 11][step 95500] logloss:0.067120 l2_regular:0.000608 rmse:536.173950 total_loss:0.067728 acc:0.237000\n",
      "[epoch 11][step 95600] logloss:0.055565 l2_regular:0.000608 rmse:422.691315 total_loss:0.056172 acc:0.204000\n",
      "[epoch 11][step 95700] logloss:0.054748 l2_regular:0.000608 rmse:355.656769 total_loss:0.055356 acc:0.209000\n",
      "[epoch 11][step 95800] logloss:0.060559 l2_regular:0.000608 rmse:440.601318 total_loss:0.061167 acc:0.227000\n",
      "[epoch 11][step 95900] logloss:0.066056 l2_regular:0.000608 rmse:604.179932 total_loss:0.066664 acc:0.243000\n",
      "[epoch 11][step 96000] logloss:0.066936 l2_regular:0.000608 rmse:370.559998 total_loss:0.067543 acc:0.263000\n",
      "[epoch 11][step 96100] logloss:0.058393 l2_regular:0.000608 rmse:408.758606 total_loss:0.059000 acc:0.273000\n",
      "[epoch 11][step 96200] logloss:0.059396 l2_regular:0.000608 rmse:667.894592 total_loss:0.060003 acc:0.225000\n",
      "[epoch 11][step 96300] logloss:0.057793 l2_regular:0.000608 rmse:451.549805 total_loss:0.058401 acc:0.283000\n",
      "[epoch 11][step 96400] logloss:0.070897 l2_regular:0.000608 rmse:427.249390 total_loss:0.071505 acc:0.161000\n",
      "[epoch 11][step 96500] logloss:0.066224 l2_regular:0.000608 rmse:481.382935 total_loss:0.066832 acc:0.199000\n",
      "[epoch 11][step 96600] logloss:0.058065 l2_regular:0.000608 rmse:398.944214 total_loss:0.058673 acc:0.216000\n",
      "[epoch 11][step 96700] logloss:0.063290 l2_regular:0.000608 rmse:489.976776 total_loss:0.063898 acc:0.320000\n",
      "[epoch 11][step 96800] logloss:0.058240 l2_regular:0.000608 rmse:339.195251 total_loss:0.058847 acc:0.183000\n",
      "[epoch 11][step 96900] logloss:0.053841 l2_regular:0.000608 rmse:532.378784 total_loss:0.054449 acc:0.243000\n",
      "[epoch 11][step 97000] logloss:0.073222 l2_regular:0.000608 rmse:433.819855 total_loss:0.073830 acc:0.163000\n",
      "[epoch 11][step 97100] logloss:0.055335 l2_regular:0.000608 rmse:410.723236 total_loss:0.055943 acc:0.285000\n",
      "[epoch 11][step 97200] logloss:0.067084 l2_regular:0.000608 rmse:561.997131 total_loss:0.067691 acc:0.230000\n",
      "[epoch 11][step 97300] logloss:0.065162 l2_regular:0.000608 rmse:326.076172 total_loss:0.065770 acc:0.205000\n",
      "[epoch 11][step 97400] logloss:0.072309 l2_regular:0.000608 rmse:320.440796 total_loss:0.072916 acc:0.308000\n",
      "[epoch 11][step 97500] logloss:0.061224 l2_regular:0.000608 rmse:565.258606 total_loss:0.061832 acc:0.248000\n",
      "[epoch 11][step 97600] logloss:0.055790 l2_regular:0.000608 rmse:593.668640 total_loss:0.056398 acc:0.230000\n",
      "[epoch 11][step 97700] logloss:0.061809 l2_regular:0.000608 rmse:471.303314 total_loss:0.062417 acc:0.173000\n",
      "[epoch 11][step 97800] logloss:0.068834 l2_regular:0.000608 rmse:587.131775 total_loss:0.069442 acc:0.166000\n",
      "[epoch 11][step 97900] logloss:0.067941 l2_regular:0.000608 rmse:326.367767 total_loss:0.068549 acc:0.146000\n",
      "[epoch 11][step 98000] logloss:0.068868 l2_regular:0.000608 rmse:548.463257 total_loss:0.069476 acc:0.215000\n",
      "[epoch 11][step 98100] logloss:0.070581 l2_regular:0.000608 rmse:371.547760 total_loss:0.071189 acc:0.223000\n",
      "[epoch 11][step 98200] logloss:0.065517 l2_regular:0.000608 rmse:854.115173 total_loss:0.066125 acc:0.183000\n",
      "[epoch 11][step 98300] logloss:0.061214 l2_regular:0.000608 rmse:509.612366 total_loss:0.061822 acc:0.163000\n",
      "[epoch 11][step 98400] logloss:0.058271 l2_regular:0.000608 rmse:368.147675 total_loss:0.058879 acc:0.263000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 11][step 98500] logloss:0.060874 l2_regular:0.000608 rmse:393.332855 total_loss:0.061482 acc:0.289000\n",
      "[epoch 11][step 98600] logloss:0.062430 l2_regular:0.000608 rmse:406.001556 total_loss:0.063037 acc:0.203000\n",
      "[epoch 11][step 98700] logloss:0.059173 l2_regular:0.000608 rmse:580.836182 total_loss:0.059781 acc:0.196000\n",
      "[epoch 11][step 98800] logloss:0.053426 l2_regular:0.000608 rmse:460.665680 total_loss:0.054034 acc:0.295000\n",
      "[epoch 11][step 98900] logloss:0.068202 l2_regular:0.000608 rmse:403.288208 total_loss:0.068810 acc:0.210000\n",
      "[epoch 11][step 99000] logloss:0.054427 l2_regular:0.000608 rmse:621.053040 total_loss:0.055035 acc:0.344000\n",
      "[epoch 11][step 99100] logloss:0.059669 l2_regular:0.000608 rmse:698.975037 total_loss:0.060276 acc:0.345000\n",
      "[epoch 11][step 99200] logloss:0.065259 l2_regular:0.000608 rmse:562.847839 total_loss:0.065867 acc:0.197000\n",
      "[epoch 11][step 99300] logloss:0.061635 l2_regular:0.000608 rmse:575.477356 total_loss:0.062243 acc:0.262000\n",
      "[epoch 11][step 99400] logloss:0.064560 l2_regular:0.000608 rmse:386.468872 total_loss:0.065168 acc:0.239000\n",
      "[epoch 11][step 99500] logloss:0.050971 l2_regular:0.000608 rmse:428.487488 total_loss:0.051579 acc:0.281000\n",
      "[epoch 11][step 99600] logloss:0.058083 l2_regular:0.000608 rmse:516.568604 total_loss:0.058691 acc:0.247000\n",
      "[epoch 11][step 99700] logloss:0.052210 l2_regular:0.000608 rmse:547.144531 total_loss:0.052818 acc:0.319000\n",
      "[epoch 11][step 99800] logloss:0.070266 l2_regular:0.000608 rmse:540.438110 total_loss:0.070873 acc:0.212000\n",
      "[epoch 11][step 99900] logloss:0.053807 l2_regular:0.000608 rmse:755.351074 total_loss:0.054414 acc:0.236000\n",
      "[epoch 11][step 100000] logloss:0.068344 l2_regular:0.000608 rmse:365.499023 total_loss:0.068952 acc:0.144000\n",
      "[epoch 11][step 100100] logloss:0.060137 l2_regular:0.000608 rmse:479.251556 total_loss:0.060745 acc:0.303000\n",
      "[epoch 11][step 100200] logloss:0.057697 l2_regular:0.000608 rmse:420.695923 total_loss:0.058305 acc:0.351000\n",
      "--------------epoch 11 finished —> total batch:8351---------------\n",
      "[epoch 12][step 100300] logloss:0.059936 l2_regular:0.000608 rmse:731.163330 total_loss:0.060544 acc:0.228000\n",
      "[epoch 12][step 100400] logloss:0.052214 l2_regular:0.000608 rmse:513.053955 total_loss:0.052822 acc:0.366000\n",
      "[epoch 12][step 100500] logloss:0.050925 l2_regular:0.000608 rmse:505.277374 total_loss:0.051533 acc:0.331000\n",
      "[epoch 12][step 100600] logloss:0.060773 l2_regular:0.000608 rmse:485.305511 total_loss:0.061381 acc:0.188000\n",
      "[epoch 12][step 100700] logloss:0.048849 l2_regular:0.000608 rmse:548.913513 total_loss:0.049456 acc:0.285000\n",
      "[epoch 12][step 100800] logloss:0.051840 l2_regular:0.000608 rmse:478.181519 total_loss:0.052448 acc:0.357000\n",
      "[epoch 12][step 100900] logloss:0.062405 l2_regular:0.000608 rmse:462.923004 total_loss:0.063013 acc:0.191000\n",
      "[epoch 12][step 101000] logloss:0.063647 l2_regular:0.000608 rmse:454.732513 total_loss:0.064255 acc:0.243000\n",
      "[epoch 12][step 101100] logloss:0.066393 l2_regular:0.000608 rmse:433.639404 total_loss:0.067000 acc:0.299000\n",
      "[epoch 12][step 101200] logloss:0.055050 l2_regular:0.000608 rmse:700.413940 total_loss:0.055657 acc:0.273000\n",
      "[epoch 12][step 101300] logloss:0.066101 l2_regular:0.000608 rmse:523.068054 total_loss:0.066708 acc:0.221000\n",
      "[epoch 12][step 101400] logloss:0.061465 l2_regular:0.000608 rmse:321.192017 total_loss:0.062073 acc:0.183000\n",
      "[epoch 12][step 101500] logloss:0.066882 l2_regular:0.000608 rmse:365.554474 total_loss:0.067490 acc:0.204000\n",
      "[epoch 12][step 101600] logloss:0.073469 l2_regular:0.000608 rmse:568.684692 total_loss:0.074077 acc:0.183000\n",
      "[epoch 12][step 101700] logloss:0.068732 l2_regular:0.000608 rmse:514.049683 total_loss:0.069340 acc:0.203000\n",
      "[epoch 12][step 101800] logloss:0.067809 l2_regular:0.000608 rmse:373.988434 total_loss:0.068416 acc:0.210000\n",
      "[epoch 12][step 101900] logloss:0.067494 l2_regular:0.000608 rmse:355.447571 total_loss:0.068102 acc:0.321000\n",
      "[epoch 12][step 102000] logloss:0.061411 l2_regular:0.000608 rmse:483.370941 total_loss:0.062018 acc:0.248000\n",
      "[epoch 12][step 102100] logloss:0.059502 l2_regular:0.000608 rmse:492.986053 total_loss:0.060109 acc:0.228000\n",
      "[epoch 12][step 102200] logloss:0.059839 l2_regular:0.000608 rmse:380.259705 total_loss:0.060447 acc:0.269000\n",
      "[epoch 12][step 102300] logloss:0.060404 l2_regular:0.000608 rmse:502.969482 total_loss:0.061012 acc:0.194000\n",
      "[epoch 12][step 102400] logloss:0.068569 l2_regular:0.000608 rmse:531.980713 total_loss:0.069177 acc:0.192000\n",
      "[epoch 12][step 102500] logloss:0.062029 l2_regular:0.000608 rmse:569.178955 total_loss:0.062636 acc:0.224000\n",
      "[epoch 12][step 102600] logloss:0.061807 l2_regular:0.000608 rmse:458.898712 total_loss:0.062415 acc:0.223000\n",
      "[epoch 12][step 102700] logloss:0.067962 l2_regular:0.000608 rmse:551.454773 total_loss:0.068570 acc:0.214000\n",
      "[epoch 12][step 102800] logloss:0.051669 l2_regular:0.000608 rmse:496.103668 total_loss:0.052277 acc:0.333000\n",
      "[epoch 12][step 102900] logloss:0.057767 l2_regular:0.000608 rmse:513.208557 total_loss:0.058375 acc:0.261000\n",
      "[epoch 12][step 103000] logloss:0.060964 l2_regular:0.000608 rmse:342.349030 total_loss:0.061572 acc:0.165000\n",
      "[epoch 12][step 103100] logloss:0.055561 l2_regular:0.000608 rmse:424.078644 total_loss:0.056169 acc:0.171000\n",
      "[epoch 12][step 103200] logloss:0.048206 l2_regular:0.000608 rmse:482.066772 total_loss:0.048814 acc:0.347000\n",
      "[epoch 12][step 103300] logloss:0.058611 l2_regular:0.000608 rmse:477.389679 total_loss:0.059219 acc:0.290000\n",
      "[epoch 12][step 103400] logloss:0.056578 l2_regular:0.000608 rmse:340.344330 total_loss:0.057186 acc:0.315000\n",
      "[epoch 12][step 103500] logloss:0.055608 l2_regular:0.000608 rmse:298.641876 total_loss:0.056216 acc:0.239000\n",
      "[epoch 12][step 103600] logloss:0.067240 l2_regular:0.000608 rmse:422.100647 total_loss:0.067848 acc:0.140000\n",
      "[epoch 12][step 103700] logloss:0.060844 l2_regular:0.000608 rmse:413.838806 total_loss:0.061451 acc:0.199000\n",
      "[epoch 12][step 103800] logloss:0.067815 l2_regular:0.000608 rmse:397.021637 total_loss:0.068423 acc:0.177000\n",
      "[epoch 12][step 103900] logloss:0.068673 l2_regular:0.000608 rmse:495.813019 total_loss:0.069281 acc:0.185000\n",
      "[epoch 12][step 104000] logloss:0.058542 l2_regular:0.000608 rmse:450.695007 total_loss:0.059149 acc:0.213000\n",
      "[epoch 12][step 104100] logloss:0.069331 l2_regular:0.000608 rmse:452.884003 total_loss:0.069939 acc:0.197000\n",
      "[epoch 12][step 104200] logloss:0.060846 l2_regular:0.000608 rmse:742.423340 total_loss:0.061454 acc:0.226000\n",
      "[epoch 12][step 104300] logloss:0.060105 l2_regular:0.000608 rmse:581.809875 total_loss:0.060713 acc:0.284000\n",
      "[epoch 12][step 104400] logloss:0.063221 l2_regular:0.000608 rmse:519.143127 total_loss:0.063829 acc:0.191000\n",
      "[epoch 12][step 104500] logloss:0.064800 l2_regular:0.000608 rmse:463.084900 total_loss:0.065408 acc:0.211000\n",
      "[epoch 12][step 104600] logloss:0.066382 l2_regular:0.000608 rmse:448.225098 total_loss:0.066990 acc:0.233000\n",
      "[epoch 12][step 104700] logloss:0.060710 l2_regular:0.000608 rmse:466.772827 total_loss:0.061317 acc:0.233000\n",
      "[epoch 12][step 104800] logloss:0.063428 l2_regular:0.000608 rmse:452.426147 total_loss:0.064036 acc:0.274000\n",
      "[epoch 12][step 104900] logloss:0.060316 l2_regular:0.000608 rmse:480.379242 total_loss:0.060924 acc:0.243000\n",
      "[epoch 12][step 105000] logloss:0.064221 l2_regular:0.000608 rmse:384.653442 total_loss:0.064828 acc:0.222000\n",
      "[epoch 12][step 105100] logloss:0.076575 l2_regular:0.000608 rmse:395.227844 total_loss:0.077183 acc:0.138000\n",
      "[epoch 12][step 105200] logloss:0.050052 l2_regular:0.000608 rmse:430.042725 total_loss:0.050660 acc:0.246000\n",
      "[epoch 12][step 105300] logloss:0.059024 l2_regular:0.000608 rmse:577.863098 total_loss:0.059632 acc:0.275000\n",
      "[epoch 12][step 105400] logloss:0.056842 l2_regular:0.000608 rmse:463.809113 total_loss:0.057449 acc:0.274000\n",
      "[epoch 12][step 105500] logloss:0.053027 l2_regular:0.000608 rmse:552.411743 total_loss:0.053635 acc:0.246000\n",
      "[epoch 12][step 105600] logloss:0.061475 l2_regular:0.000608 rmse:391.055634 total_loss:0.062083 acc:0.213000\n",
      "[epoch 12][step 105700] logloss:0.049330 l2_regular:0.000608 rmse:414.854034 total_loss:0.049938 acc:0.424000\n",
      "[epoch 12][step 105800] logloss:0.046985 l2_regular:0.000608 rmse:479.393158 total_loss:0.047593 acc:0.372000\n",
      "[epoch 12][step 105900] logloss:0.063931 l2_regular:0.000608 rmse:465.733704 total_loss:0.064539 acc:0.206000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 12][step 106000] logloss:0.056926 l2_regular:0.000608 rmse:318.276611 total_loss:0.057534 acc:0.267000\n",
      "[epoch 12][step 106100] logloss:0.069580 l2_regular:0.000608 rmse:576.065796 total_loss:0.070187 acc:0.137000\n",
      "[epoch 12][step 106200] logloss:0.050048 l2_regular:0.000608 rmse:626.622437 total_loss:0.050656 acc:0.333000\n",
      "[epoch 12][step 106300] logloss:0.060044 l2_regular:0.000608 rmse:420.626160 total_loss:0.060651 acc:0.239000\n",
      "[epoch 12][step 106400] logloss:0.066656 l2_regular:0.000608 rmse:470.218140 total_loss:0.067263 acc:0.296000\n",
      "[epoch 12][step 106500] logloss:0.061785 l2_regular:0.000608 rmse:467.778412 total_loss:0.062392 acc:0.227000\n",
      "[epoch 12][step 106600] logloss:0.060956 l2_regular:0.000608 rmse:561.718933 total_loss:0.061564 acc:0.197000\n",
      "[epoch 12][step 106700] logloss:0.064749 l2_regular:0.000608 rmse:393.870148 total_loss:0.065356 acc:0.203000\n",
      "[epoch 12][step 106800] logloss:0.062345 l2_regular:0.000608 rmse:522.302185 total_loss:0.062953 acc:0.272000\n",
      "[epoch 12][step 106900] logloss:0.062622 l2_regular:0.000608 rmse:527.853088 total_loss:0.063230 acc:0.257000\n",
      "[epoch 12][step 107000] logloss:0.053748 l2_regular:0.000608 rmse:462.683044 total_loss:0.054356 acc:0.234000\n",
      "[epoch 12][step 107100] logloss:0.057478 l2_regular:0.000608 rmse:511.121307 total_loss:0.058086 acc:0.219000\n",
      "[epoch 12][step 107200] logloss:0.065542 l2_regular:0.000608 rmse:476.432770 total_loss:0.066150 acc:0.163000\n",
      "[epoch 12][step 107300] logloss:0.075656 l2_regular:0.000608 rmse:835.618347 total_loss:0.076264 acc:0.107000\n",
      "[epoch 12][step 107400] logloss:0.071090 l2_regular:0.000608 rmse:361.147095 total_loss:0.071698 acc:0.265000\n",
      "[epoch 12][step 107500] logloss:0.053748 l2_regular:0.000608 rmse:442.654877 total_loss:0.054356 acc:0.224000\n",
      "[epoch 12][step 107600] logloss:0.065460 l2_regular:0.000608 rmse:356.493988 total_loss:0.066067 acc:0.219000\n",
      "[epoch 12][step 107700] logloss:0.065149 l2_regular:0.000608 rmse:467.829285 total_loss:0.065756 acc:0.184000\n",
      "[epoch 12][step 107800] logloss:0.070954 l2_regular:0.000608 rmse:526.921997 total_loss:0.071561 acc:0.348000\n",
      "[epoch 12][step 107900] logloss:0.063849 l2_regular:0.000608 rmse:292.881134 total_loss:0.064456 acc:0.185000\n",
      "[epoch 12][step 108000] logloss:0.049138 l2_regular:0.000608 rmse:450.213776 total_loss:0.049745 acc:0.279000\n",
      "[epoch 12][step 108100] logloss:0.074382 l2_regular:0.000608 rmse:447.027130 total_loss:0.074990 acc:0.150000\n",
      "[epoch 12][step 108200] logloss:0.065236 l2_regular:0.000608 rmse:425.942505 total_loss:0.065843 acc:0.240000\n",
      "[epoch 12][step 108300] logloss:0.070159 l2_regular:0.000608 rmse:569.152405 total_loss:0.070767 acc:0.291000\n",
      "[epoch 12][step 108400] logloss:0.056506 l2_regular:0.000608 rmse:460.228699 total_loss:0.057114 acc:0.340000\n",
      "[epoch 12][step 108500] logloss:0.072081 l2_regular:0.000608 rmse:614.880371 total_loss:0.072688 acc:0.214000\n",
      "--------------epoch 12 finished —> total batch:8351---------------\n",
      "[epoch 13][step 108600] logloss:0.061669 l2_regular:0.000608 rmse:453.123016 total_loss:0.062277 acc:0.299000\n",
      "[epoch 13][step 108700] logloss:0.076449 l2_regular:0.000608 rmse:461.784210 total_loss:0.077056 acc:0.128000\n",
      "[epoch 13][step 108800] logloss:0.056288 l2_regular:0.000608 rmse:387.062073 total_loss:0.056895 acc:0.281000\n",
      "[epoch 13][step 108900] logloss:0.059842 l2_regular:0.000608 rmse:379.466003 total_loss:0.060450 acc:0.239000\n",
      "[epoch 13][step 109000] logloss:0.058865 l2_regular:0.000608 rmse:594.262756 total_loss:0.059473 acc:0.185000\n",
      "[epoch 13][step 109100] logloss:0.048803 l2_regular:0.000608 rmse:363.845184 total_loss:0.049411 acc:0.302000\n",
      "[epoch 13][step 109200] logloss:0.073018 l2_regular:0.000608 rmse:656.939819 total_loss:0.073626 acc:0.202000\n",
      "[epoch 13][step 109300] logloss:0.066173 l2_regular:0.000608 rmse:402.457214 total_loss:0.066781 acc:0.239000\n",
      "[epoch 13][step 109400] logloss:0.063133 l2_regular:0.000608 rmse:368.016693 total_loss:0.063741 acc:0.192000\n",
      "[epoch 13][step 109500] logloss:0.064105 l2_regular:0.000608 rmse:417.454407 total_loss:0.064713 acc:0.199000\n",
      "[epoch 13][step 109600] logloss:0.058841 l2_regular:0.000608 rmse:442.599579 total_loss:0.059449 acc:0.274000\n",
      "[epoch 13][step 109700] logloss:0.053601 l2_regular:0.000608 rmse:463.519470 total_loss:0.054209 acc:0.380000\n",
      "[epoch 13][step 109800] logloss:0.059289 l2_regular:0.000608 rmse:569.231323 total_loss:0.059897 acc:0.214000\n",
      "[epoch 13][step 109900] logloss:0.055037 l2_regular:0.000608 rmse:516.817383 total_loss:0.055645 acc:0.239000\n",
      "[epoch 13][step 110000] logloss:0.053900 l2_regular:0.000608 rmse:552.067017 total_loss:0.054508 acc:0.397000\n",
      "[epoch 13][step 110100] logloss:0.065417 l2_regular:0.000608 rmse:478.762756 total_loss:0.066024 acc:0.245000\n",
      "[epoch 13][step 110200] logloss:0.056339 l2_regular:0.000608 rmse:557.580994 total_loss:0.056947 acc:0.263000\n",
      "[epoch 13][step 110300] logloss:0.062573 l2_regular:0.000608 rmse:576.207031 total_loss:0.063181 acc:0.242000\n",
      "[epoch 13][step 110400] logloss:0.055025 l2_regular:0.000608 rmse:333.648041 total_loss:0.055633 acc:0.249000\n",
      "[epoch 13][step 110500] logloss:0.071314 l2_regular:0.000608 rmse:621.944275 total_loss:0.071922 acc:0.188000\n",
      "[epoch 13][step 110600] logloss:0.065836 l2_regular:0.000608 rmse:443.721436 total_loss:0.066444 acc:0.256000\n",
      "[epoch 13][step 110700] logloss:0.064046 l2_regular:0.000608 rmse:481.599243 total_loss:0.064654 acc:0.202000\n",
      "[epoch 13][step 110800] logloss:0.056502 l2_regular:0.000608 rmse:483.904419 total_loss:0.057110 acc:0.345000\n",
      "[epoch 13][step 110900] logloss:0.054423 l2_regular:0.000608 rmse:550.734314 total_loss:0.055030 acc:0.279000\n",
      "[epoch 13][step 111000] logloss:0.060248 l2_regular:0.000608 rmse:770.631409 total_loss:0.060855 acc:0.284000\n",
      "[epoch 13][step 111100] logloss:0.066201 l2_regular:0.000608 rmse:693.841003 total_loss:0.066809 acc:0.157000\n",
      "[epoch 13][step 111200] logloss:0.063434 l2_regular:0.000608 rmse:359.391968 total_loss:0.064042 acc:0.241000\n",
      "[epoch 13][step 111300] logloss:0.076021 l2_regular:0.000608 rmse:377.666473 total_loss:0.076629 acc:0.176000\n",
      "[epoch 13][step 111400] logloss:0.058640 l2_regular:0.000608 rmse:747.021362 total_loss:0.059248 acc:0.217000\n",
      "[epoch 13][step 111500] logloss:0.048767 l2_regular:0.000608 rmse:463.913849 total_loss:0.049375 acc:0.278000\n",
      "[epoch 13][step 111600] logloss:0.061213 l2_regular:0.000608 rmse:475.569611 total_loss:0.061821 acc:0.133000\n",
      "[epoch 13][step 111700] logloss:0.053245 l2_regular:0.000608 rmse:418.293488 total_loss:0.053853 acc:0.278000\n",
      "[epoch 13][step 111800] logloss:0.066498 l2_regular:0.000608 rmse:404.465576 total_loss:0.067106 acc:0.256000\n",
      "[epoch 13][step 111900] logloss:0.060661 l2_regular:0.000608 rmse:454.699646 total_loss:0.061269 acc:0.210000\n",
      "[epoch 13][step 112000] logloss:0.058721 l2_regular:0.000608 rmse:459.418121 total_loss:0.059328 acc:0.243000\n",
      "[epoch 13][step 112100] logloss:0.062191 l2_regular:0.000608 rmse:339.193207 total_loss:0.062798 acc:0.249000\n",
      "[epoch 13][step 112200] logloss:0.063703 l2_regular:0.000608 rmse:552.852661 total_loss:0.064311 acc:0.260000\n",
      "[epoch 13][step 112300] logloss:0.058201 l2_regular:0.000608 rmse:548.663330 total_loss:0.058808 acc:0.205000\n",
      "[epoch 13][step 112400] logloss:0.068558 l2_regular:0.000608 rmse:419.643555 total_loss:0.069166 acc:0.204000\n",
      "[epoch 13][step 112500] logloss:0.053868 l2_regular:0.000608 rmse:543.720459 total_loss:0.054476 acc:0.342000\n",
      "[epoch 13][step 112600] logloss:0.064114 l2_regular:0.000608 rmse:480.609009 total_loss:0.064722 acc:0.184000\n",
      "[epoch 13][step 112700] logloss:0.059103 l2_regular:0.000608 rmse:511.693939 total_loss:0.059711 acc:0.206000\n",
      "[epoch 13][step 112800] logloss:0.058564 l2_regular:0.000608 rmse:422.602478 total_loss:0.059172 acc:0.168000\n",
      "[epoch 13][step 112900] logloss:0.061863 l2_regular:0.000608 rmse:418.512024 total_loss:0.062471 acc:0.215000\n",
      "[epoch 13][step 113000] logloss:0.062065 l2_regular:0.000608 rmse:391.453491 total_loss:0.062672 acc:0.153000\n",
      "[epoch 13][step 113100] logloss:0.059222 l2_regular:0.000608 rmse:518.870667 total_loss:0.059830 acc:0.338000\n",
      "[epoch 13][step 113200] logloss:0.064365 l2_regular:0.000608 rmse:513.660461 total_loss:0.064972 acc:0.203000\n",
      "[epoch 13][step 113300] logloss:0.058812 l2_regular:0.000608 rmse:597.681519 total_loss:0.059420 acc:0.249000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 13][step 113400] logloss:0.067734 l2_regular:0.000608 rmse:402.588287 total_loss:0.068342 acc:0.175000\n",
      "[epoch 13][step 113500] logloss:0.053324 l2_regular:0.000608 rmse:496.883392 total_loss:0.053932 acc:0.213000\n",
      "[epoch 13][step 113600] logloss:0.065175 l2_regular:0.000608 rmse:580.251099 total_loss:0.065783 acc:0.231000\n",
      "[epoch 13][step 113700] logloss:0.047419 l2_regular:0.000608 rmse:334.962372 total_loss:0.048027 acc:0.268000\n",
      "[epoch 13][step 113800] logloss:0.062236 l2_regular:0.000608 rmse:593.002075 total_loss:0.062844 acc:0.224000\n",
      "[epoch 13][step 113900] logloss:0.061508 l2_regular:0.000608 rmse:618.900330 total_loss:0.062116 acc:0.188000\n",
      "[epoch 13][step 114000] logloss:0.062093 l2_regular:0.000608 rmse:756.948303 total_loss:0.062700 acc:0.294000\n",
      "[epoch 13][step 114100] logloss:0.070033 l2_regular:0.000608 rmse:499.768982 total_loss:0.070641 acc:0.224000\n",
      "[epoch 13][step 114200] logloss:0.064663 l2_regular:0.000608 rmse:458.139130 total_loss:0.065270 acc:0.305000\n",
      "[epoch 13][step 114300] logloss:0.067932 l2_regular:0.000608 rmse:415.307129 total_loss:0.068539 acc:0.193000\n",
      "[epoch 13][step 114400] logloss:0.061281 l2_regular:0.000608 rmse:347.410980 total_loss:0.061889 acc:0.197000\n",
      "[epoch 13][step 114500] logloss:0.066693 l2_regular:0.000608 rmse:495.838470 total_loss:0.067301 acc:0.167000\n",
      "[epoch 13][step 114600] logloss:0.061953 l2_regular:0.000608 rmse:482.485168 total_loss:0.062561 acc:0.285000\n",
      "[epoch 13][step 114700] logloss:0.063542 l2_regular:0.000608 rmse:343.382568 total_loss:0.064150 acc:0.227000\n",
      "[epoch 13][step 114800] logloss:0.060315 l2_regular:0.000608 rmse:519.153381 total_loss:0.060922 acc:0.307000\n",
      "[epoch 13][step 114900] logloss:0.065274 l2_regular:0.000608 rmse:597.239075 total_loss:0.065882 acc:0.202000\n",
      "[epoch 13][step 115000] logloss:0.053357 l2_regular:0.000608 rmse:541.195984 total_loss:0.053964 acc:0.332000\n",
      "[epoch 13][step 115100] logloss:0.058013 l2_regular:0.000608 rmse:401.643311 total_loss:0.058621 acc:0.252000\n",
      "[epoch 13][step 115200] logloss:0.077232 l2_regular:0.000608 rmse:436.688507 total_loss:0.077840 acc:0.130000\n",
      "[epoch 13][step 115300] logloss:0.060625 l2_regular:0.000608 rmse:512.198303 total_loss:0.061233 acc:0.295000\n",
      "[epoch 13][step 115400] logloss:0.053482 l2_regular:0.000608 rmse:687.485657 total_loss:0.054090 acc:0.280000\n",
      "[epoch 13][step 115500] logloss:0.064492 l2_regular:0.000608 rmse:437.360779 total_loss:0.065100 acc:0.206000\n",
      "[epoch 13][step 115600] logloss:0.073228 l2_regular:0.000608 rmse:526.142761 total_loss:0.073836 acc:0.174000\n",
      "[epoch 13][step 115700] logloss:0.057466 l2_regular:0.000608 rmse:489.265961 total_loss:0.058074 acc:0.303000\n",
      "[epoch 13][step 115800] logloss:0.068136 l2_regular:0.000608 rmse:596.413513 total_loss:0.068744 acc:0.188000\n",
      "[epoch 13][step 115900] logloss:0.060686 l2_regular:0.000608 rmse:321.218140 total_loss:0.061293 acc:0.249000\n",
      "[epoch 13][step 116000] logloss:0.049346 l2_regular:0.000608 rmse:478.787994 total_loss:0.049954 acc:0.244000\n",
      "[epoch 13][step 116100] logloss:0.058720 l2_regular:0.000608 rmse:324.363800 total_loss:0.059328 acc:0.241000\n",
      "[epoch 13][step 116200] logloss:0.051123 l2_regular:0.000608 rmse:619.686829 total_loss:0.051731 acc:0.267000\n",
      "[epoch 13][step 116300] logloss:0.069971 l2_regular:0.000608 rmse:525.712402 total_loss:0.070579 acc:0.240000\n",
      "[epoch 13][step 116400] logloss:0.055937 l2_regular:0.000608 rmse:414.698303 total_loss:0.056544 acc:0.225000\n",
      "[epoch 13][step 116500] logloss:0.048621 l2_regular:0.000608 rmse:347.706299 total_loss:0.049229 acc:0.222000\n",
      "[epoch 13][step 116600] logloss:0.065456 l2_regular:0.000608 rmse:438.469940 total_loss:0.066064 acc:0.305000\n",
      "[epoch 13][step 116700] logloss:0.065476 l2_regular:0.000608 rmse:383.114380 total_loss:0.066083 acc:0.255000\n",
      "[epoch 13][step 116800] logloss:0.064617 l2_regular:0.000608 rmse:362.850403 total_loss:0.065225 acc:0.240000\n",
      "[epoch 13][step 116900] logloss:0.055600 l2_regular:0.000608 rmse:412.500427 total_loss:0.056208 acc:0.273000\n",
      "--------------epoch 13 finished —> total batch:8351---------------\n",
      "[epoch 14][step 117000] logloss:0.062182 l2_regular:0.000608 rmse:443.582794 total_loss:0.062790 acc:0.257000\n",
      "[epoch 14][step 117100] logloss:0.061135 l2_regular:0.000608 rmse:497.519043 total_loss:0.061743 acc:0.234000\n",
      "[epoch 14][step 117200] logloss:0.049651 l2_regular:0.000608 rmse:546.918823 total_loss:0.050259 acc:0.363000\n",
      "[epoch 14][step 117300] logloss:0.059801 l2_regular:0.000608 rmse:557.827148 total_loss:0.060409 acc:0.308000\n",
      "[epoch 14][step 117400] logloss:0.062568 l2_regular:0.000608 rmse:445.229218 total_loss:0.063176 acc:0.148000\n",
      "[epoch 14][step 117500] logloss:0.062354 l2_regular:0.000608 rmse:470.918488 total_loss:0.062962 acc:0.217000\n",
      "[epoch 14][step 117600] logloss:0.058974 l2_regular:0.000608 rmse:420.205505 total_loss:0.059582 acc:0.243000\n",
      "[epoch 14][step 117700] logloss:0.070379 l2_regular:0.000608 rmse:503.447937 total_loss:0.070987 acc:0.251000\n",
      "[epoch 14][step 117800] logloss:0.052301 l2_regular:0.000608 rmse:585.550049 total_loss:0.052908 acc:0.348000\n",
      "[epoch 14][step 117900] logloss:0.067356 l2_regular:0.000608 rmse:518.828491 total_loss:0.067964 acc:0.175000\n",
      "[epoch 14][step 118000] logloss:0.055505 l2_regular:0.000608 rmse:432.040131 total_loss:0.056112 acc:0.187000\n",
      "[epoch 14][step 118100] logloss:0.059752 l2_regular:0.000608 rmse:592.782898 total_loss:0.060360 acc:0.225000\n",
      "[epoch 14][step 118200] logloss:0.061499 l2_regular:0.000608 rmse:367.841095 total_loss:0.062107 acc:0.221000\n",
      "[epoch 14][step 118300] logloss:0.059815 l2_regular:0.000608 rmse:602.069763 total_loss:0.060422 acc:0.245000\n",
      "[epoch 14][step 118400] logloss:0.062738 l2_regular:0.000608 rmse:517.064209 total_loss:0.063345 acc:0.292000\n",
      "[epoch 14][step 118500] logloss:0.062667 l2_regular:0.000608 rmse:675.391052 total_loss:0.063275 acc:0.192000\n",
      "[epoch 14][step 118600] logloss:0.067311 l2_regular:0.000608 rmse:514.264893 total_loss:0.067919 acc:0.167000\n",
      "[epoch 14][step 118700] logloss:0.054260 l2_regular:0.000608 rmse:371.809845 total_loss:0.054868 acc:0.228000\n",
      "[epoch 14][step 118800] logloss:0.059424 l2_regular:0.000608 rmse:462.749969 total_loss:0.060032 acc:0.256000\n",
      "[epoch 14][step 118900] logloss:0.060343 l2_regular:0.000608 rmse:420.964996 total_loss:0.060951 acc:0.135000\n",
      "[epoch 14][step 119000] logloss:0.065129 l2_regular:0.000608 rmse:454.405762 total_loss:0.065736 acc:0.275000\n",
      "[epoch 14][step 119100] logloss:0.064628 l2_regular:0.000608 rmse:475.359161 total_loss:0.065235 acc:0.237000\n",
      "[epoch 14][step 119200] logloss:0.061583 l2_regular:0.000608 rmse:418.558594 total_loss:0.062191 acc:0.295000\n",
      "[epoch 14][step 119300] logloss:0.063335 l2_regular:0.000608 rmse:558.280640 total_loss:0.063943 acc:0.295000\n",
      "[epoch 14][step 119400] logloss:0.053544 l2_regular:0.000608 rmse:499.983826 total_loss:0.054152 acc:0.304000\n",
      "[epoch 14][step 119500] logloss:0.058089 l2_regular:0.000608 rmse:504.705231 total_loss:0.058696 acc:0.219000\n",
      "[epoch 14][step 119600] logloss:0.058615 l2_regular:0.000608 rmse:311.143616 total_loss:0.059223 acc:0.347000\n",
      "[epoch 14][step 119700] logloss:0.071033 l2_regular:0.000608 rmse:447.096741 total_loss:0.071641 acc:0.207000\n",
      "[epoch 14][step 119800] logloss:0.066279 l2_regular:0.000608 rmse:438.220367 total_loss:0.066887 acc:0.251000\n",
      "[epoch 14][step 119900] logloss:0.060022 l2_regular:0.000608 rmse:295.336212 total_loss:0.060630 acc:0.320000\n",
      "[epoch 14][step 120000] logloss:0.061242 l2_regular:0.000608 rmse:400.100647 total_loss:0.061850 acc:0.255000\n",
      "[epoch 14][step 120100] logloss:0.054476 l2_regular:0.000608 rmse:534.392517 total_loss:0.055084 acc:0.318000\n",
      "[epoch 14][step 120200] logloss:0.055454 l2_regular:0.000608 rmse:415.442566 total_loss:0.056061 acc:0.268000\n",
      "[epoch 14][step 120300] logloss:0.058708 l2_regular:0.000608 rmse:464.735901 total_loss:0.059316 acc:0.244000\n",
      "[epoch 14][step 120400] logloss:0.058681 l2_regular:0.000608 rmse:1243.939453 total_loss:0.059289 acc:0.233000\n",
      "[epoch 14][step 120500] logloss:0.061528 l2_regular:0.000608 rmse:464.342468 total_loss:0.062136 acc:0.283000\n",
      "[epoch 14][step 120600] logloss:0.053106 l2_regular:0.000608 rmse:452.269592 total_loss:0.053714 acc:0.233000\n",
      "[epoch 14][step 120700] logloss:0.060869 l2_regular:0.000608 rmse:422.003784 total_loss:0.061477 acc:0.174000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 14][step 120800] logloss:0.065546 l2_regular:0.000608 rmse:562.342529 total_loss:0.066153 acc:0.156000\n",
      "[epoch 14][step 120900] logloss:0.062210 l2_regular:0.000608 rmse:476.232941 total_loss:0.062818 acc:0.205000\n",
      "[epoch 14][step 121000] logloss:0.058608 l2_regular:0.000608 rmse:458.360199 total_loss:0.059216 acc:0.260000\n",
      "[epoch 14][step 121100] logloss:0.058801 l2_regular:0.000608 rmse:510.042877 total_loss:0.059408 acc:0.226000\n",
      "[epoch 14][step 121200] logloss:0.064408 l2_regular:0.000608 rmse:782.846069 total_loss:0.065015 acc:0.217000\n",
      "[epoch 14][step 121300] logloss:0.065852 l2_regular:0.000608 rmse:364.679382 total_loss:0.066460 acc:0.276000\n",
      "[epoch 14][step 121400] logloss:0.061032 l2_regular:0.000608 rmse:510.853760 total_loss:0.061640 acc:0.203000\n",
      "[epoch 14][step 121500] logloss:0.066053 l2_regular:0.000608 rmse:681.908264 total_loss:0.066661 acc:0.240000\n",
      "[epoch 14][step 121600] logloss:0.060232 l2_regular:0.000608 rmse:801.487732 total_loss:0.060840 acc:0.217000\n",
      "[epoch 14][step 121700] logloss:0.062219 l2_regular:0.000608 rmse:432.109070 total_loss:0.062827 acc:0.263000\n",
      "[epoch 14][step 121800] logloss:0.060671 l2_regular:0.000608 rmse:413.885223 total_loss:0.061278 acc:0.248000\n",
      "[epoch 14][step 121900] logloss:0.057419 l2_regular:0.000608 rmse:502.966400 total_loss:0.058027 acc:0.228000\n",
      "[epoch 14][step 122000] logloss:0.068977 l2_regular:0.000608 rmse:368.994995 total_loss:0.069585 acc:0.280000\n",
      "[epoch 14][step 122100] logloss:0.055240 l2_regular:0.000608 rmse:451.193573 total_loss:0.055848 acc:0.307000\n",
      "[epoch 14][step 122200] logloss:0.067959 l2_regular:0.000608 rmse:507.818024 total_loss:0.068566 acc:0.214000\n",
      "[epoch 14][step 122300] logloss:0.054049 l2_regular:0.000608 rmse:517.405640 total_loss:0.054657 acc:0.364000\n",
      "[epoch 14][step 122400] logloss:0.063210 l2_regular:0.000608 rmse:513.293274 total_loss:0.063818 acc:0.241000\n",
      "[epoch 14][step 122500] logloss:0.062062 l2_regular:0.000608 rmse:373.765808 total_loss:0.062670 acc:0.313000\n",
      "[epoch 14][step 122600] logloss:0.054926 l2_regular:0.000608 rmse:540.891174 total_loss:0.055534 acc:0.311000\n",
      "[epoch 14][step 122700] logloss:0.058087 l2_regular:0.000608 rmse:573.656189 total_loss:0.058695 acc:0.251000\n",
      "[epoch 14][step 122800] logloss:0.066620 l2_regular:0.000608 rmse:664.359436 total_loss:0.067228 acc:0.192000\n",
      "[epoch 14][step 122900] logloss:0.061232 l2_regular:0.000608 rmse:424.563324 total_loss:0.061840 acc:0.306000\n",
      "[epoch 14][step 123000] logloss:0.057517 l2_regular:0.000608 rmse:434.629395 total_loss:0.058125 acc:0.323000\n",
      "[epoch 14][step 123100] logloss:0.050319 l2_regular:0.000608 rmse:354.491272 total_loss:0.050927 acc:0.398000\n",
      "[epoch 14][step 123200] logloss:0.081465 l2_regular:0.000608 rmse:599.442017 total_loss:0.082073 acc:0.152000\n",
      "[epoch 14][step 123300] logloss:0.065967 l2_regular:0.000608 rmse:765.057312 total_loss:0.066575 acc:0.264000\n",
      "[epoch 14][step 123400] logloss:0.044349 l2_regular:0.000608 rmse:559.725647 total_loss:0.044957 acc:0.307000\n",
      "[epoch 14][step 123500] logloss:0.072179 l2_regular:0.000608 rmse:403.940369 total_loss:0.072786 acc:0.200000\n",
      "[epoch 14][step 123600] logloss:0.060642 l2_regular:0.000608 rmse:695.795837 total_loss:0.061249 acc:0.237000\n",
      "[epoch 14][step 123700] logloss:0.053980 l2_regular:0.000608 rmse:397.272888 total_loss:0.054587 acc:0.275000\n",
      "[epoch 14][step 123800] logloss:0.057595 l2_regular:0.000608 rmse:603.439453 total_loss:0.058203 acc:0.214000\n",
      "[epoch 14][step 123900] logloss:0.060139 l2_regular:0.000608 rmse:458.982452 total_loss:0.060747 acc:0.211000\n",
      "[epoch 14][step 124000] logloss:0.053369 l2_regular:0.000608 rmse:426.843353 total_loss:0.053976 acc:0.269000\n",
      "[epoch 14][step 124100] logloss:0.073892 l2_regular:0.000608 rmse:607.244934 total_loss:0.074500 acc:0.151000\n",
      "[epoch 14][step 124200] logloss:0.056148 l2_regular:0.000608 rmse:623.136658 total_loss:0.056756 acc:0.216000\n",
      "[epoch 14][step 124300] logloss:0.055592 l2_regular:0.000608 rmse:486.907166 total_loss:0.056199 acc:0.185000\n",
      "[epoch 14][step 124400] logloss:0.065082 l2_regular:0.000608 rmse:330.227264 total_loss:0.065689 acc:0.165000\n",
      "[epoch 14][step 124500] logloss:0.052322 l2_regular:0.000608 rmse:436.652130 total_loss:0.052929 acc:0.313000\n",
      "[epoch 14][step 124600] logloss:0.062184 l2_regular:0.000608 rmse:599.710999 total_loss:0.062792 acc:0.266000\n",
      "[epoch 14][step 124700] logloss:0.061442 l2_regular:0.000608 rmse:564.825562 total_loss:0.062050 acc:0.140000\n",
      "[epoch 14][step 124800] logloss:0.054907 l2_regular:0.000608 rmse:576.920166 total_loss:0.055515 acc:0.221000\n",
      "[epoch 14][step 124900] logloss:0.051756 l2_regular:0.000608 rmse:544.811401 total_loss:0.052364 acc:0.365000\n",
      "[epoch 14][step 125000] logloss:0.054321 l2_regular:0.000608 rmse:394.648987 total_loss:0.054928 acc:0.304000\n",
      "[epoch 14][step 125100] logloss:0.053954 l2_regular:0.000608 rmse:480.353394 total_loss:0.054562 acc:0.228000\n",
      "[epoch 14][step 125200] logloss:0.065295 l2_regular:0.000608 rmse:443.138641 total_loss:0.065902 acc:0.219000\n",
      "--------------epoch 14 finished —> total batch:8351---------------\n",
      "[epoch 15][step 125300] logloss:0.054137 l2_regular:0.000608 rmse:400.711121 total_loss:0.054744 acc:0.311000\n",
      "[epoch 15][step 125400] logloss:0.057837 l2_regular:0.000608 rmse:614.429565 total_loss:0.058445 acc:0.306000\n",
      "[epoch 15][step 125500] logloss:0.064133 l2_regular:0.000608 rmse:405.006927 total_loss:0.064741 acc:0.260000\n",
      "[epoch 15][step 125600] logloss:0.067198 l2_regular:0.000608 rmse:583.569824 total_loss:0.067806 acc:0.215000\n",
      "[epoch 15][step 125700] logloss:0.068458 l2_regular:0.000608 rmse:468.309998 total_loss:0.069066 acc:0.251000\n",
      "[epoch 15][step 125800] logloss:0.058013 l2_regular:0.000608 rmse:490.929138 total_loss:0.058621 acc:0.282000\n",
      "[epoch 15][step 125900] logloss:0.052032 l2_regular:0.000608 rmse:467.904816 total_loss:0.052640 acc:0.261000\n",
      "[epoch 15][step 126000] logloss:0.056675 l2_regular:0.000608 rmse:488.257507 total_loss:0.057283 acc:0.243000\n",
      "[epoch 15][step 126100] logloss:0.059359 l2_regular:0.000608 rmse:442.417267 total_loss:0.059967 acc:0.232000\n",
      "[epoch 15][step 126200] logloss:0.072037 l2_regular:0.000608 rmse:547.158081 total_loss:0.072645 acc:0.168000\n",
      "[epoch 15][step 126300] logloss:0.059270 l2_regular:0.000608 rmse:451.651611 total_loss:0.059878 acc:0.256000\n",
      "[epoch 15][step 126400] logloss:0.067213 l2_regular:0.000608 rmse:756.776001 total_loss:0.067821 acc:0.279000\n",
      "[epoch 15][step 126500] logloss:0.064528 l2_regular:0.000608 rmse:421.393585 total_loss:0.065136 acc:0.257000\n",
      "[epoch 15][step 126600] logloss:0.059992 l2_regular:0.000608 rmse:415.002777 total_loss:0.060600 acc:0.172000\n",
      "[epoch 15][step 126700] logloss:0.063204 l2_regular:0.000608 rmse:459.901642 total_loss:0.063812 acc:0.250000\n",
      "[epoch 15][step 126800] logloss:0.064495 l2_regular:0.000608 rmse:322.647675 total_loss:0.065103 acc:0.229000\n",
      "[epoch 15][step 126900] logloss:0.057850 l2_regular:0.000608 rmse:486.662811 total_loss:0.058458 acc:0.237000\n",
      "[epoch 15][step 127000] logloss:0.059877 l2_regular:0.000608 rmse:373.787506 total_loss:0.060484 acc:0.203000\n",
      "[epoch 15][step 127100] logloss:0.065250 l2_regular:0.000608 rmse:683.869019 total_loss:0.065858 acc:0.196000\n",
      "[epoch 15][step 127200] logloss:0.077444 l2_regular:0.000608 rmse:506.883667 total_loss:0.078052 acc:0.113000\n",
      "[epoch 15][step 127300] logloss:0.059469 l2_regular:0.000608 rmse:382.089050 total_loss:0.060077 acc:0.379000\n",
      "[epoch 15][step 127400] logloss:0.065727 l2_regular:0.000608 rmse:459.368927 total_loss:0.066335 acc:0.196000\n",
      "[epoch 15][step 127500] logloss:0.059932 l2_regular:0.000608 rmse:529.256714 total_loss:0.060539 acc:0.183000\n",
      "[epoch 15][step 127600] logloss:0.057141 l2_regular:0.000608 rmse:568.829163 total_loss:0.057749 acc:0.286000\n",
      "[epoch 15][step 127700] logloss:0.057731 l2_regular:0.000608 rmse:623.104980 total_loss:0.058339 acc:0.130000\n",
      "[epoch 15][step 127800] logloss:0.059341 l2_regular:0.000608 rmse:383.461090 total_loss:0.059949 acc:0.231000\n",
      "[epoch 15][step 127900] logloss:0.065256 l2_regular:0.000608 rmse:777.245544 total_loss:0.065864 acc:0.257000\n",
      "[epoch 15][step 128000] logloss:0.062733 l2_regular:0.000608 rmse:341.376038 total_loss:0.063341 acc:0.252000\n",
      "[epoch 15][step 128100] logloss:0.054354 l2_regular:0.000608 rmse:384.052643 total_loss:0.054962 acc:0.238000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 15][step 128200] logloss:0.067017 l2_regular:0.000608 rmse:423.919647 total_loss:0.067625 acc:0.159000\n",
      "[epoch 15][step 128300] logloss:0.057305 l2_regular:0.000608 rmse:404.148102 total_loss:0.057913 acc:0.289000\n",
      "[epoch 15][step 128400] logloss:0.063228 l2_regular:0.000608 rmse:584.896606 total_loss:0.063836 acc:0.208000\n",
      "[epoch 15][step 128500] logloss:0.054200 l2_regular:0.000608 rmse:363.933777 total_loss:0.054808 acc:0.216000\n",
      "[epoch 15][step 128600] logloss:0.053653 l2_regular:0.000608 rmse:494.984436 total_loss:0.054261 acc:0.235000\n",
      "[epoch 15][step 128700] logloss:0.057977 l2_regular:0.000608 rmse:461.574799 total_loss:0.058584 acc:0.196000\n",
      "[epoch 15][step 128800] logloss:0.059935 l2_regular:0.000608 rmse:485.914032 total_loss:0.060542 acc:0.212000\n",
      "[epoch 15][step 128900] logloss:0.061956 l2_regular:0.000608 rmse:462.957031 total_loss:0.062564 acc:0.297000\n",
      "[epoch 15][step 129000] logloss:0.053097 l2_regular:0.000608 rmse:582.768494 total_loss:0.053705 acc:0.231000\n",
      "[epoch 15][step 129100] logloss:0.081133 l2_regular:0.000608 rmse:485.405609 total_loss:0.081740 acc:0.110000\n",
      "[epoch 15][step 129200] logloss:0.062860 l2_regular:0.000608 rmse:503.835144 total_loss:0.063468 acc:0.182000\n",
      "[epoch 15][step 129300] logloss:0.071578 l2_regular:0.000608 rmse:544.414062 total_loss:0.072185 acc:0.164000\n",
      "[epoch 15][step 129400] logloss:0.063034 l2_regular:0.000608 rmse:469.363800 total_loss:0.063642 acc:0.207000\n",
      "[epoch 15][step 129500] logloss:0.077445 l2_regular:0.000608 rmse:326.024902 total_loss:0.078053 acc:0.196000\n",
      "[epoch 15][step 129600] logloss:0.058046 l2_regular:0.000608 rmse:470.200653 total_loss:0.058654 acc:0.303000\n",
      "[epoch 15][step 129700] logloss:0.059156 l2_regular:0.000608 rmse:437.048645 total_loss:0.059764 acc:0.248000\n",
      "[epoch 15][step 129800] logloss:0.056030 l2_regular:0.000608 rmse:456.577637 total_loss:0.056638 acc:0.248000\n",
      "[epoch 15][step 129900] logloss:0.060418 l2_regular:0.000608 rmse:489.489838 total_loss:0.061026 acc:0.322000\n",
      "[epoch 15][step 130000] logloss:0.059247 l2_regular:0.000608 rmse:448.451172 total_loss:0.059855 acc:0.317000\n",
      "[epoch 15][step 130100] logloss:0.057313 l2_regular:0.000608 rmse:534.449097 total_loss:0.057921 acc:0.190000\n",
      "[epoch 15][step 130200] logloss:0.064451 l2_regular:0.000608 rmse:426.536987 total_loss:0.065059 acc:0.175000\n",
      "[epoch 15][step 130300] logloss:0.057093 l2_regular:0.000608 rmse:477.651459 total_loss:0.057701 acc:0.307000\n",
      "[epoch 15][step 130400] logloss:0.065137 l2_regular:0.000608 rmse:383.561890 total_loss:0.065745 acc:0.216000\n",
      "[epoch 15][step 130500] logloss:0.059531 l2_regular:0.000608 rmse:511.897339 total_loss:0.060139 acc:0.184000\n",
      "[epoch 15][step 130600] logloss:0.053225 l2_regular:0.000608 rmse:390.426819 total_loss:0.053833 acc:0.230000\n",
      "[epoch 15][step 130700] logloss:0.056329 l2_regular:0.000608 rmse:531.549622 total_loss:0.056937 acc:0.271000\n",
      "[epoch 15][step 130800] logloss:0.049169 l2_regular:0.000608 rmse:593.930176 total_loss:0.049776 acc:0.248000\n",
      "[epoch 15][step 130900] logloss:0.059903 l2_regular:0.000608 rmse:463.906769 total_loss:0.060510 acc:0.255000\n",
      "[epoch 15][step 131000] logloss:0.058889 l2_regular:0.000608 rmse:1179.474487 total_loss:0.059497 acc:0.225000\n",
      "[epoch 15][step 131100] logloss:0.060290 l2_regular:0.000608 rmse:495.239624 total_loss:0.060898 acc:0.232000\n",
      "[epoch 15][step 131200] logloss:0.055219 l2_regular:0.000608 rmse:460.004974 total_loss:0.055827 acc:0.364000\n",
      "[epoch 15][step 131300] logloss:0.058582 l2_regular:0.000608 rmse:600.701538 total_loss:0.059189 acc:0.254000\n",
      "[epoch 15][step 131400] logloss:0.049623 l2_regular:0.000608 rmse:489.359711 total_loss:0.050231 acc:0.312000\n",
      "[epoch 15][step 131500] logloss:0.056705 l2_regular:0.000608 rmse:500.593811 total_loss:0.057312 acc:0.324000\n",
      "[epoch 15][step 131600] logloss:0.068994 l2_regular:0.000608 rmse:542.399841 total_loss:0.069602 acc:0.163000\n",
      "[epoch 15][step 131700] logloss:0.060927 l2_regular:0.000608 rmse:465.478119 total_loss:0.061535 acc:0.282000\n",
      "[epoch 15][step 131800] logloss:0.060028 l2_regular:0.000608 rmse:597.516296 total_loss:0.060636 acc:0.245000\n",
      "[epoch 15][step 131900] logloss:0.063915 l2_regular:0.000608 rmse:456.117798 total_loss:0.064523 acc:0.228000\n",
      "[epoch 15][step 132000] logloss:0.054442 l2_regular:0.000608 rmse:442.667328 total_loss:0.055050 acc:0.289000\n",
      "[epoch 15][step 132100] logloss:0.058576 l2_regular:0.000608 rmse:467.995270 total_loss:0.059184 acc:0.155000\n",
      "[epoch 15][step 132200] logloss:0.058297 l2_regular:0.000608 rmse:353.598297 total_loss:0.058905 acc:0.269000\n",
      "[epoch 15][step 132300] logloss:0.066124 l2_regular:0.000608 rmse:539.083130 total_loss:0.066732 acc:0.271000\n",
      "[epoch 15][step 132400] logloss:0.054882 l2_regular:0.000608 rmse:449.402496 total_loss:0.055489 acc:0.274000\n",
      "[epoch 15][step 132500] logloss:0.064401 l2_regular:0.000608 rmse:549.806091 total_loss:0.065009 acc:0.200000\n",
      "[epoch 15][step 132600] logloss:0.065261 l2_regular:0.000608 rmse:516.272888 total_loss:0.065869 acc:0.165000\n",
      "[epoch 15][step 132700] logloss:0.065879 l2_regular:0.000608 rmse:658.111450 total_loss:0.066487 acc:0.177000\n",
      "[epoch 15][step 132800] logloss:0.048416 l2_regular:0.000608 rmse:426.523041 total_loss:0.049024 acc:0.236000\n",
      "[epoch 15][step 132900] logloss:0.069947 l2_regular:0.000608 rmse:491.351440 total_loss:0.070555 acc:0.243000\n",
      "[epoch 15][step 133000] logloss:0.054456 l2_regular:0.000608 rmse:304.365875 total_loss:0.055064 acc:0.402000\n",
      "[epoch 15][step 133100] logloss:0.059342 l2_regular:0.000608 rmse:412.959167 total_loss:0.059950 acc:0.364000\n",
      "[epoch 15][step 133200] logloss:0.072711 l2_regular:0.000608 rmse:392.914734 total_loss:0.073319 acc:0.224000\n",
      "[epoch 15][step 133300] logloss:0.054372 l2_regular:0.000608 rmse:506.382446 total_loss:0.054979 acc:0.259000\n",
      "[epoch 15][step 133400] logloss:0.063655 l2_regular:0.000608 rmse:544.313293 total_loss:0.064263 acc:0.218000\n",
      "[epoch 15][step 133500] logloss:0.053066 l2_regular:0.000608 rmse:424.116882 total_loss:0.053674 acc:0.255000\n",
      "[epoch 15][step 133600] logloss:0.053788 l2_regular:0.000608 rmse:600.132019 total_loss:0.054396 acc:0.317000\n",
      "--------------epoch 15 finished —> total batch:8351---------------\n",
      "[epoch 16][step 133700] logloss:0.058156 l2_regular:0.000608 rmse:455.718445 total_loss:0.058764 acc:0.253000\n",
      "[epoch 16][step 133800] logloss:0.068985 l2_regular:0.000608 rmse:375.321381 total_loss:0.069593 acc:0.154000\n",
      "[epoch 16][step 133900] logloss:0.056323 l2_regular:0.000608 rmse:387.818237 total_loss:0.056931 acc:0.343000\n",
      "[epoch 16][step 134000] logloss:0.062054 l2_regular:0.000608 rmse:459.282867 total_loss:0.062661 acc:0.236000\n",
      "[epoch 16][step 134100] logloss:0.055068 l2_regular:0.000608 rmse:416.082184 total_loss:0.055676 acc:0.353000\n",
      "[epoch 16][step 134200] logloss:0.062322 l2_regular:0.000608 rmse:404.205994 total_loss:0.062929 acc:0.251000\n",
      "[epoch 16][step 134300] logloss:0.051025 l2_regular:0.000608 rmse:431.556793 total_loss:0.051632 acc:0.478000\n",
      "[epoch 16][step 134400] logloss:0.059253 l2_regular:0.000608 rmse:598.338989 total_loss:0.059860 acc:0.228000\n",
      "[epoch 16][step 134500] logloss:0.066614 l2_regular:0.000608 rmse:464.929626 total_loss:0.067222 acc:0.143000\n",
      "[epoch 16][step 134600] logloss:0.065285 l2_regular:0.000608 rmse:523.374817 total_loss:0.065893 acc:0.206000\n",
      "[epoch 16][step 134700] logloss:0.061019 l2_regular:0.000608 rmse:522.253845 total_loss:0.061627 acc:0.282000\n",
      "[epoch 16][step 134800] logloss:0.051153 l2_regular:0.000608 rmse:450.129944 total_loss:0.051760 acc:0.366000\n",
      "[epoch 16][step 134900] logloss:0.059363 l2_regular:0.000608 rmse:459.481079 total_loss:0.059970 acc:0.277000\n",
      "[epoch 16][step 135000] logloss:0.052963 l2_regular:0.000608 rmse:525.081482 total_loss:0.053571 acc:0.276000\n",
      "[epoch 16][step 135100] logloss:0.058811 l2_regular:0.000608 rmse:426.850708 total_loss:0.059419 acc:0.242000\n",
      "[epoch 16][step 135200] logloss:0.054427 l2_regular:0.000608 rmse:710.206909 total_loss:0.055035 acc:0.194000\n",
      "[epoch 16][step 135300] logloss:0.052063 l2_regular:0.000608 rmse:507.593292 total_loss:0.052671 acc:0.266000\n",
      "[epoch 16][step 135400] logloss:0.063089 l2_regular:0.000608 rmse:333.275970 total_loss:0.063697 acc:0.188000\n",
      "[epoch 16][step 135500] logloss:0.053823 l2_regular:0.000608 rmse:681.351562 total_loss:0.054431 acc:0.190000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 16][step 135600] logloss:0.057846 l2_regular:0.000608 rmse:520.759705 total_loss:0.058453 acc:0.259000\n",
      "[epoch 16][step 135700] logloss:0.066447 l2_regular:0.000608 rmse:531.849548 total_loss:0.067055 acc:0.319000\n",
      "[epoch 16][step 135800] logloss:0.054740 l2_regular:0.000608 rmse:605.380554 total_loss:0.055347 acc:0.238000\n",
      "[epoch 16][step 135900] logloss:0.071116 l2_regular:0.000608 rmse:404.449066 total_loss:0.071724 acc:0.181000\n",
      "[epoch 16][step 136000] logloss:0.068068 l2_regular:0.000608 rmse:391.698944 total_loss:0.068676 acc:0.128000\n",
      "[epoch 16][step 136100] logloss:0.064875 l2_regular:0.000608 rmse:451.213409 total_loss:0.065483 acc:0.186000\n",
      "[epoch 16][step 136200] logloss:0.055181 l2_regular:0.000608 rmse:430.462769 total_loss:0.055789 acc:0.243000\n",
      "[epoch 16][step 136300] logloss:0.062733 l2_regular:0.000608 rmse:403.532379 total_loss:0.063341 acc:0.252000\n",
      "[epoch 16][step 136400] logloss:0.053805 l2_regular:0.000608 rmse:367.932098 total_loss:0.054413 acc:0.239000\n",
      "[epoch 16][step 136500] logloss:0.071505 l2_regular:0.000608 rmse:382.986725 total_loss:0.072113 acc:0.132000\n",
      "[epoch 16][step 136600] logloss:0.057106 l2_regular:0.000608 rmse:535.548523 total_loss:0.057714 acc:0.304000\n",
      "[epoch 16][step 136700] logloss:0.053510 l2_regular:0.000608 rmse:473.349396 total_loss:0.054118 acc:0.287000\n",
      "[epoch 16][step 136800] logloss:0.067090 l2_regular:0.000608 rmse:494.090057 total_loss:0.067698 acc:0.260000\n",
      "[epoch 16][step 136900] logloss:0.061819 l2_regular:0.000608 rmse:587.283630 total_loss:0.062427 acc:0.230000\n",
      "[epoch 16][step 137000] logloss:0.060933 l2_regular:0.000608 rmse:446.059906 total_loss:0.061540 acc:0.180000\n",
      "[epoch 16][step 137100] logloss:0.067387 l2_regular:0.000608 rmse:469.326660 total_loss:0.067994 acc:0.178000\n",
      "[epoch 16][step 137200] logloss:0.054904 l2_regular:0.000608 rmse:305.670532 total_loss:0.055512 acc:0.267000\n",
      "[epoch 16][step 137300] logloss:0.060487 l2_regular:0.000608 rmse:381.071442 total_loss:0.061094 acc:0.157000\n",
      "[epoch 16][step 137400] logloss:0.057869 l2_regular:0.000608 rmse:529.075562 total_loss:0.058477 acc:0.252000\n",
      "[epoch 16][step 137500] logloss:0.074551 l2_regular:0.000608 rmse:495.393280 total_loss:0.075159 acc:0.162000\n",
      "[epoch 16][step 137600] logloss:0.058123 l2_regular:0.000608 rmse:437.954193 total_loss:0.058731 acc:0.189000\n",
      "[epoch 16][step 137700] logloss:0.067272 l2_regular:0.000608 rmse:841.173889 total_loss:0.067880 acc:0.127000\n",
      "[epoch 16][step 137800] logloss:0.054543 l2_regular:0.000608 rmse:459.024353 total_loss:0.055151 acc:0.231000\n",
      "[epoch 16][step 137900] logloss:0.062798 l2_regular:0.000608 rmse:734.965027 total_loss:0.063405 acc:0.220000\n",
      "[epoch 16][step 138000] logloss:0.054603 l2_regular:0.000608 rmse:559.335754 total_loss:0.055211 acc:0.231000\n",
      "[epoch 16][step 138100] logloss:0.069200 l2_regular:0.000608 rmse:535.226868 total_loss:0.069808 acc:0.197000\n",
      "[epoch 16][step 138200] logloss:0.066251 l2_regular:0.000608 rmse:923.682495 total_loss:0.066858 acc:0.256000\n",
      "[epoch 16][step 138300] logloss:0.054094 l2_regular:0.000608 rmse:485.204285 total_loss:0.054702 acc:0.386000\n",
      "[epoch 16][step 138400] logloss:0.065606 l2_regular:0.000608 rmse:480.460541 total_loss:0.066214 acc:0.203000\n",
      "[epoch 16][step 138500] logloss:0.068928 l2_regular:0.000608 rmse:435.887207 total_loss:0.069536 acc:0.158000\n",
      "[epoch 16][step 138600] logloss:0.060488 l2_regular:0.000608 rmse:393.259369 total_loss:0.061096 acc:0.246000\n",
      "[epoch 16][step 138700] logloss:0.062576 l2_regular:0.000608 rmse:470.787079 total_loss:0.063184 acc:0.200000\n",
      "[epoch 16][step 138800] logloss:0.061853 l2_regular:0.000608 rmse:474.105133 total_loss:0.062461 acc:0.265000\n",
      "[epoch 16][step 138900] logloss:0.074245 l2_regular:0.000608 rmse:487.815948 total_loss:0.074853 acc:0.225000\n",
      "[epoch 16][step 139000] logloss:0.056148 l2_regular:0.000608 rmse:386.098389 total_loss:0.056756 acc:0.208000\n",
      "[epoch 16][step 139100] logloss:0.064136 l2_regular:0.000608 rmse:427.105194 total_loss:0.064744 acc:0.141000\n",
      "[epoch 16][step 139200] logloss:0.059622 l2_regular:0.000608 rmse:441.522308 total_loss:0.060230 acc:0.258000\n",
      "[epoch 16][step 139300] logloss:0.058647 l2_regular:0.000608 rmse:536.898132 total_loss:0.059254 acc:0.210000\n",
      "[epoch 16][step 139400] logloss:0.065453 l2_regular:0.000608 rmse:479.623962 total_loss:0.066061 acc:0.227000\n",
      "[epoch 16][step 139500] logloss:0.064582 l2_regular:0.000608 rmse:481.228455 total_loss:0.065190 acc:0.162000\n",
      "[epoch 16][step 139600] logloss:0.055440 l2_regular:0.000608 rmse:644.545715 total_loss:0.056048 acc:0.232000\n",
      "[epoch 16][step 139700] logloss:0.064189 l2_regular:0.000608 rmse:342.054199 total_loss:0.064797 acc:0.217000\n",
      "[epoch 16][step 139800] logloss:0.055244 l2_regular:0.000608 rmse:469.242981 total_loss:0.055852 acc:0.286000\n",
      "[epoch 16][step 139900] logloss:0.072221 l2_regular:0.000608 rmse:504.014526 total_loss:0.072829 acc:0.190000\n",
      "[epoch 16][step 140000] logloss:0.056644 l2_regular:0.000608 rmse:401.440552 total_loss:0.057251 acc:0.205000\n",
      "[epoch 16][step 140100] logloss:0.057887 l2_regular:0.000608 rmse:475.367188 total_loss:0.058495 acc:0.147000\n",
      "[epoch 16][step 140200] logloss:0.063794 l2_regular:0.000608 rmse:414.773651 total_loss:0.064402 acc:0.217000\n",
      "[epoch 16][step 140300] logloss:0.049887 l2_regular:0.000608 rmse:450.699463 total_loss:0.050495 acc:0.371000\n",
      "[epoch 16][step 140400] logloss:0.058490 l2_regular:0.000608 rmse:411.599701 total_loss:0.059097 acc:0.250000\n",
      "[epoch 16][step 140500] logloss:0.067064 l2_regular:0.000608 rmse:638.920593 total_loss:0.067672 acc:0.274000\n",
      "[epoch 16][step 140600] logloss:0.057081 l2_regular:0.000608 rmse:430.125549 total_loss:0.057689 acc:0.268000\n",
      "[epoch 16][step 140700] logloss:0.071666 l2_regular:0.000608 rmse:456.834747 total_loss:0.072273 acc:0.146000\n",
      "[epoch 16][step 140800] logloss:0.048212 l2_regular:0.000608 rmse:395.918365 total_loss:0.048820 acc:0.337000\n",
      "[epoch 16][step 140900] logloss:0.054024 l2_regular:0.000608 rmse:472.618805 total_loss:0.054632 acc:0.261000\n",
      "[epoch 16][step 141000] logloss:0.060076 l2_regular:0.000608 rmse:431.399689 total_loss:0.060684 acc:0.241000\n",
      "[epoch 16][step 141100] logloss:0.076930 l2_regular:0.000608 rmse:341.675629 total_loss:0.077537 acc:0.153000\n",
      "[epoch 16][step 141200] logloss:0.059337 l2_regular:0.000608 rmse:465.695709 total_loss:0.059945 acc:0.221000\n",
      "[epoch 16][step 141300] logloss:0.050862 l2_regular:0.000608 rmse:425.264923 total_loss:0.051470 acc:0.382000\n",
      "[epoch 16][step 141400] logloss:0.057774 l2_regular:0.000608 rmse:458.512299 total_loss:0.058381 acc:0.261000\n",
      "[epoch 16][step 141500] logloss:0.057238 l2_regular:0.000608 rmse:296.285614 total_loss:0.057846 acc:0.240000\n",
      "[epoch 16][step 141600] logloss:0.064014 l2_regular:0.000608 rmse:387.718719 total_loss:0.064622 acc:0.202000\n",
      "[epoch 16][step 141700] logloss:0.063356 l2_regular:0.000608 rmse:391.109924 total_loss:0.063964 acc:0.218000\n",
      "[epoch 16][step 141800] logloss:0.056979 l2_regular:0.000608 rmse:498.826202 total_loss:0.057587 acc:0.227000\n",
      "[epoch 16][step 141900] logloss:0.049238 l2_regular:0.000608 rmse:401.224792 total_loss:0.049846 acc:0.331000\n",
      "--------------epoch 16 finished —> total batch:8351---------------\n",
      "[epoch 17][step 142000] logloss:0.062298 l2_regular:0.000608 rmse:547.405945 total_loss:0.062906 acc:0.242000\n",
      "[epoch 17][step 142100] logloss:0.064453 l2_regular:0.000608 rmse:394.260864 total_loss:0.065061 acc:0.164000\n",
      "[epoch 17][step 142200] logloss:0.047449 l2_regular:0.000608 rmse:515.016846 total_loss:0.048057 acc:0.245000\n",
      "[epoch 17][step 142300] logloss:0.050128 l2_regular:0.000608 rmse:426.187958 total_loss:0.050736 acc:0.242000\n",
      "[epoch 17][step 142400] logloss:0.056701 l2_regular:0.000608 rmse:426.212769 total_loss:0.057308 acc:0.213000\n",
      "[epoch 17][step 142500] logloss:0.055614 l2_regular:0.000608 rmse:364.626801 total_loss:0.056222 acc:0.239000\n",
      "[epoch 17][step 142600] logloss:0.061768 l2_regular:0.000608 rmse:726.298279 total_loss:0.062376 acc:0.243000\n",
      "[epoch 17][step 142700] logloss:0.057472 l2_regular:0.000608 rmse:502.882080 total_loss:0.058080 acc:0.237000\n",
      "[epoch 17][step 142800] logloss:0.055544 l2_regular:0.000608 rmse:805.060852 total_loss:0.056151 acc:0.278000\n",
      "[epoch 17][step 142900] logloss:0.069492 l2_regular:0.000608 rmse:394.974976 total_loss:0.070100 acc:0.214000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 17][step 143000] logloss:0.060720 l2_regular:0.000608 rmse:388.847443 total_loss:0.061328 acc:0.247000\n",
      "[epoch 17][step 143100] logloss:0.060840 l2_regular:0.000608 rmse:564.300842 total_loss:0.061448 acc:0.175000\n",
      "[epoch 17][step 143200] logloss:0.051118 l2_regular:0.000608 rmse:628.165344 total_loss:0.051726 acc:0.275000\n",
      "[epoch 17][step 143300] logloss:0.058091 l2_regular:0.000608 rmse:477.149597 total_loss:0.058699 acc:0.311000\n",
      "[epoch 17][step 143400] logloss:0.060512 l2_regular:0.000608 rmse:377.786591 total_loss:0.061120 acc:0.218000\n",
      "[epoch 17][step 143500] logloss:0.059329 l2_regular:0.000608 rmse:495.727997 total_loss:0.059937 acc:0.300000\n",
      "[epoch 17][step 143600] logloss:0.066766 l2_regular:0.000608 rmse:352.444183 total_loss:0.067374 acc:0.182000\n",
      "[epoch 17][step 143700] logloss:0.072121 l2_regular:0.000608 rmse:440.539612 total_loss:0.072729 acc:0.200000\n",
      "[epoch 17][step 143800] logloss:0.064072 l2_regular:0.000608 rmse:431.775269 total_loss:0.064680 acc:0.220000\n",
      "[epoch 17][step 143900] logloss:0.058782 l2_regular:0.000608 rmse:390.761932 total_loss:0.059390 acc:0.194000\n",
      "[epoch 17][step 144000] logloss:0.057964 l2_regular:0.000608 rmse:527.584045 total_loss:0.058572 acc:0.285000\n",
      "[epoch 17][step 144100] logloss:0.055150 l2_regular:0.000608 rmse:534.065674 total_loss:0.055758 acc:0.289000\n",
      "[epoch 17][step 144200] logloss:0.057203 l2_regular:0.000608 rmse:481.992096 total_loss:0.057810 acc:0.286000\n",
      "[epoch 17][step 144300] logloss:0.056196 l2_regular:0.000608 rmse:506.979950 total_loss:0.056804 acc:0.197000\n",
      "[epoch 17][step 144400] logloss:0.064591 l2_regular:0.000608 rmse:542.372681 total_loss:0.065199 acc:0.169000\n",
      "[epoch 17][step 144500] logloss:0.064454 l2_regular:0.000608 rmse:444.368317 total_loss:0.065062 acc:0.238000\n",
      "[epoch 17][step 144600] logloss:0.049783 l2_regular:0.000608 rmse:352.654388 total_loss:0.050391 acc:0.413000\n",
      "[epoch 17][step 144700] logloss:0.059023 l2_regular:0.000608 rmse:384.747620 total_loss:0.059631 acc:0.205000\n",
      "[epoch 17][step 144800] logloss:0.059726 l2_regular:0.000608 rmse:351.293884 total_loss:0.060333 acc:0.330000\n",
      "[epoch 17][step 144900] logloss:0.060218 l2_regular:0.000608 rmse:395.903961 total_loss:0.060826 acc:0.290000\n",
      "[epoch 17][step 145000] logloss:0.050686 l2_regular:0.000608 rmse:370.876801 total_loss:0.051294 acc:0.229000\n",
      "[epoch 17][step 145100] logloss:0.050239 l2_regular:0.000608 rmse:454.326569 total_loss:0.050846 acc:0.347000\n",
      "[epoch 17][step 145200] logloss:0.073316 l2_regular:0.000608 rmse:405.551453 total_loss:0.073924 acc:0.167000\n",
      "[epoch 17][step 145300] logloss:0.066729 l2_regular:0.000608 rmse:540.655823 total_loss:0.067336 acc:0.213000\n",
      "[epoch 17][step 145400] logloss:0.058231 l2_regular:0.000608 rmse:425.139221 total_loss:0.058839 acc:0.276000\n",
      "[epoch 17][step 145500] logloss:0.062929 l2_regular:0.000608 rmse:483.123505 total_loss:0.063537 acc:0.225000\n",
      "[epoch 17][step 145600] logloss:0.053689 l2_regular:0.000608 rmse:567.159119 total_loss:0.054297 acc:0.273000\n",
      "[epoch 17][step 145700] logloss:0.063576 l2_regular:0.000608 rmse:349.610382 total_loss:0.064183 acc:0.227000\n",
      "[epoch 17][step 145800] logloss:0.062556 l2_regular:0.000608 rmse:386.894012 total_loss:0.063163 acc:0.357000\n",
      "[epoch 17][step 145900] logloss:0.058672 l2_regular:0.000608 rmse:827.939087 total_loss:0.059280 acc:0.222000\n",
      "[epoch 17][step 146000] logloss:0.074925 l2_regular:0.000608 rmse:415.581146 total_loss:0.075533 acc:0.173000\n",
      "[epoch 17][step 146100] logloss:0.060668 l2_regular:0.000608 rmse:391.670471 total_loss:0.061276 acc:0.251000\n",
      "[epoch 17][step 146200] logloss:0.063588 l2_regular:0.000608 rmse:432.914276 total_loss:0.064196 acc:0.201000\n",
      "[epoch 17][step 146300] logloss:0.063914 l2_regular:0.000608 rmse:519.583557 total_loss:0.064522 acc:0.206000\n",
      "[epoch 17][step 146400] logloss:0.053940 l2_regular:0.000608 rmse:461.332306 total_loss:0.054548 acc:0.256000\n",
      "[epoch 17][step 146500] logloss:0.065239 l2_regular:0.000608 rmse:480.981415 total_loss:0.065846 acc:0.225000\n",
      "[epoch 17][step 146600] logloss:0.061991 l2_regular:0.000608 rmse:1031.045044 total_loss:0.062599 acc:0.373000\n",
      "[epoch 17][step 146700] logloss:0.058276 l2_regular:0.000608 rmse:419.661346 total_loss:0.058884 acc:0.271000\n",
      "[epoch 17][step 146800] logloss:0.053563 l2_regular:0.000608 rmse:497.319275 total_loss:0.054171 acc:0.393000\n",
      "[epoch 17][step 146900] logloss:0.063858 l2_regular:0.000608 rmse:596.676392 total_loss:0.064466 acc:0.239000\n",
      "[epoch 17][step 147000] logloss:0.060047 l2_regular:0.000608 rmse:482.843536 total_loss:0.060655 acc:0.236000\n",
      "[epoch 17][step 147100] logloss:0.063362 l2_regular:0.000608 rmse:485.819336 total_loss:0.063970 acc:0.250000\n",
      "[epoch 17][step 147200] logloss:0.057970 l2_regular:0.000608 rmse:380.151825 total_loss:0.058578 acc:0.238000\n",
      "[epoch 17][step 147300] logloss:0.068974 l2_regular:0.000608 rmse:545.519592 total_loss:0.069582 acc:0.177000\n",
      "[epoch 17][step 147400] logloss:0.060963 l2_regular:0.000608 rmse:538.708984 total_loss:0.061571 acc:0.253000\n",
      "[epoch 17][step 147500] logloss:0.051403 l2_regular:0.000608 rmse:387.356842 total_loss:0.052011 acc:0.294000\n",
      "[epoch 17][step 147600] logloss:0.075124 l2_regular:0.000608 rmse:415.995575 total_loss:0.075732 acc:0.178000\n",
      "[epoch 17][step 147700] logloss:0.050344 l2_regular:0.000608 rmse:395.876312 total_loss:0.050952 acc:0.247000\n",
      "[epoch 17][step 147800] logloss:0.053677 l2_regular:0.000608 rmse:456.330841 total_loss:0.054285 acc:0.277000\n",
      "[epoch 17][step 147900] logloss:0.060166 l2_regular:0.000608 rmse:418.726654 total_loss:0.060774 acc:0.337000\n",
      "[epoch 17][step 148000] logloss:0.061373 l2_regular:0.000608 rmse:435.227295 total_loss:0.061981 acc:0.269000\n",
      "[epoch 17][step 148100] logloss:0.050933 l2_regular:0.000608 rmse:544.347534 total_loss:0.051541 acc:0.242000\n",
      "[epoch 17][step 148200] logloss:0.062065 l2_regular:0.000608 rmse:430.496979 total_loss:0.062673 acc:0.247000\n",
      "[epoch 17][step 148300] logloss:0.047893 l2_regular:0.000608 rmse:546.094849 total_loss:0.048501 acc:0.247000\n",
      "[epoch 17][step 148400] logloss:0.055118 l2_regular:0.000608 rmse:450.307587 total_loss:0.055726 acc:0.322000\n",
      "[epoch 17][step 148500] logloss:0.046057 l2_regular:0.000608 rmse:474.300476 total_loss:0.046665 acc:0.346000\n",
      "[epoch 17][step 148600] logloss:0.060949 l2_regular:0.000608 rmse:501.700867 total_loss:0.061557 acc:0.292000\n",
      "[epoch 17][step 148700] logloss:0.057363 l2_regular:0.000608 rmse:436.879211 total_loss:0.057970 acc:0.330000\n",
      "[epoch 17][step 148800] logloss:0.068795 l2_regular:0.000608 rmse:474.196991 total_loss:0.069402 acc:0.197000\n",
      "[epoch 17][step 148900] logloss:0.055590 l2_regular:0.000608 rmse:795.884155 total_loss:0.056198 acc:0.225000\n",
      "[epoch 17][step 149000] logloss:0.057099 l2_regular:0.000608 rmse:343.348511 total_loss:0.057707 acc:0.207000\n",
      "[epoch 17][step 149100] logloss:0.061423 l2_regular:0.000608 rmse:525.615540 total_loss:0.062031 acc:0.221000\n",
      "[epoch 17][step 149200] logloss:0.057104 l2_regular:0.000608 rmse:726.533447 total_loss:0.057711 acc:0.293000\n",
      "[epoch 17][step 149300] logloss:0.057309 l2_regular:0.000608 rmse:355.743011 total_loss:0.057917 acc:0.145000\n",
      "[epoch 17][step 149400] logloss:0.055702 l2_regular:0.000608 rmse:452.694611 total_loss:0.056310 acc:0.268000\n",
      "[epoch 17][step 149500] logloss:0.044525 l2_regular:0.000608 rmse:424.741516 total_loss:0.045133 acc:0.357000\n",
      "[epoch 17][step 149600] logloss:0.057801 l2_regular:0.000608 rmse:475.973999 total_loss:0.058409 acc:0.265000\n",
      "[epoch 17][step 149700] logloss:0.069223 l2_regular:0.000608 rmse:423.649445 total_loss:0.069831 acc:0.238000\n",
      "[epoch 17][step 149800] logloss:0.058203 l2_regular:0.000608 rmse:452.687836 total_loss:0.058811 acc:0.254000\n",
      "[epoch 17][step 149900] logloss:0.070600 l2_regular:0.000608 rmse:554.702820 total_loss:0.071208 acc:0.294000\n",
      "[epoch 17][step 150000] logloss:0.060534 l2_regular:0.000608 rmse:770.160278 total_loss:0.061142 acc:0.202000\n",
      "[epoch 17][step 150100] logloss:0.052375 l2_regular:0.000608 rmse:588.095886 total_loss:0.052983 acc:0.387000\n",
      "[epoch 17][step 150200] logloss:0.058196 l2_regular:0.000608 rmse:527.333069 total_loss:0.058804 acc:0.184000\n",
      "[epoch 17][step 150300] logloss:0.057222 l2_regular:0.000608 rmse:660.030273 total_loss:0.057830 acc:0.291000\n",
      "--------------epoch 17 finished —> total batch:8351---------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 18][step 150400] logloss:0.059837 l2_regular:0.000608 rmse:419.989319 total_loss:0.060445 acc:0.276000\n",
      "[epoch 18][step 150500] logloss:0.065514 l2_regular:0.000608 rmse:512.008789 total_loss:0.066122 acc:0.250000\n",
      "[epoch 18][step 150600] logloss:0.063670 l2_regular:0.000608 rmse:447.211243 total_loss:0.064278 acc:0.227000\n",
      "[epoch 18][step 150700] logloss:0.055616 l2_regular:0.000608 rmse:387.156525 total_loss:0.056224 acc:0.174000\n",
      "[epoch 18][step 150800] logloss:0.058830 l2_regular:0.000608 rmse:435.421509 total_loss:0.059438 acc:0.366000\n",
      "[epoch 18][step 150900] logloss:0.053502 l2_regular:0.000608 rmse:484.154724 total_loss:0.054110 acc:0.180000\n",
      "[epoch 18][step 151000] logloss:0.057125 l2_regular:0.000608 rmse:339.417572 total_loss:0.057733 acc:0.281000\n",
      "[epoch 18][step 151100] logloss:0.062233 l2_regular:0.000608 rmse:423.013458 total_loss:0.062841 acc:0.266000\n",
      "[epoch 18][step 151200] logloss:0.056553 l2_regular:0.000608 rmse:544.298035 total_loss:0.057161 acc:0.247000\n",
      "[epoch 18][step 151300] logloss:0.053984 l2_regular:0.000608 rmse:593.924133 total_loss:0.054591 acc:0.260000\n",
      "[epoch 18][step 151400] logloss:0.060351 l2_regular:0.000608 rmse:669.775085 total_loss:0.060959 acc:0.275000\n",
      "[epoch 18][step 151500] logloss:0.060825 l2_regular:0.000608 rmse:757.013062 total_loss:0.061433 acc:0.280000\n",
      "[epoch 18][step 151600] logloss:0.071220 l2_regular:0.000608 rmse:399.417847 total_loss:0.071828 acc:0.185000\n",
      "[epoch 18][step 151700] logloss:0.057870 l2_regular:0.000608 rmse:528.689270 total_loss:0.058478 acc:0.194000\n",
      "[epoch 18][step 151800] logloss:0.061028 l2_regular:0.000608 rmse:586.242859 total_loss:0.061635 acc:0.213000\n",
      "[epoch 18][step 151900] logloss:0.058628 l2_regular:0.000608 rmse:511.145020 total_loss:0.059236 acc:0.251000\n",
      "[epoch 18][step 152000] logloss:0.075266 l2_regular:0.000608 rmse:535.437805 total_loss:0.075873 acc:0.143000\n",
      "[epoch 18][step 152100] logloss:0.057404 l2_regular:0.000608 rmse:448.111389 total_loss:0.058012 acc:0.270000\n",
      "[epoch 18][step 152200] logloss:0.060405 l2_regular:0.000608 rmse:557.145752 total_loss:0.061013 acc:0.320000\n",
      "[epoch 18][step 152300] logloss:0.048927 l2_regular:0.000608 rmse:475.639801 total_loss:0.049535 acc:0.319000\n",
      "[epoch 18][step 152400] logloss:0.068832 l2_regular:0.000608 rmse:917.783875 total_loss:0.069440 acc:0.184000\n",
      "[epoch 18][step 152500] logloss:0.054225 l2_regular:0.000608 rmse:568.407288 total_loss:0.054833 acc:0.262000\n",
      "[epoch 18][step 152600] logloss:0.055478 l2_regular:0.000608 rmse:527.849487 total_loss:0.056086 acc:0.177000\n",
      "[epoch 18][step 152700] logloss:0.057367 l2_regular:0.000608 rmse:405.599915 total_loss:0.057975 acc:0.270000\n",
      "[epoch 18][step 152800] logloss:0.060750 l2_regular:0.000608 rmse:480.613464 total_loss:0.061358 acc:0.229000\n",
      "[epoch 18][step 152900] logloss:0.062450 l2_regular:0.000608 rmse:543.578552 total_loss:0.063057 acc:0.217000\n",
      "[epoch 18][step 153000] logloss:0.062306 l2_regular:0.000608 rmse:419.193176 total_loss:0.062914 acc:0.207000\n",
      "[epoch 18][step 153100] logloss:0.058954 l2_regular:0.000608 rmse:477.046082 total_loss:0.059561 acc:0.243000\n",
      "[epoch 18][step 153200] logloss:0.066064 l2_regular:0.000608 rmse:460.694885 total_loss:0.066671 acc:0.206000\n",
      "[epoch 18][step 153300] logloss:0.051252 l2_regular:0.000608 rmse:331.298615 total_loss:0.051860 acc:0.240000\n",
      "[epoch 18][step 153400] logloss:0.059068 l2_regular:0.000608 rmse:468.693756 total_loss:0.059676 acc:0.351000\n",
      "[epoch 18][step 153500] logloss:0.069009 l2_regular:0.000608 rmse:482.262207 total_loss:0.069617 acc:0.174000\n",
      "[epoch 18][step 153600] logloss:0.059819 l2_regular:0.000608 rmse:376.741760 total_loss:0.060427 acc:0.335000\n",
      "[epoch 18][step 153700] logloss:0.059748 l2_regular:0.000608 rmse:479.596191 total_loss:0.060356 acc:0.231000\n",
      "[epoch 18][step 153800] logloss:0.053240 l2_regular:0.000608 rmse:562.538025 total_loss:0.053848 acc:0.242000\n",
      "[epoch 18][step 153900] logloss:0.062356 l2_regular:0.000608 rmse:391.903442 total_loss:0.062964 acc:0.212000\n",
      "[epoch 18][step 154000] logloss:0.064693 l2_regular:0.000608 rmse:531.335205 total_loss:0.065301 acc:0.180000\n",
      "[epoch 18][step 154100] logloss:0.064028 l2_regular:0.000608 rmse:521.701355 total_loss:0.064635 acc:0.214000\n",
      "[epoch 18][step 154200] logloss:0.062282 l2_regular:0.000608 rmse:637.449768 total_loss:0.062890 acc:0.225000\n",
      "[epoch 18][step 154300] logloss:0.068710 l2_regular:0.000608 rmse:584.191895 total_loss:0.069318 acc:0.161000\n",
      "[epoch 18][step 154400] logloss:0.065072 l2_regular:0.000608 rmse:585.637939 total_loss:0.065680 acc:0.271000\n",
      "[epoch 18][step 154500] logloss:0.059832 l2_regular:0.000608 rmse:446.599640 total_loss:0.060440 acc:0.258000\n",
      "[epoch 18][step 154600] logloss:0.069345 l2_regular:0.000608 rmse:574.758179 total_loss:0.069953 acc:0.182000\n",
      "[epoch 18][step 154700] logloss:0.058295 l2_regular:0.000608 rmse:341.034119 total_loss:0.058903 acc:0.086000\n",
      "[epoch 18][step 154800] logloss:0.061827 l2_regular:0.000608 rmse:426.972809 total_loss:0.062435 acc:0.219000\n",
      "[epoch 18][step 154900] logloss:0.058636 l2_regular:0.000608 rmse:612.519165 total_loss:0.059244 acc:0.187000\n",
      "[epoch 18][step 155000] logloss:0.058008 l2_regular:0.000608 rmse:428.508392 total_loss:0.058616 acc:0.229000\n",
      "[epoch 18][step 155100] logloss:0.065923 l2_regular:0.000608 rmse:425.578827 total_loss:0.066531 acc:0.194000\n",
      "[epoch 18][step 155200] logloss:0.060234 l2_regular:0.000608 rmse:435.529114 total_loss:0.060841 acc:0.244000\n",
      "[epoch 18][step 155300] logloss:0.058296 l2_regular:0.000608 rmse:391.935608 total_loss:0.058904 acc:0.275000\n",
      "[epoch 18][step 155400] logloss:0.063707 l2_regular:0.000608 rmse:427.550537 total_loss:0.064315 acc:0.220000\n",
      "[epoch 18][step 155500] logloss:0.060241 l2_regular:0.000608 rmse:374.041718 total_loss:0.060849 acc:0.206000\n",
      "[epoch 18][step 155600] logloss:0.060807 l2_regular:0.000608 rmse:454.633240 total_loss:0.061415 acc:0.220000\n",
      "[epoch 18][step 155700] logloss:0.059788 l2_regular:0.000608 rmse:582.078979 total_loss:0.060396 acc:0.258000\n",
      "[epoch 18][step 155800] logloss:0.055584 l2_regular:0.000608 rmse:440.102905 total_loss:0.056191 acc:0.162000\n",
      "[epoch 18][step 155900] logloss:0.063278 l2_regular:0.000608 rmse:692.780762 total_loss:0.063886 acc:0.173000\n",
      "[epoch 18][step 156000] logloss:0.061501 l2_regular:0.000608 rmse:441.260376 total_loss:0.062109 acc:0.247000\n",
      "[epoch 18][step 156100] logloss:0.057564 l2_regular:0.000608 rmse:571.070190 total_loss:0.058172 acc:0.214000\n",
      "[epoch 18][step 156200] logloss:0.069987 l2_regular:0.000608 rmse:442.060669 total_loss:0.070595 acc:0.201000\n",
      "[epoch 18][step 156300] logloss:0.063643 l2_regular:0.000608 rmse:518.214783 total_loss:0.064251 acc:0.273000\n",
      "[epoch 18][step 156400] logloss:0.065312 l2_regular:0.000608 rmse:586.206543 total_loss:0.065920 acc:0.135000\n",
      "[epoch 18][step 156500] logloss:0.059331 l2_regular:0.000608 rmse:445.369965 total_loss:0.059939 acc:0.245000\n",
      "[epoch 18][step 156600] logloss:0.070864 l2_regular:0.000608 rmse:498.521484 total_loss:0.071472 acc:0.125000\n",
      "[epoch 18][step 156700] logloss:0.059062 l2_regular:0.000608 rmse:402.765411 total_loss:0.059670 acc:0.146000\n",
      "[epoch 18][step 156800] logloss:0.054815 l2_regular:0.000608 rmse:439.982605 total_loss:0.055423 acc:0.254000\n",
      "[epoch 18][step 156900] logloss:0.060744 l2_regular:0.000608 rmse:377.442688 total_loss:0.061352 acc:0.268000\n",
      "[epoch 18][step 157000] logloss:0.063338 l2_regular:0.000608 rmse:471.471405 total_loss:0.063946 acc:0.226000\n",
      "[epoch 18][step 157100] logloss:0.059925 l2_regular:0.000608 rmse:400.381287 total_loss:0.060533 acc:0.297000\n",
      "[epoch 18][step 157200] logloss:0.059603 l2_regular:0.000608 rmse:473.545105 total_loss:0.060211 acc:0.235000\n",
      "[epoch 18][step 157300] logloss:0.058706 l2_regular:0.000608 rmse:434.343842 total_loss:0.059313 acc:0.328000\n",
      "[epoch 18][step 157400] logloss:0.055372 l2_regular:0.000608 rmse:479.833221 total_loss:0.055980 acc:0.331000\n",
      "[epoch 18][step 157500] logloss:0.066219 l2_regular:0.000608 rmse:433.290344 total_loss:0.066827 acc:0.193000\n",
      "[epoch 18][step 157600] logloss:0.059764 l2_regular:0.000608 rmse:434.541656 total_loss:0.060371 acc:0.358000\n",
      "[epoch 18][step 157700] logloss:0.051949 l2_regular:0.000608 rmse:416.733459 total_loss:0.052557 acc:0.339000\n",
      "[epoch 18][step 157800] logloss:0.054407 l2_regular:0.000608 rmse:403.131531 total_loss:0.055014 acc:0.269000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 18][step 157900] logloss:0.049100 l2_regular:0.000608 rmse:531.985779 total_loss:0.049708 acc:0.316000\n",
      "[epoch 18][step 158000] logloss:0.055771 l2_regular:0.000608 rmse:406.628387 total_loss:0.056379 acc:0.296000\n",
      "[epoch 18][step 158100] logloss:0.060804 l2_regular:0.000608 rmse:447.489685 total_loss:0.061412 acc:0.203000\n",
      "[epoch 18][step 158200] logloss:0.054481 l2_regular:0.000608 rmse:396.312805 total_loss:0.055089 acc:0.331000\n",
      "[epoch 18][step 158300] logloss:0.056584 l2_regular:0.000608 rmse:454.858002 total_loss:0.057191 acc:0.315000\n",
      "[epoch 18][step 158400] logloss:0.056701 l2_regular:0.000608 rmse:352.042419 total_loss:0.057308 acc:0.202000\n",
      "[epoch 18][step 158500] logloss:0.050048 l2_regular:0.000608 rmse:337.081085 total_loss:0.050656 acc:0.282000\n",
      "[epoch 18][step 158600] logloss:0.073135 l2_regular:0.000608 rmse:398.496674 total_loss:0.073743 acc:0.176000\n",
      "--------------epoch 18 finished —> total batch:8351---------------\n",
      "[epoch 19][step 158700] logloss:0.063783 l2_regular:0.000608 rmse:601.542419 total_loss:0.064391 acc:0.243000\n",
      "[epoch 19][step 158800] logloss:0.066177 l2_regular:0.000608 rmse:354.426300 total_loss:0.066785 acc:0.227000\n",
      "[epoch 19][step 158900] logloss:0.054483 l2_regular:0.000608 rmse:1025.971802 total_loss:0.055091 acc:0.273000\n",
      "[epoch 19][step 159000] logloss:0.064208 l2_regular:0.000608 rmse:451.846191 total_loss:0.064815 acc:0.267000\n",
      "[epoch 19][step 159100] logloss:0.059554 l2_regular:0.000608 rmse:468.385193 total_loss:0.060162 acc:0.180000\n",
      "[epoch 19][step 159200] logloss:0.068882 l2_regular:0.000608 rmse:460.609039 total_loss:0.069490 acc:0.241000\n",
      "[epoch 19][step 159300] logloss:0.057564 l2_regular:0.000608 rmse:470.293427 total_loss:0.058172 acc:0.212000\n",
      "[epoch 19][step 159400] logloss:0.054468 l2_regular:0.000608 rmse:601.474609 total_loss:0.055076 acc:0.307000\n",
      "[epoch 19][step 159500] logloss:0.058569 l2_regular:0.000608 rmse:423.008301 total_loss:0.059177 acc:0.287000\n",
      "[epoch 19][step 159600] logloss:0.063828 l2_regular:0.000608 rmse:552.054138 total_loss:0.064436 acc:0.283000\n",
      "[epoch 19][step 159700] logloss:0.071803 l2_regular:0.000608 rmse:704.362915 total_loss:0.072410 acc:0.193000\n",
      "[epoch 19][step 159800] logloss:0.059491 l2_regular:0.000608 rmse:461.871735 total_loss:0.060099 acc:0.281000\n",
      "[epoch 19][step 159900] logloss:0.068628 l2_regular:0.000608 rmse:501.874878 total_loss:0.069236 acc:0.201000\n",
      "[epoch 19][step 160000] logloss:0.060334 l2_regular:0.000608 rmse:489.997955 total_loss:0.060942 acc:0.244000\n",
      "[epoch 19][step 160100] logloss:0.060712 l2_regular:0.000608 rmse:425.429382 total_loss:0.061320 acc:0.204000\n",
      "[epoch 19][step 160200] logloss:0.071639 l2_regular:0.000608 rmse:514.114624 total_loss:0.072247 acc:0.251000\n",
      "[epoch 19][step 160300] logloss:0.069786 l2_regular:0.000608 rmse:664.213806 total_loss:0.070394 acc:0.163000\n",
      "[epoch 19][step 160400] logloss:0.056900 l2_regular:0.000608 rmse:385.677246 total_loss:0.057508 acc:0.165000\n",
      "[epoch 19][step 160500] logloss:0.069385 l2_regular:0.000608 rmse:483.044098 total_loss:0.069993 acc:0.162000\n",
      "[epoch 19][step 160600] logloss:0.060385 l2_regular:0.000608 rmse:513.868469 total_loss:0.060992 acc:0.145000\n",
      "[epoch 19][step 160700] logloss:0.053644 l2_regular:0.000608 rmse:420.650970 total_loss:0.054251 acc:0.308000\n",
      "[epoch 19][step 160800] logloss:0.064780 l2_regular:0.000608 rmse:359.303375 total_loss:0.065388 acc:0.280000\n",
      "[epoch 19][step 160900] logloss:0.058864 l2_regular:0.000608 rmse:464.709076 total_loss:0.059471 acc:0.272000\n",
      "[epoch 19][step 161000] logloss:0.062033 l2_regular:0.000608 rmse:413.729187 total_loss:0.062641 acc:0.330000\n",
      "[epoch 19][step 161100] logloss:0.065280 l2_regular:0.000608 rmse:536.162048 total_loss:0.065888 acc:0.193000\n",
      "[epoch 19][step 161200] logloss:0.064248 l2_regular:0.000608 rmse:304.286652 total_loss:0.064856 acc:0.165000\n",
      "[epoch 19][step 161300] logloss:0.066275 l2_regular:0.000608 rmse:462.443939 total_loss:0.066882 acc:0.142000\n",
      "[epoch 19][step 161400] logloss:0.060002 l2_regular:0.000608 rmse:489.964355 total_loss:0.060610 acc:0.211000\n",
      "[epoch 19][step 161500] logloss:0.052500 l2_regular:0.000608 rmse:372.432281 total_loss:0.053108 acc:0.201000\n",
      "[epoch 19][step 161600] logloss:0.055975 l2_regular:0.000608 rmse:356.954071 total_loss:0.056583 acc:0.214000\n",
      "[epoch 19][step 161700] logloss:0.053580 l2_regular:0.000608 rmse:482.842468 total_loss:0.054188 acc:0.240000\n",
      "[epoch 19][step 161800] logloss:0.075849 l2_regular:0.000608 rmse:536.321350 total_loss:0.076457 acc:0.199000\n",
      "[epoch 19][step 161900] logloss:0.064074 l2_regular:0.000608 rmse:443.299286 total_loss:0.064682 acc:0.185000\n",
      "[epoch 19][step 162000] logloss:0.057824 l2_regular:0.000608 rmse:428.588684 total_loss:0.058432 acc:0.278000\n",
      "[epoch 19][step 162100] logloss:0.049605 l2_regular:0.000608 rmse:401.977905 total_loss:0.050213 acc:0.331000\n",
      "[epoch 19][step 162200] logloss:0.062793 l2_regular:0.000608 rmse:858.711487 total_loss:0.063401 acc:0.267000\n",
      "[epoch 19][step 162300] logloss:0.061497 l2_regular:0.000608 rmse:545.167908 total_loss:0.062105 acc:0.201000\n",
      "[epoch 19][step 162400] logloss:0.062805 l2_regular:0.000608 rmse:374.288483 total_loss:0.063412 acc:0.226000\n",
      "[epoch 19][step 162500] logloss:0.057051 l2_regular:0.000608 rmse:439.719452 total_loss:0.057659 acc:0.244000\n",
      "[epoch 19][step 162600] logloss:0.053507 l2_regular:0.000608 rmse:379.803619 total_loss:0.054115 acc:0.338000\n",
      "[epoch 19][step 162700] logloss:0.060016 l2_regular:0.000608 rmse:604.443359 total_loss:0.060624 acc:0.187000\n",
      "[epoch 19][step 162800] logloss:0.074954 l2_regular:0.000608 rmse:498.900513 total_loss:0.075561 acc:0.110000\n",
      "[epoch 19][step 162900] logloss:0.060703 l2_regular:0.000608 rmse:631.156311 total_loss:0.061311 acc:0.332000\n",
      "[epoch 19][step 163000] logloss:0.060485 l2_regular:0.000608 rmse:357.763153 total_loss:0.061093 acc:0.247000\n",
      "[epoch 19][step 163100] logloss:0.063301 l2_regular:0.000608 rmse:539.976990 total_loss:0.063909 acc:0.248000\n",
      "[epoch 19][step 163200] logloss:0.066594 l2_regular:0.000608 rmse:517.380432 total_loss:0.067202 acc:0.220000\n",
      "[epoch 19][step 163300] logloss:0.062907 l2_regular:0.000608 rmse:531.079468 total_loss:0.063515 acc:0.275000\n",
      "[epoch 19][step 163400] logloss:0.071758 l2_regular:0.000608 rmse:366.491058 total_loss:0.072366 acc:0.232000\n",
      "[epoch 19][step 163500] logloss:0.056080 l2_regular:0.000608 rmse:402.631195 total_loss:0.056687 acc:0.266000\n",
      "[epoch 19][step 163600] logloss:0.057559 l2_regular:0.000608 rmse:416.959015 total_loss:0.058167 acc:0.319000\n",
      "[epoch 19][step 163700] logloss:0.059811 l2_regular:0.000608 rmse:452.987946 total_loss:0.060419 acc:0.243000\n",
      "[epoch 19][step 163800] logloss:0.058166 l2_regular:0.000608 rmse:498.769287 total_loss:0.058774 acc:0.272000\n",
      "[epoch 19][step 163900] logloss:0.057476 l2_regular:0.000608 rmse:519.066711 total_loss:0.058084 acc:0.237000\n",
      "[epoch 19][step 164000] logloss:0.059361 l2_regular:0.000608 rmse:381.108124 total_loss:0.059969 acc:0.210000\n",
      "[epoch 19][step 164100] logloss:0.049218 l2_regular:0.000608 rmse:451.070801 total_loss:0.049825 acc:0.319000\n",
      "[epoch 19][step 164200] logloss:0.055749 l2_regular:0.000608 rmse:501.463287 total_loss:0.056356 acc:0.194000\n",
      "[epoch 19][step 164300] logloss:0.060835 l2_regular:0.000608 rmse:565.149048 total_loss:0.061443 acc:0.231000\n",
      "[epoch 19][step 164400] logloss:0.056715 l2_regular:0.000608 rmse:378.285370 total_loss:0.057323 acc:0.266000\n",
      "[epoch 19][step 164500] logloss:0.053278 l2_regular:0.000608 rmse:458.914978 total_loss:0.053886 acc:0.340000\n",
      "[epoch 19][step 164600] logloss:0.070530 l2_regular:0.000608 rmse:463.051941 total_loss:0.071138 acc:0.205000\n",
      "[epoch 19][step 164700] logloss:0.045709 l2_regular:0.000608 rmse:397.407959 total_loss:0.046317 acc:0.338000\n",
      "[epoch 19][step 164800] logloss:0.054168 l2_regular:0.000608 rmse:469.389771 total_loss:0.054776 acc:0.321000\n",
      "[epoch 19][step 164900] logloss:0.055530 l2_regular:0.000608 rmse:544.124695 total_loss:0.056138 acc:0.226000\n",
      "[epoch 19][step 165000] logloss:0.073998 l2_regular:0.000608 rmse:580.484924 total_loss:0.074605 acc:0.184000\n",
      "[epoch 19][step 165100] logloss:0.064373 l2_regular:0.000608 rmse:550.984802 total_loss:0.064981 acc:0.264000\n",
      "[epoch 19][step 165200] logloss:0.062847 l2_regular:0.000608 rmse:558.720886 total_loss:0.063455 acc:0.211000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 19][step 165300] logloss:0.066280 l2_regular:0.000608 rmse:517.643188 total_loss:0.066887 acc:0.174000\n",
      "[epoch 19][step 165400] logloss:0.056551 l2_regular:0.000608 rmse:480.495667 total_loss:0.057158 acc:0.270000\n",
      "[epoch 19][step 165500] logloss:0.058583 l2_regular:0.000608 rmse:781.939514 total_loss:0.059191 acc:0.219000\n",
      "[epoch 19][step 165600] logloss:0.060117 l2_regular:0.000608 rmse:504.803772 total_loss:0.060725 acc:0.229000\n",
      "[epoch 19][step 165700] logloss:0.066260 l2_regular:0.000608 rmse:467.209229 total_loss:0.066868 acc:0.202000\n",
      "[epoch 19][step 165800] logloss:0.053220 l2_regular:0.000608 rmse:425.912781 total_loss:0.053828 acc:0.260000\n",
      "[epoch 19][step 165900] logloss:0.074156 l2_regular:0.000608 rmse:2746.094971 total_loss:0.074764 acc:0.220000\n",
      "[epoch 19][step 166000] logloss:0.050363 l2_regular:0.000608 rmse:479.766693 total_loss:0.050971 acc:0.237000\n",
      "[epoch 19][step 166100] logloss:0.073097 l2_regular:0.000608 rmse:416.576416 total_loss:0.073704 acc:0.108000\n",
      "[epoch 19][step 166200] logloss:0.062902 l2_regular:0.000608 rmse:363.788300 total_loss:0.063510 acc:0.314000\n",
      "[epoch 19][step 166300] logloss:0.062169 l2_regular:0.000608 rmse:377.209686 total_loss:0.062777 acc:0.177000\n",
      "[epoch 19][step 166400] logloss:0.059343 l2_regular:0.000608 rmse:318.518524 total_loss:0.059951 acc:0.437000\n",
      "[epoch 19][step 166500] logloss:0.051608 l2_regular:0.000608 rmse:653.111877 total_loss:0.052216 acc:0.440000\n",
      "[epoch 19][step 166600] logloss:0.049787 l2_regular:0.000608 rmse:476.314362 total_loss:0.050395 acc:0.310000\n",
      "[epoch 19][step 166700] logloss:0.043174 l2_regular:0.000608 rmse:549.349060 total_loss:0.043782 acc:0.373000\n",
      "[epoch 19][step 166800] logloss:0.058137 l2_regular:0.000608 rmse:541.129089 total_loss:0.058744 acc:0.233000\n",
      "[epoch 19][step 166900] logloss:0.064100 l2_regular:0.000608 rmse:586.114746 total_loss:0.064708 acc:0.180000\n",
      "[epoch 19][step 167000] logloss:0.054631 l2_regular:0.000608 rmse:426.484680 total_loss:0.055238 acc:0.183000\n",
      "--------------epoch 19 finished —> total batch:8351---------------\n",
      "[epoch 20][step 167100] logloss:0.057876 l2_regular:0.000608 rmse:386.224243 total_loss:0.058484 acc:0.214000\n",
      "[epoch 20][step 167200] logloss:0.057245 l2_regular:0.000608 rmse:431.069672 total_loss:0.057852 acc:0.336000\n",
      "[epoch 20][step 167300] logloss:0.059226 l2_regular:0.000608 rmse:461.114410 total_loss:0.059833 acc:0.277000\n",
      "[epoch 20][step 167400] logloss:0.062695 l2_regular:0.000608 rmse:527.056213 total_loss:0.063302 acc:0.258000\n",
      "[epoch 20][step 167500] logloss:0.057036 l2_regular:0.000608 rmse:414.959137 total_loss:0.057643 acc:0.306000\n",
      "[epoch 20][step 167600] logloss:0.058981 l2_regular:0.000608 rmse:443.084381 total_loss:0.059589 acc:0.200000\n",
      "[epoch 20][step 167700] logloss:0.065865 l2_regular:0.000608 rmse:581.870850 total_loss:0.066473 acc:0.251000\n",
      "[epoch 20][step 167800] logloss:0.054692 l2_regular:0.000608 rmse:600.874451 total_loss:0.055300 acc:0.237000\n",
      "[epoch 20][step 167900] logloss:0.069452 l2_regular:0.000608 rmse:445.490662 total_loss:0.070059 acc:0.195000\n",
      "[epoch 20][step 168000] logloss:0.059011 l2_regular:0.000608 rmse:605.442749 total_loss:0.059618 acc:0.276000\n",
      "[epoch 20][step 168100] logloss:0.058118 l2_regular:0.000608 rmse:475.936401 total_loss:0.058726 acc:0.259000\n",
      "[epoch 20][step 168200] logloss:0.053167 l2_regular:0.000608 rmse:444.681915 total_loss:0.053774 acc:0.324000\n",
      "[epoch 20][step 168300] logloss:0.068801 l2_regular:0.000608 rmse:676.385437 total_loss:0.069409 acc:0.216000\n",
      "[epoch 20][step 168400] logloss:0.055729 l2_regular:0.000608 rmse:454.047943 total_loss:0.056337 acc:0.310000\n",
      "[epoch 20][step 168500] logloss:0.053724 l2_regular:0.000608 rmse:424.173065 total_loss:0.054332 acc:0.204000\n",
      "[epoch 20][step 168600] logloss:0.053292 l2_regular:0.000608 rmse:716.977661 total_loss:0.053900 acc:0.242000\n",
      "[epoch 20][step 168700] logloss:0.064049 l2_regular:0.000608 rmse:574.390991 total_loss:0.064657 acc:0.266000\n",
      "[epoch 20][step 168800] logloss:0.070438 l2_regular:0.000608 rmse:567.399353 total_loss:0.071045 acc:0.156000\n",
      "[epoch 20][step 168900] logloss:0.057780 l2_regular:0.000608 rmse:396.584747 total_loss:0.058388 acc:0.163000\n",
      "[epoch 20][step 169000] logloss:0.064733 l2_regular:0.000608 rmse:1289.251221 total_loss:0.065341 acc:0.180000\n",
      "[epoch 20][step 169100] logloss:0.066148 l2_regular:0.000608 rmse:497.782837 total_loss:0.066756 acc:0.133000\n",
      "[epoch 20][step 169200] logloss:0.060614 l2_regular:0.000608 rmse:511.600830 total_loss:0.061221 acc:0.379000\n",
      "[epoch 20][step 169300] logloss:0.049448 l2_regular:0.000608 rmse:482.700531 total_loss:0.050056 acc:0.400000\n",
      "[epoch 20][step 169400] logloss:0.062341 l2_regular:0.000608 rmse:537.640686 total_loss:0.062949 acc:0.217000\n",
      "[epoch 20][step 169500] logloss:0.049953 l2_regular:0.000608 rmse:412.490845 total_loss:0.050560 acc:0.254000\n",
      "[epoch 20][step 169600] logloss:0.068464 l2_regular:0.000608 rmse:644.953918 total_loss:0.069072 acc:0.130000\n",
      "[epoch 20][step 169700] logloss:0.054641 l2_regular:0.000608 rmse:725.878174 total_loss:0.055248 acc:0.253000\n",
      "[epoch 20][step 169800] logloss:0.055536 l2_regular:0.000608 rmse:420.486664 total_loss:0.056143 acc:0.204000\n",
      "[epoch 20][step 169900] logloss:0.065613 l2_regular:0.000608 rmse:481.966095 total_loss:0.066221 acc:0.172000\n",
      "[epoch 20][step 170000] logloss:0.071259 l2_regular:0.000608 rmse:510.000763 total_loss:0.071867 acc:0.140000\n",
      "[epoch 20][step 170100] logloss:0.054052 l2_regular:0.000608 rmse:415.862274 total_loss:0.054659 acc:0.265000\n",
      "[epoch 20][step 170200] logloss:0.066399 l2_regular:0.000608 rmse:434.489075 total_loss:0.067007 acc:0.255000\n",
      "[epoch 20][step 170300] logloss:0.059790 l2_regular:0.000608 rmse:616.309509 total_loss:0.060398 acc:0.234000\n",
      "[epoch 20][step 170400] logloss:0.054174 l2_regular:0.000608 rmse:431.060089 total_loss:0.054782 acc:0.311000\n",
      "[epoch 20][step 170500] logloss:0.057413 l2_regular:0.000608 rmse:588.440796 total_loss:0.058021 acc:0.214000\n",
      "[epoch 20][step 170600] logloss:0.059321 l2_regular:0.000608 rmse:415.939575 total_loss:0.059929 acc:0.205000\n",
      "[epoch 20][step 170700] logloss:0.060763 l2_regular:0.000608 rmse:382.593506 total_loss:0.061371 acc:0.225000\n",
      "[epoch 20][step 170800] logloss:0.067011 l2_regular:0.000608 rmse:644.702820 total_loss:0.067619 acc:0.205000\n",
      "[epoch 20][step 170900] logloss:0.065018 l2_regular:0.000608 rmse:420.565796 total_loss:0.065626 acc:0.200000\n",
      "[epoch 20][step 171000] logloss:0.060999 l2_regular:0.000608 rmse:480.512482 total_loss:0.061607 acc:0.225000\n",
      "[epoch 20][step 171100] logloss:0.061527 l2_regular:0.000608 rmse:538.692383 total_loss:0.062135 acc:0.213000\n",
      "[epoch 20][step 171200] logloss:0.065363 l2_regular:0.000608 rmse:420.968262 total_loss:0.065970 acc:0.187000\n",
      "[epoch 20][step 171300] logloss:0.052845 l2_regular:0.000608 rmse:410.388184 total_loss:0.053452 acc:0.251000\n",
      "[epoch 20][step 171400] logloss:0.052180 l2_regular:0.000608 rmse:372.097900 total_loss:0.052788 acc:0.267000\n",
      "[epoch 20][step 171500] logloss:0.059998 l2_regular:0.000608 rmse:348.265503 total_loss:0.060606 acc:0.283000\n",
      "[epoch 20][step 171600] logloss:0.057255 l2_regular:0.000608 rmse:568.296997 total_loss:0.057863 acc:0.221000\n",
      "[epoch 20][step 171700] logloss:0.060807 l2_regular:0.000608 rmse:439.132324 total_loss:0.061415 acc:0.230000\n",
      "[epoch 20][step 171800] logloss:0.062354 l2_regular:0.000608 rmse:959.098633 total_loss:0.062962 acc:0.321000\n",
      "[epoch 20][step 171900] logloss:0.059491 l2_regular:0.000608 rmse:497.681213 total_loss:0.060099 acc:0.321000\n",
      "[epoch 20][step 172000] logloss:0.066542 l2_regular:0.000608 rmse:434.068695 total_loss:0.067150 acc:0.223000\n",
      "[epoch 20][step 172100] logloss:0.056372 l2_regular:0.000608 rmse:559.299438 total_loss:0.056979 acc:0.299000\n",
      "[epoch 20][step 172200] logloss:0.056714 l2_regular:0.000608 rmse:413.887604 total_loss:0.057322 acc:0.174000\n",
      "[epoch 20][step 172300] logloss:0.057680 l2_regular:0.000608 rmse:678.549133 total_loss:0.058287 acc:0.262000\n",
      "[epoch 20][step 172400] logloss:0.055591 l2_regular:0.000608 rmse:469.282257 total_loss:0.056199 acc:0.307000\n",
      "[epoch 20][step 172500] logloss:0.052272 l2_regular:0.000608 rmse:580.591675 total_loss:0.052880 acc:0.310000\n",
      "[epoch 20][step 172600] logloss:0.049377 l2_regular:0.000608 rmse:501.544067 total_loss:0.049985 acc:0.227000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 20][step 172700] logloss:0.056879 l2_regular:0.000608 rmse:521.337830 total_loss:0.057487 acc:0.236000\n",
      "[epoch 20][step 172800] logloss:0.050015 l2_regular:0.000608 rmse:393.505463 total_loss:0.050623 acc:0.287000\n",
      "[epoch 20][step 172900] logloss:0.048299 l2_regular:0.000608 rmse:592.101501 total_loss:0.048907 acc:0.224000\n",
      "[epoch 20][step 173000] logloss:0.060819 l2_regular:0.000608 rmse:430.884949 total_loss:0.061427 acc:0.255000\n",
      "[epoch 20][step 173100] logloss:0.071460 l2_regular:0.000608 rmse:489.200317 total_loss:0.072067 acc:0.268000\n",
      "[epoch 20][step 173200] logloss:0.061753 l2_regular:0.000608 rmse:537.317993 total_loss:0.062361 acc:0.166000\n",
      "[epoch 20][step 173300] logloss:0.063946 l2_regular:0.000608 rmse:434.105469 total_loss:0.064554 acc:0.256000\n",
      "[epoch 20][step 173400] logloss:0.066626 l2_regular:0.000608 rmse:581.753357 total_loss:0.067234 acc:0.211000\n",
      "[epoch 20][step 173500] logloss:0.065521 l2_regular:0.000608 rmse:385.755890 total_loss:0.066129 acc:0.225000\n",
      "[epoch 20][step 173600] logloss:0.057797 l2_regular:0.000608 rmse:674.670288 total_loss:0.058405 acc:0.380000\n",
      "[epoch 20][step 173700] logloss:0.052651 l2_regular:0.000608 rmse:540.246704 total_loss:0.053259 acc:0.256000\n",
      "[epoch 20][step 173800] logloss:0.049075 l2_regular:0.000608 rmse:502.729675 total_loss:0.049682 acc:0.238000\n",
      "[epoch 20][step 173900] logloss:0.050705 l2_regular:0.000608 rmse:425.874603 total_loss:0.051313 acc:0.284000\n",
      "[epoch 20][step 174000] logloss:0.056923 l2_regular:0.000608 rmse:327.064575 total_loss:0.057531 acc:0.342000\n",
      "[epoch 20][step 174100] logloss:0.062637 l2_regular:0.000608 rmse:407.098969 total_loss:0.063245 acc:0.266000\n",
      "[epoch 20][step 174200] logloss:0.066891 l2_regular:0.000608 rmse:525.109375 total_loss:0.067499 acc:0.222000\n",
      "[epoch 20][step 174300] logloss:0.061359 l2_regular:0.000608 rmse:507.596100 total_loss:0.061967 acc:0.266000\n",
      "[epoch 20][step 174400] logloss:0.075693 l2_regular:0.000608 rmse:589.784058 total_loss:0.076301 acc:0.200000\n",
      "[epoch 20][step 174500] logloss:0.058153 l2_regular:0.000608 rmse:460.114410 total_loss:0.058761 acc:0.301000\n",
      "[epoch 20][step 174600] logloss:0.062420 l2_regular:0.000608 rmse:520.866211 total_loss:0.063028 acc:0.236000\n",
      "[epoch 20][step 174700] logloss:0.057499 l2_regular:0.000608 rmse:447.426422 total_loss:0.058107 acc:0.304000\n",
      "[epoch 20][step 174800] logloss:0.058400 l2_regular:0.000608 rmse:751.536316 total_loss:0.059008 acc:0.316000\n",
      "[epoch 20][step 174900] logloss:0.085062 l2_regular:0.000608 rmse:648.113220 total_loss:0.085669 acc:0.183000\n",
      "[epoch 20][step 175000] logloss:0.058786 l2_regular:0.000608 rmse:561.672302 total_loss:0.059394 acc:0.217000\n",
      "[epoch 20][step 175100] logloss:0.055783 l2_regular:0.000608 rmse:439.070862 total_loss:0.056391 acc:0.196000\n",
      "[epoch 20][step 175200] logloss:0.061982 l2_regular:0.000608 rmse:545.776367 total_loss:0.062590 acc:0.223000\n",
      "[epoch 20][step 175300] logloss:0.061750 l2_regular:0.000608 rmse:512.218933 total_loss:0.062358 acc:0.171000\n",
      "--------------epoch 20 finished —> total batch:8351---------------\n",
      "[epoch 21][step 175400] logloss:0.059023 l2_regular:0.000608 rmse:656.942017 total_loss:0.059631 acc:0.189000\n",
      "[epoch 21][step 175500] logloss:0.058291 l2_regular:0.000608 rmse:493.204315 total_loss:0.058899 acc:0.336000\n",
      "[epoch 21][step 175600] logloss:0.064961 l2_regular:0.000608 rmse:643.923218 total_loss:0.065569 acc:0.171000\n",
      "[epoch 21][step 175700] logloss:0.066931 l2_regular:0.000608 rmse:418.707642 total_loss:0.067539 acc:0.154000\n",
      "[epoch 21][step 175800] logloss:0.059446 l2_regular:0.000608 rmse:485.641602 total_loss:0.060054 acc:0.186000\n",
      "[epoch 21][step 175900] logloss:0.062052 l2_regular:0.000608 rmse:855.018188 total_loss:0.062660 acc:0.278000\n",
      "[epoch 21][step 176000] logloss:0.055738 l2_regular:0.000608 rmse:671.353516 total_loss:0.056345 acc:0.234000\n",
      "[epoch 21][step 176100] logloss:0.051008 l2_regular:0.000608 rmse:568.807922 total_loss:0.051616 acc:0.338000\n",
      "[epoch 21][step 176200] logloss:0.054430 l2_regular:0.000608 rmse:675.093506 total_loss:0.055038 acc:0.248000\n",
      "[epoch 21][step 176300] logloss:0.058501 l2_regular:0.000608 rmse:381.626160 total_loss:0.059109 acc:0.381000\n",
      "[epoch 21][step 176400] logloss:0.073137 l2_regular:0.000608 rmse:488.426605 total_loss:0.073745 acc:0.230000\n",
      "[epoch 21][step 176500] logloss:0.051088 l2_regular:0.000608 rmse:560.114136 total_loss:0.051696 acc:0.324000\n",
      "[epoch 21][step 176600] logloss:0.060368 l2_regular:0.000608 rmse:572.799133 total_loss:0.060976 acc:0.283000\n",
      "[epoch 21][step 176700] logloss:0.055353 l2_regular:0.000608 rmse:472.916321 total_loss:0.055960 acc:0.272000\n",
      "[epoch 21][step 176800] logloss:0.061327 l2_regular:0.000608 rmse:456.689911 total_loss:0.061935 acc:0.271000\n",
      "[epoch 21][step 176900] logloss:0.054716 l2_regular:0.000608 rmse:630.181824 total_loss:0.055323 acc:0.260000\n",
      "[epoch 21][step 177000] logloss:0.054779 l2_regular:0.000608 rmse:439.983337 total_loss:0.055387 acc:0.268000\n",
      "[epoch 21][step 177100] logloss:0.048074 l2_regular:0.000608 rmse:342.804138 total_loss:0.048682 acc:0.300000\n",
      "[epoch 21][step 177200] logloss:0.052935 l2_regular:0.000608 rmse:379.773376 total_loss:0.053543 acc:0.271000\n",
      "[epoch 21][step 177300] logloss:0.065548 l2_regular:0.000608 rmse:421.597137 total_loss:0.066156 acc:0.161000\n",
      "[epoch 21][step 177400] logloss:0.052167 l2_regular:0.000608 rmse:445.645569 total_loss:0.052774 acc:0.323000\n",
      "[epoch 21][step 177500] logloss:0.067711 l2_regular:0.000608 rmse:383.647369 total_loss:0.068319 acc:0.198000\n",
      "[epoch 21][step 177600] logloss:0.061290 l2_regular:0.000608 rmse:448.297333 total_loss:0.061898 acc:0.289000\n",
      "[epoch 21][step 177700] logloss:0.063460 l2_regular:0.000608 rmse:375.464783 total_loss:0.064068 acc:0.231000\n",
      "[epoch 21][step 177800] logloss:0.056835 l2_regular:0.000608 rmse:520.005249 total_loss:0.057443 acc:0.293000\n",
      "[epoch 21][step 177900] logloss:0.056395 l2_regular:0.000608 rmse:381.872375 total_loss:0.057003 acc:0.265000\n",
      "[epoch 21][step 178000] logloss:0.059644 l2_regular:0.000608 rmse:439.314087 total_loss:0.060252 acc:0.210000\n",
      "[epoch 21][step 178100] logloss:0.059790 l2_regular:0.000608 rmse:546.848389 total_loss:0.060397 acc:0.240000\n",
      "[epoch 21][step 178200] logloss:0.053879 l2_regular:0.000608 rmse:476.779022 total_loss:0.054487 acc:0.193000\n",
      "[epoch 21][step 178300] logloss:0.057852 l2_regular:0.000608 rmse:466.222260 total_loss:0.058460 acc:0.194000\n",
      "[epoch 21][step 178400] logloss:0.044311 l2_regular:0.000608 rmse:561.965820 total_loss:0.044919 acc:0.365000\n",
      "[epoch 21][step 178500] logloss:0.067231 l2_regular:0.000608 rmse:295.838715 total_loss:0.067838 acc:0.307000\n",
      "[epoch 21][step 178600] logloss:0.066131 l2_regular:0.000608 rmse:383.832672 total_loss:0.066739 acc:0.218000\n",
      "[epoch 21][step 178700] logloss:0.056526 l2_regular:0.000608 rmse:554.919495 total_loss:0.057133 acc:0.251000\n",
      "[epoch 21][step 178800] logloss:0.061472 l2_regular:0.000608 rmse:445.826080 total_loss:0.062080 acc:0.317000\n",
      "[epoch 21][step 178900] logloss:0.056777 l2_regular:0.000608 rmse:536.930725 total_loss:0.057385 acc:0.154000\n",
      "[epoch 21][step 179000] logloss:0.061079 l2_regular:0.000608 rmse:531.348938 total_loss:0.061687 acc:0.311000\n",
      "[epoch 21][step 179100] logloss:0.061285 l2_regular:0.000608 rmse:486.063660 total_loss:0.061893 acc:0.258000\n",
      "[epoch 21][step 179200] logloss:0.062400 l2_regular:0.000608 rmse:412.294678 total_loss:0.063008 acc:0.227000\n",
      "[epoch 21][step 179300] logloss:0.058370 l2_regular:0.000608 rmse:660.318481 total_loss:0.058978 acc:0.310000\n",
      "[epoch 21][step 179400] logloss:0.058088 l2_regular:0.000608 rmse:526.001221 total_loss:0.058696 acc:0.256000\n",
      "[epoch 21][step 179500] logloss:0.061103 l2_regular:0.000608 rmse:397.664124 total_loss:0.061710 acc:0.210000\n",
      "[epoch 21][step 179600] logloss:0.071503 l2_regular:0.000608 rmse:438.483856 total_loss:0.072110 acc:0.148000\n",
      "[epoch 21][step 179700] logloss:0.059645 l2_regular:0.000608 rmse:403.916534 total_loss:0.060253 acc:0.256000\n",
      "[epoch 21][step 179800] logloss:0.066522 l2_regular:0.000608 rmse:452.125244 total_loss:0.067130 acc:0.270000\n",
      "[epoch 21][step 179900] logloss:0.054955 l2_regular:0.000608 rmse:475.995483 total_loss:0.055563 acc:0.257000\n",
      "[epoch 21][step 180000] logloss:0.063468 l2_regular:0.000608 rmse:310.401398 total_loss:0.064076 acc:0.266000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 21][step 180100] logloss:0.054161 l2_regular:0.000608 rmse:404.884888 total_loss:0.054769 acc:0.301000\n",
      "[epoch 21][step 180200] logloss:0.050490 l2_regular:0.000608 rmse:708.550598 total_loss:0.051097 acc:0.342000\n",
      "[epoch 21][step 180300] logloss:0.063634 l2_regular:0.000608 rmse:583.965942 total_loss:0.064242 acc:0.240000\n",
      "[epoch 21][step 180400] logloss:0.057437 l2_regular:0.000608 rmse:457.010132 total_loss:0.058044 acc:0.232000\n",
      "[epoch 21][step 180500] logloss:0.056007 l2_regular:0.000608 rmse:377.888611 total_loss:0.056615 acc:0.194000\n",
      "[epoch 21][step 180600] logloss:0.065423 l2_regular:0.000608 rmse:373.896606 total_loss:0.066031 acc:0.223000\n",
      "[epoch 21][step 180700] logloss:0.065795 l2_regular:0.000608 rmse:393.818359 total_loss:0.066403 acc:0.244000\n",
      "[epoch 21][step 180800] logloss:0.071415 l2_regular:0.000608 rmse:429.477844 total_loss:0.072023 acc:0.168000\n",
      "[epoch 21][step 180900] logloss:0.054162 l2_regular:0.000608 rmse:421.070190 total_loss:0.054770 acc:0.309000\n",
      "[epoch 21][step 181000] logloss:0.061425 l2_regular:0.000608 rmse:401.242157 total_loss:0.062032 acc:0.327000\n",
      "[epoch 21][step 181100] logloss:0.064510 l2_regular:0.000608 rmse:618.036438 total_loss:0.065118 acc:0.223000\n",
      "[epoch 21][step 181200] logloss:0.053832 l2_regular:0.000608 rmse:350.921112 total_loss:0.054440 acc:0.322000\n",
      "[epoch 21][step 181300] logloss:0.058096 l2_regular:0.000608 rmse:440.277374 total_loss:0.058704 acc:0.210000\n",
      "[epoch 21][step 181400] logloss:0.054461 l2_regular:0.000608 rmse:396.916229 total_loss:0.055068 acc:0.196000\n",
      "[epoch 21][step 181500] logloss:0.065984 l2_regular:0.000608 rmse:410.043976 total_loss:0.066592 acc:0.246000\n",
      "[epoch 21][step 181600] logloss:0.063582 l2_regular:0.000608 rmse:527.325256 total_loss:0.064189 acc:0.163000\n",
      "[epoch 21][step 181700] logloss:0.054127 l2_regular:0.000608 rmse:448.708862 total_loss:0.054735 acc:0.230000\n",
      "[epoch 21][step 181800] logloss:0.058984 l2_regular:0.000608 rmse:562.118286 total_loss:0.059591 acc:0.276000\n",
      "[epoch 21][step 181900] logloss:0.052874 l2_regular:0.000608 rmse:442.941772 total_loss:0.053481 acc:0.236000\n",
      "[epoch 21][step 182000] logloss:0.058196 l2_regular:0.000608 rmse:578.593933 total_loss:0.058804 acc:0.279000\n",
      "[epoch 21][step 182100] logloss:0.050638 l2_regular:0.000608 rmse:414.375641 total_loss:0.051246 acc:0.248000\n",
      "[epoch 21][step 182200] logloss:0.063528 l2_regular:0.000608 rmse:525.961609 total_loss:0.064136 acc:0.137000\n",
      "[epoch 21][step 182300] logloss:0.056349 l2_regular:0.000608 rmse:545.317200 total_loss:0.056957 acc:0.264000\n",
      "[epoch 21][step 182400] logloss:0.059924 l2_regular:0.000608 rmse:439.724396 total_loss:0.060532 acc:0.264000\n",
      "[epoch 21][step 182500] logloss:0.057329 l2_regular:0.000608 rmse:510.808777 total_loss:0.057937 acc:0.252000\n",
      "[epoch 21][step 182600] logloss:0.061878 l2_regular:0.000608 rmse:551.691101 total_loss:0.062486 acc:0.248000\n",
      "[epoch 21][step 182700] logloss:0.066315 l2_regular:0.000608 rmse:633.340576 total_loss:0.066923 acc:0.258000\n",
      "[epoch 21][step 182800] logloss:0.056517 l2_regular:0.000608 rmse:421.843231 total_loss:0.057124 acc:0.268000\n",
      "[epoch 21][step 182900] logloss:0.065731 l2_regular:0.000608 rmse:428.234436 total_loss:0.066339 acc:0.224000\n",
      "[epoch 21][step 183000] logloss:0.046059 l2_regular:0.000608 rmse:541.499695 total_loss:0.046666 acc:0.375000\n",
      "[epoch 21][step 183100] logloss:0.064880 l2_regular:0.000608 rmse:363.908905 total_loss:0.065488 acc:0.263000\n",
      "[epoch 21][step 183200] logloss:0.057019 l2_regular:0.000608 rmse:637.320801 total_loss:0.057627 acc:0.224000\n",
      "[epoch 21][step 183300] logloss:0.052190 l2_regular:0.000608 rmse:449.494232 total_loss:0.052798 acc:0.324000\n",
      "[epoch 21][step 183400] logloss:0.065206 l2_regular:0.000608 rmse:471.238892 total_loss:0.065814 acc:0.228000\n",
      "[epoch 21][step 183500] logloss:0.063673 l2_regular:0.000608 rmse:368.320160 total_loss:0.064280 acc:0.130000\n",
      "[epoch 21][step 183600] logloss:0.063365 l2_regular:0.000608 rmse:514.145325 total_loss:0.063973 acc:0.253000\n",
      "[epoch 21][step 183700] logloss:0.068257 l2_regular:0.000608 rmse:535.114258 total_loss:0.068865 acc:0.221000\n",
      "--------------epoch 21 finished —> total batch:8351---------------\n",
      "[epoch 22][step 183800] logloss:0.055255 l2_regular:0.000608 rmse:529.950989 total_loss:0.055862 acc:0.218000\n",
      "[epoch 22][step 183900] logloss:0.060236 l2_regular:0.000608 rmse:430.349823 total_loss:0.060844 acc:0.261000\n",
      "[epoch 22][step 184000] logloss:0.064391 l2_regular:0.000608 rmse:607.595520 total_loss:0.064999 acc:0.200000\n",
      "[epoch 22][step 184100] logloss:0.065070 l2_regular:0.000608 rmse:595.950256 total_loss:0.065677 acc:0.158000\n",
      "[epoch 22][step 184200] logloss:0.056511 l2_regular:0.000608 rmse:733.260193 total_loss:0.057119 acc:0.314000\n",
      "[epoch 22][step 184300] logloss:0.066493 l2_regular:0.000608 rmse:571.125732 total_loss:0.067101 acc:0.194000\n",
      "[epoch 22][step 184400] logloss:0.065050 l2_regular:0.000608 rmse:520.554321 total_loss:0.065658 acc:0.164000\n",
      "[epoch 22][step 184500] logloss:0.071980 l2_regular:0.000608 rmse:483.390991 total_loss:0.072588 acc:0.172000\n",
      "[epoch 22][step 184600] logloss:0.050660 l2_regular:0.000608 rmse:583.005127 total_loss:0.051268 acc:0.313000\n",
      "[epoch 22][step 184700] logloss:0.065431 l2_regular:0.000608 rmse:696.479492 total_loss:0.066038 acc:0.295000\n",
      "[epoch 22][step 184800] logloss:0.055042 l2_regular:0.000608 rmse:454.698730 total_loss:0.055649 acc:0.265000\n",
      "[epoch 22][step 184900] logloss:0.067139 l2_regular:0.000608 rmse:418.635895 total_loss:0.067747 acc:0.243000\n",
      "[epoch 22][step 185000] logloss:0.060822 l2_regular:0.000608 rmse:492.634460 total_loss:0.061430 acc:0.293000\n",
      "[epoch 22][step 185100] logloss:0.057578 l2_regular:0.000608 rmse:520.427979 total_loss:0.058186 acc:0.290000\n",
      "[epoch 22][step 185200] logloss:0.055731 l2_regular:0.000608 rmse:362.506866 total_loss:0.056339 acc:0.382000\n",
      "[epoch 22][step 185300] logloss:0.061008 l2_regular:0.000608 rmse:427.843658 total_loss:0.061616 acc:0.270000\n",
      "[epoch 22][step 185400] logloss:0.061203 l2_regular:0.000608 rmse:477.784576 total_loss:0.061811 acc:0.193000\n",
      "[epoch 22][step 185500] logloss:0.066185 l2_regular:0.000608 rmse:398.560577 total_loss:0.066793 acc:0.286000\n",
      "[epoch 22][step 185600] logloss:0.055625 l2_regular:0.000608 rmse:370.757202 total_loss:0.056233 acc:0.281000\n",
      "[epoch 22][step 185700] logloss:0.057310 l2_regular:0.000608 rmse:425.644653 total_loss:0.057918 acc:0.316000\n",
      "[epoch 22][step 185800] logloss:0.061801 l2_regular:0.000608 rmse:411.483215 total_loss:0.062409 acc:0.241000\n",
      "[epoch 22][step 185900] logloss:0.058922 l2_regular:0.000608 rmse:395.391663 total_loss:0.059529 acc:0.262000\n",
      "[epoch 22][step 186000] logloss:0.076790 l2_regular:0.000608 rmse:838.966125 total_loss:0.077398 acc:0.164000\n",
      "[epoch 22][step 186100] logloss:0.070995 l2_regular:0.000608 rmse:348.962708 total_loss:0.071603 acc:0.127000\n",
      "[epoch 22][step 186200] logloss:0.058765 l2_regular:0.000608 rmse:334.181335 total_loss:0.059373 acc:0.256000\n",
      "[epoch 22][step 186300] logloss:0.051418 l2_regular:0.000608 rmse:599.819336 total_loss:0.052026 acc:0.310000\n",
      "[epoch 22][step 186400] logloss:0.059825 l2_regular:0.000608 rmse:428.788208 total_loss:0.060433 acc:0.265000\n",
      "[epoch 22][step 186500] logloss:0.060309 l2_regular:0.000608 rmse:537.238525 total_loss:0.060917 acc:0.244000\n",
      "[epoch 22][step 186600] logloss:0.063765 l2_regular:0.000608 rmse:561.460754 total_loss:0.064372 acc:0.195000\n",
      "[epoch 22][step 186700] logloss:0.057572 l2_regular:0.000608 rmse:478.132874 total_loss:0.058179 acc:0.218000\n",
      "[epoch 22][step 186800] logloss:0.061273 l2_regular:0.000608 rmse:496.770996 total_loss:0.061881 acc:0.238000\n",
      "[epoch 22][step 186900] logloss:0.056966 l2_regular:0.000608 rmse:503.835785 total_loss:0.057573 acc:0.232000\n",
      "[epoch 22][step 187000] logloss:0.053156 l2_regular:0.000608 rmse:528.182495 total_loss:0.053764 acc:0.257000\n",
      "[epoch 22][step 187100] logloss:0.064811 l2_regular:0.000608 rmse:407.443085 total_loss:0.065419 acc:0.170000\n",
      "[epoch 22][step 187200] logloss:0.068441 l2_regular:0.000608 rmse:361.385620 total_loss:0.069049 acc:0.153000\n",
      "[epoch 22][step 187300] logloss:0.061415 l2_regular:0.000608 rmse:377.238373 total_loss:0.062023 acc:0.167000\n",
      "[epoch 22][step 187400] logloss:0.056326 l2_regular:0.000608 rmse:490.728210 total_loss:0.056933 acc:0.219000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 22][step 187500] logloss:0.062089 l2_regular:0.000608 rmse:427.016510 total_loss:0.062697 acc:0.195000\n",
      "[epoch 22][step 187600] logloss:0.072559 l2_regular:0.000608 rmse:457.169617 total_loss:0.073167 acc:0.177000\n",
      "[epoch 22][step 187700] logloss:0.061004 l2_regular:0.000608 rmse:505.149353 total_loss:0.061612 acc:0.272000\n",
      "[epoch 22][step 187800] logloss:0.058112 l2_regular:0.000608 rmse:434.001678 total_loss:0.058719 acc:0.268000\n",
      "[epoch 22][step 187900] logloss:0.058223 l2_regular:0.000608 rmse:354.793671 total_loss:0.058831 acc:0.273000\n",
      "[epoch 22][step 188000] logloss:0.063078 l2_regular:0.000608 rmse:540.202271 total_loss:0.063686 acc:0.173000\n",
      "[epoch 22][step 188100] logloss:0.059706 l2_regular:0.000608 rmse:495.885040 total_loss:0.060314 acc:0.234000\n",
      "[epoch 22][step 188200] logloss:0.061514 l2_regular:0.000608 rmse:429.176758 total_loss:0.062121 acc:0.264000\n",
      "[epoch 22][step 188300] logloss:0.057480 l2_regular:0.000608 rmse:622.629456 total_loss:0.058088 acc:0.389000\n",
      "[epoch 22][step 188400] logloss:0.061699 l2_regular:0.000608 rmse:459.009979 total_loss:0.062307 acc:0.308000\n",
      "[epoch 22][step 188500] logloss:0.055139 l2_regular:0.000608 rmse:342.364380 total_loss:0.055746 acc:0.236000\n",
      "[epoch 22][step 188600] logloss:0.061833 l2_regular:0.000608 rmse:502.713776 total_loss:0.062441 acc:0.263000\n",
      "[epoch 22][step 188700] logloss:0.055519 l2_regular:0.000608 rmse:371.386627 total_loss:0.056127 acc:0.235000\n",
      "[epoch 22][step 188800] logloss:0.066471 l2_regular:0.000608 rmse:364.200806 total_loss:0.067078 acc:0.314000\n",
      "[epoch 22][step 188900] logloss:0.060611 l2_regular:0.000608 rmse:486.690094 total_loss:0.061219 acc:0.234000\n",
      "[epoch 22][step 189000] logloss:0.068405 l2_regular:0.000608 rmse:578.220154 total_loss:0.069013 acc:0.287000\n",
      "[epoch 22][step 189100] logloss:0.067601 l2_regular:0.000608 rmse:424.783173 total_loss:0.068209 acc:0.239000\n",
      "[epoch 22][step 189200] logloss:0.059096 l2_regular:0.000608 rmse:443.926727 total_loss:0.059704 acc:0.240000\n",
      "[epoch 22][step 189300] logloss:0.060925 l2_regular:0.000608 rmse:613.120605 total_loss:0.061533 acc:0.217000\n",
      "[epoch 22][step 189400] logloss:0.056968 l2_regular:0.000608 rmse:451.273895 total_loss:0.057576 acc:0.241000\n",
      "[epoch 22][step 189500] logloss:0.062092 l2_regular:0.000608 rmse:376.131378 total_loss:0.062700 acc:0.276000\n",
      "[epoch 22][step 189600] logloss:0.063931 l2_regular:0.000608 rmse:490.452271 total_loss:0.064539 acc:0.165000\n",
      "[epoch 22][step 189700] logloss:0.062429 l2_regular:0.000608 rmse:405.785919 total_loss:0.063036 acc:0.296000\n",
      "[epoch 22][step 189800] logloss:0.051433 l2_regular:0.000608 rmse:412.775146 total_loss:0.052041 acc:0.389000\n",
      "[epoch 22][step 189900] logloss:0.061132 l2_regular:0.000608 rmse:858.851501 total_loss:0.061740 acc:0.135000\n",
      "[epoch 22][step 190000] logloss:0.069638 l2_regular:0.000608 rmse:442.104156 total_loss:0.070246 acc:0.127000\n",
      "[epoch 22][step 190100] logloss:0.060200 l2_regular:0.000608 rmse:463.509125 total_loss:0.060807 acc:0.370000\n",
      "[epoch 22][step 190200] logloss:0.050693 l2_regular:0.000608 rmse:435.099457 total_loss:0.051301 acc:0.306000\n",
      "[epoch 22][step 190300] logloss:0.050722 l2_regular:0.000608 rmse:522.876404 total_loss:0.051330 acc:0.290000\n",
      "[epoch 22][step 190400] logloss:0.063112 l2_regular:0.000608 rmse:370.327728 total_loss:0.063720 acc:0.203000\n",
      "[epoch 22][step 190500] logloss:0.056942 l2_regular:0.000608 rmse:519.598816 total_loss:0.057550 acc:0.422000\n",
      "[epoch 22][step 190600] logloss:0.061863 l2_regular:0.000608 rmse:429.413605 total_loss:0.062471 acc:0.273000\n",
      "[epoch 22][step 190700] logloss:0.064258 l2_regular:0.000608 rmse:379.119324 total_loss:0.064865 acc:0.199000\n",
      "[epoch 22][step 190800] logloss:0.059543 l2_regular:0.000608 rmse:682.258606 total_loss:0.060151 acc:0.291000\n",
      "[epoch 22][step 190900] logloss:0.055397 l2_regular:0.000608 rmse:442.975555 total_loss:0.056005 acc:0.242000\n",
      "[epoch 22][step 191000] logloss:0.060798 l2_regular:0.000608 rmse:506.583740 total_loss:0.061406 acc:0.329000\n",
      "[epoch 22][step 191100] logloss:0.048594 l2_regular:0.000608 rmse:771.480164 total_loss:0.049201 acc:0.241000\n",
      "[epoch 22][step 191200] logloss:0.063022 l2_regular:0.000608 rmse:567.928223 total_loss:0.063630 acc:0.212000\n",
      "[epoch 22][step 191300] logloss:0.050211 l2_regular:0.000608 rmse:455.631897 total_loss:0.050819 acc:0.322000\n",
      "[epoch 22][step 191400] logloss:0.062695 l2_regular:0.000608 rmse:268.823547 total_loss:0.063303 acc:0.294000\n",
      "[epoch 22][step 191500] logloss:0.069905 l2_regular:0.000608 rmse:402.446594 total_loss:0.070513 acc:0.234000\n",
      "[epoch 22][step 191600] logloss:0.059572 l2_regular:0.000608 rmse:489.183990 total_loss:0.060179 acc:0.259000\n",
      "[epoch 22][step 191700] logloss:0.054389 l2_regular:0.000608 rmse:433.775208 total_loss:0.054997 acc:0.191000\n",
      "[epoch 22][step 191800] logloss:0.055788 l2_regular:0.000608 rmse:433.243134 total_loss:0.056395 acc:0.334000\n",
      "[epoch 22][step 191900] logloss:0.049764 l2_regular:0.000608 rmse:344.360596 total_loss:0.050371 acc:0.248000\n",
      "[epoch 22][step 192000] logloss:0.064205 l2_regular:0.000608 rmse:502.085052 total_loss:0.064813 acc:0.312000\n",
      "--------------epoch 22 finished —> total batch:8351---------------\n",
      "[epoch 23][step 192100] logloss:0.055152 l2_regular:0.000608 rmse:356.048492 total_loss:0.055759 acc:0.230000\n",
      "[epoch 23][step 192200] logloss:0.062383 l2_regular:0.000608 rmse:409.250183 total_loss:0.062991 acc:0.211000\n",
      "[epoch 23][step 192300] logloss:0.054483 l2_regular:0.000608 rmse:411.869812 total_loss:0.055090 acc:0.224000\n",
      "[epoch 23][step 192400] logloss:0.066673 l2_regular:0.000608 rmse:511.612793 total_loss:0.067280 acc:0.200000\n",
      "[epoch 23][step 192500] logloss:0.062212 l2_regular:0.000608 rmse:430.136322 total_loss:0.062819 acc:0.170000\n",
      "[epoch 23][step 192600] logloss:0.059550 l2_regular:0.000608 rmse:394.987061 total_loss:0.060158 acc:0.205000\n",
      "[epoch 23][step 192700] logloss:0.064004 l2_regular:0.000608 rmse:386.344330 total_loss:0.064612 acc:0.194000\n",
      "[epoch 23][step 192800] logloss:0.053484 l2_regular:0.000608 rmse:403.295807 total_loss:0.054092 acc:0.315000\n",
      "[epoch 23][step 192900] logloss:0.052953 l2_regular:0.000608 rmse:302.022644 total_loss:0.053561 acc:0.300000\n",
      "[epoch 23][step 193000] logloss:0.067859 l2_regular:0.000608 rmse:504.534943 total_loss:0.068466 acc:0.204000\n",
      "[epoch 23][step 193100] logloss:0.050206 l2_regular:0.000608 rmse:417.210785 total_loss:0.050814 acc:0.275000\n",
      "[epoch 23][step 193200] logloss:0.063203 l2_regular:0.000608 rmse:364.802460 total_loss:0.063811 acc:0.255000\n",
      "[epoch 23][step 193300] logloss:0.055218 l2_regular:0.000608 rmse:519.819214 total_loss:0.055826 acc:0.209000\n",
      "[epoch 23][step 193400] logloss:0.058965 l2_regular:0.000608 rmse:533.976868 total_loss:0.059572 acc:0.224000\n",
      "[epoch 23][step 193500] logloss:0.065206 l2_regular:0.000608 rmse:449.816376 total_loss:0.065813 acc:0.214000\n",
      "[epoch 23][step 193600] logloss:0.058535 l2_regular:0.000608 rmse:406.350708 total_loss:0.059142 acc:0.317000\n",
      "[epoch 23][step 193700] logloss:0.061668 l2_regular:0.000608 rmse:442.756866 total_loss:0.062275 acc:0.173000\n",
      "[epoch 23][step 193800] logloss:0.061003 l2_regular:0.000608 rmse:424.983307 total_loss:0.061611 acc:0.222000\n",
      "[epoch 23][step 193900] logloss:0.061615 l2_regular:0.000608 rmse:375.758911 total_loss:0.062223 acc:0.324000\n",
      "[epoch 23][step 194000] logloss:0.060816 l2_regular:0.000608 rmse:426.804199 total_loss:0.061424 acc:0.255000\n",
      "[epoch 23][step 194100] logloss:0.065241 l2_regular:0.000608 rmse:646.273682 total_loss:0.065849 acc:0.222000\n",
      "[epoch 23][step 194200] logloss:0.050635 l2_regular:0.000608 rmse:451.230865 total_loss:0.051243 acc:0.347000\n",
      "[epoch 23][step 194300] logloss:0.063234 l2_regular:0.000608 rmse:503.494171 total_loss:0.063842 acc:0.230000\n",
      "[epoch 23][step 194400] logloss:0.053072 l2_regular:0.000608 rmse:454.593750 total_loss:0.053680 acc:0.287000\n",
      "[epoch 23][step 194500] logloss:0.061955 l2_regular:0.000608 rmse:518.258972 total_loss:0.062563 acc:0.192000\n",
      "[epoch 23][step 194600] logloss:0.061434 l2_regular:0.000608 rmse:332.569824 total_loss:0.062042 acc:0.259000\n",
      "[epoch 23][step 194700] logloss:0.064318 l2_regular:0.000608 rmse:476.825195 total_loss:0.064925 acc:0.195000\n",
      "[epoch 23][step 194800] logloss:0.078031 l2_regular:0.000608 rmse:586.274780 total_loss:0.078638 acc:0.180000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 23][step 194900] logloss:0.064048 l2_regular:0.000608 rmse:599.022339 total_loss:0.064656 acc:0.295000\n",
      "[epoch 23][step 195000] logloss:0.059200 l2_regular:0.000608 rmse:461.220886 total_loss:0.059808 acc:0.293000\n",
      "[epoch 23][step 195100] logloss:0.075285 l2_regular:0.000608 rmse:451.614960 total_loss:0.075892 acc:0.220000\n",
      "[epoch 23][step 195200] logloss:0.065413 l2_regular:0.000608 rmse:510.219971 total_loss:0.066020 acc:0.226000\n",
      "[epoch 23][step 195300] logloss:0.059982 l2_regular:0.000608 rmse:620.759521 total_loss:0.060590 acc:0.178000\n",
      "[epoch 23][step 195400] logloss:0.065678 l2_regular:0.000608 rmse:401.746918 total_loss:0.066286 acc:0.201000\n",
      "[epoch 23][step 195500] logloss:0.061467 l2_regular:0.000608 rmse:423.351624 total_loss:0.062074 acc:0.219000\n",
      "[epoch 23][step 195600] logloss:0.059186 l2_regular:0.000608 rmse:425.268250 total_loss:0.059794 acc:0.212000\n",
      "[epoch 23][step 195700] logloss:0.052002 l2_regular:0.000608 rmse:388.428986 total_loss:0.052610 acc:0.384000\n",
      "[epoch 23][step 195800] logloss:0.053008 l2_regular:0.000608 rmse:876.951416 total_loss:0.053616 acc:0.181000\n",
      "[epoch 23][step 195900] logloss:0.056670 l2_regular:0.000608 rmse:474.652313 total_loss:0.057277 acc:0.197000\n",
      "[epoch 23][step 196000] logloss:0.061767 l2_regular:0.000608 rmse:336.357513 total_loss:0.062375 acc:0.241000\n",
      "[epoch 23][step 196100] logloss:0.064171 l2_regular:0.000608 rmse:517.102356 total_loss:0.064778 acc:0.159000\n",
      "[epoch 23][step 196200] logloss:0.062297 l2_regular:0.000608 rmse:383.048126 total_loss:0.062905 acc:0.176000\n",
      "[epoch 23][step 196300] logloss:0.064549 l2_regular:0.000608 rmse:623.265198 total_loss:0.065156 acc:0.223000\n",
      "[epoch 23][step 196400] logloss:0.059644 l2_regular:0.000608 rmse:485.034576 total_loss:0.060252 acc:0.225000\n",
      "[epoch 23][step 196500] logloss:0.066938 l2_regular:0.000608 rmse:388.581390 total_loss:0.067546 acc:0.188000\n",
      "[epoch 23][step 196600] logloss:0.060490 l2_regular:0.000608 rmse:517.705444 total_loss:0.061098 acc:0.159000\n",
      "[epoch 23][step 196700] logloss:0.060099 l2_regular:0.000608 rmse:521.222900 total_loss:0.060707 acc:0.196000\n",
      "[epoch 23][step 196800] logloss:0.065542 l2_regular:0.000608 rmse:541.079590 total_loss:0.066150 acc:0.187000\n",
      "[epoch 23][step 196900] logloss:0.069964 l2_regular:0.000608 rmse:445.226654 total_loss:0.070572 acc:0.302000\n",
      "[epoch 23][step 197000] logloss:0.077329 l2_regular:0.000608 rmse:432.570435 total_loss:0.077937 acc:0.195000\n",
      "[epoch 23][step 197100] logloss:0.053426 l2_regular:0.000608 rmse:501.709503 total_loss:0.054034 acc:0.269000\n",
      "[epoch 23][step 197200] logloss:0.068581 l2_regular:0.000608 rmse:320.820892 total_loss:0.069189 acc:0.366000\n",
      "[epoch 23][step 197300] logloss:0.055965 l2_regular:0.000608 rmse:433.238251 total_loss:0.056573 acc:0.227000\n",
      "[epoch 23][step 197400] logloss:0.067261 l2_regular:0.000608 rmse:392.229645 total_loss:0.067869 acc:0.232000\n",
      "[epoch 23][step 197500] logloss:0.055994 l2_regular:0.000608 rmse:438.842499 total_loss:0.056601 acc:0.301000\n",
      "[epoch 23][step 197600] logloss:0.056273 l2_regular:0.000608 rmse:410.962860 total_loss:0.056881 acc:0.302000\n",
      "[epoch 23][step 197700] logloss:0.062910 l2_regular:0.000608 rmse:391.013550 total_loss:0.063517 acc:0.254000\n",
      "[epoch 23][step 197800] logloss:0.071173 l2_regular:0.000608 rmse:596.028809 total_loss:0.071781 acc:0.152000\n",
      "[epoch 23][step 197900] logloss:0.068327 l2_regular:0.000608 rmse:508.679138 total_loss:0.068935 acc:0.220000\n",
      "[epoch 23][step 198000] logloss:0.055383 l2_regular:0.000608 rmse:402.212708 total_loss:0.055991 acc:0.246000\n",
      "[epoch 23][step 198100] logloss:0.061111 l2_regular:0.000608 rmse:601.699646 total_loss:0.061719 acc:0.221000\n",
      "[epoch 23][step 198200] logloss:0.061005 l2_regular:0.000608 rmse:504.059479 total_loss:0.061613 acc:0.287000\n",
      "[epoch 23][step 198300] logloss:0.065659 l2_regular:0.000608 rmse:491.945282 total_loss:0.066267 acc:0.211000\n",
      "[epoch 23][step 198400] logloss:0.056812 l2_regular:0.000608 rmse:459.876251 total_loss:0.057420 acc:0.268000\n",
      "[epoch 23][step 198500] logloss:0.061268 l2_regular:0.000608 rmse:418.405090 total_loss:0.061876 acc:0.204000\n",
      "[epoch 23][step 198600] logloss:0.064278 l2_regular:0.000608 rmse:400.999664 total_loss:0.064886 acc:0.230000\n",
      "[epoch 23][step 198700] logloss:0.055152 l2_regular:0.000608 rmse:575.975220 total_loss:0.055760 acc:0.268000\n",
      "[epoch 23][step 198800] logloss:0.057628 l2_regular:0.000608 rmse:506.643616 total_loss:0.058236 acc:0.294000\n",
      "[epoch 23][step 198900] logloss:0.055500 l2_regular:0.000608 rmse:362.243988 total_loss:0.056108 acc:0.281000\n",
      "[epoch 23][step 199000] logloss:0.065957 l2_regular:0.000608 rmse:362.483093 total_loss:0.066565 acc:0.194000\n",
      "[epoch 23][step 199100] logloss:0.062842 l2_regular:0.000608 rmse:462.456421 total_loss:0.063449 acc:0.266000\n",
      "[epoch 23][step 199200] logloss:0.057628 l2_regular:0.000608 rmse:589.088318 total_loss:0.058236 acc:0.252000\n",
      "[epoch 23][step 199300] logloss:0.062925 l2_regular:0.000608 rmse:493.943695 total_loss:0.063533 acc:0.153000\n",
      "[epoch 23][step 199400] logloss:0.066898 l2_regular:0.000608 rmse:384.490448 total_loss:0.067506 acc:0.167000\n",
      "[epoch 23][step 199500] logloss:0.062495 l2_regular:0.000608 rmse:471.730896 total_loss:0.063103 acc:0.150000\n",
      "[epoch 23][step 199600] logloss:0.061113 l2_regular:0.000608 rmse:551.487854 total_loss:0.061721 acc:0.206000\n",
      "[epoch 23][step 199700] logloss:0.066887 l2_regular:0.000608 rmse:460.295410 total_loss:0.067494 acc:0.256000\n",
      "[epoch 23][step 199800] logloss:0.055265 l2_regular:0.000608 rmse:366.180145 total_loss:0.055873 acc:0.236000\n",
      "[epoch 23][step 199900] logloss:0.065408 l2_regular:0.000608 rmse:532.800781 total_loss:0.066016 acc:0.161000\n",
      "[epoch 23][step 200000] logloss:0.059216 l2_regular:0.000608 rmse:428.864899 total_loss:0.059823 acc:0.230000\n",
      "[epoch 23][step 200100] logloss:0.061019 l2_regular:0.000608 rmse:396.414703 total_loss:0.061627 acc:0.178000\n",
      "[epoch 23][step 200200] logloss:0.066638 l2_regular:0.000608 rmse:535.649353 total_loss:0.067246 acc:0.201000\n",
      "[epoch 23][step 200300] logloss:0.065872 l2_regular:0.000608 rmse:448.001007 total_loss:0.066480 acc:0.154000\n",
      "[epoch 23][step 200400] logloss:0.068632 l2_regular:0.000608 rmse:506.110138 total_loss:0.069240 acc:0.261000\n",
      "--------------epoch 23 finished —> total batch:8351---------------\n",
      "[epoch 24][step 200500] logloss:0.070039 l2_regular:0.000608 rmse:623.962524 total_loss:0.070647 acc:0.193000\n",
      "[epoch 24][step 200600] logloss:0.047750 l2_regular:0.000608 rmse:287.554077 total_loss:0.048357 acc:0.283000\n",
      "[epoch 24][step 200700] logloss:0.049277 l2_regular:0.000608 rmse:428.376190 total_loss:0.049884 acc:0.166000\n",
      "[epoch 24][step 200800] logloss:0.070194 l2_regular:0.000608 rmse:522.553284 total_loss:0.070802 acc:0.255000\n",
      "[epoch 24][step 200900] logloss:0.062361 l2_regular:0.000608 rmse:463.665344 total_loss:0.062969 acc:0.256000\n",
      "[epoch 24][step 201000] logloss:0.063234 l2_regular:0.000608 rmse:462.660217 total_loss:0.063842 acc:0.218000\n",
      "[epoch 24][step 201100] logloss:0.055910 l2_regular:0.000608 rmse:592.476196 total_loss:0.056518 acc:0.244000\n",
      "[epoch 24][step 201200] logloss:0.055274 l2_regular:0.000608 rmse:458.752533 total_loss:0.055882 acc:0.423000\n",
      "[epoch 24][step 201300] logloss:0.065840 l2_regular:0.000608 rmse:450.791901 total_loss:0.066447 acc:0.214000\n",
      "[epoch 24][step 201400] logloss:0.065819 l2_regular:0.000608 rmse:443.690796 total_loss:0.066427 acc:0.183000\n",
      "[epoch 24][step 201500] logloss:0.055704 l2_regular:0.000608 rmse:426.326752 total_loss:0.056311 acc:0.177000\n",
      "[epoch 24][step 201600] logloss:0.062604 l2_regular:0.000608 rmse:495.944977 total_loss:0.063212 acc:0.375000\n",
      "[epoch 24][step 201700] logloss:0.059258 l2_regular:0.000608 rmse:435.709015 total_loss:0.059866 acc:0.171000\n",
      "[epoch 24][step 201800] logloss:0.056940 l2_regular:0.000608 rmse:451.673370 total_loss:0.057548 acc:0.301000\n",
      "[epoch 24][step 201900] logloss:0.057402 l2_regular:0.000608 rmse:595.019836 total_loss:0.058010 acc:0.240000\n",
      "[epoch 24][step 202000] logloss:0.060600 l2_regular:0.000608 rmse:385.663727 total_loss:0.061207 acc:0.233000\n",
      "[epoch 24][step 202100] logloss:0.066817 l2_regular:0.000608 rmse:753.121521 total_loss:0.067425 acc:0.192000\n",
      "[epoch 24][step 202200] logloss:0.059057 l2_regular:0.000608 rmse:485.745209 total_loss:0.059664 acc:0.308000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 24][step 202300] logloss:0.058472 l2_regular:0.000608 rmse:383.853210 total_loss:0.059080 acc:0.204000\n",
      "[epoch 24][step 202400] logloss:0.063454 l2_regular:0.000608 rmse:405.922943 total_loss:0.064061 acc:0.224000\n",
      "[epoch 24][step 202500] logloss:0.048758 l2_regular:0.000608 rmse:351.647308 total_loss:0.049366 acc:0.249000\n",
      "[epoch 24][step 202600] logloss:0.059433 l2_regular:0.000608 rmse:365.028137 total_loss:0.060041 acc:0.187000\n",
      "[epoch 24][step 202700] logloss:0.067685 l2_regular:0.000608 rmse:543.453491 total_loss:0.068293 acc:0.210000\n",
      "[epoch 24][step 202800] logloss:0.061313 l2_regular:0.000608 rmse:430.921906 total_loss:0.061921 acc:0.309000\n",
      "[epoch 24][step 202900] logloss:0.055006 l2_regular:0.000608 rmse:344.461517 total_loss:0.055613 acc:0.349000\n",
      "[epoch 24][step 203000] logloss:0.058890 l2_regular:0.000608 rmse:428.136993 total_loss:0.059498 acc:0.180000\n",
      "[epoch 24][step 203100] logloss:0.069410 l2_regular:0.000608 rmse:489.270142 total_loss:0.070017 acc:0.194000\n",
      "[epoch 24][step 203200] logloss:0.072470 l2_regular:0.000608 rmse:555.512085 total_loss:0.073078 acc:0.258000\n",
      "[epoch 24][step 203300] logloss:0.055699 l2_regular:0.000608 rmse:455.761078 total_loss:0.056307 acc:0.308000\n",
      "[epoch 24][step 203400] logloss:0.053700 l2_regular:0.000608 rmse:576.314697 total_loss:0.054308 acc:0.342000\n",
      "[epoch 24][step 203500] logloss:0.068836 l2_regular:0.000608 rmse:489.059296 total_loss:0.069444 acc:0.251000\n",
      "[epoch 24][step 203600] logloss:0.054232 l2_regular:0.000608 rmse:289.315369 total_loss:0.054840 acc:0.310000\n",
      "[epoch 24][step 203700] logloss:0.059634 l2_regular:0.000608 rmse:661.808105 total_loss:0.060242 acc:0.267000\n",
      "[epoch 24][step 203800] logloss:0.064004 l2_regular:0.000608 rmse:517.544312 total_loss:0.064612 acc:0.155000\n",
      "[epoch 24][step 203900] logloss:0.056638 l2_regular:0.000608 rmse:399.525391 total_loss:0.057246 acc:0.264000\n",
      "[epoch 24][step 204000] logloss:0.071284 l2_regular:0.000608 rmse:592.980469 total_loss:0.071892 acc:0.207000\n",
      "[epoch 24][step 204100] logloss:0.063678 l2_regular:0.000608 rmse:675.756714 total_loss:0.064286 acc:0.117000\n",
      "[epoch 24][step 204200] logloss:0.063583 l2_regular:0.000608 rmse:527.817139 total_loss:0.064191 acc:0.207000\n",
      "[epoch 24][step 204300] logloss:0.057073 l2_regular:0.000608 rmse:572.757629 total_loss:0.057681 acc:0.230000\n",
      "[epoch 24][step 204400] logloss:0.052819 l2_regular:0.000608 rmse:366.520599 total_loss:0.053427 acc:0.214000\n",
      "[epoch 24][step 204500] logloss:0.047597 l2_regular:0.000608 rmse:398.660095 total_loss:0.048205 acc:0.302000\n",
      "[epoch 24][step 204600] logloss:0.065670 l2_regular:0.000608 rmse:526.627808 total_loss:0.066278 acc:0.225000\n",
      "[epoch 24][step 204700] logloss:0.050090 l2_regular:0.000608 rmse:427.321960 total_loss:0.050698 acc:0.251000\n",
      "[epoch 24][step 204800] logloss:0.073683 l2_regular:0.000608 rmse:414.937469 total_loss:0.074291 acc:0.165000\n",
      "[epoch 24][step 204900] logloss:0.053100 l2_regular:0.000608 rmse:451.113525 total_loss:0.053708 acc:0.293000\n",
      "[epoch 24][step 205000] logloss:0.066255 l2_regular:0.000608 rmse:980.599487 total_loss:0.066862 acc:0.234000\n",
      "[epoch 24][step 205100] logloss:0.055004 l2_regular:0.000608 rmse:634.426575 total_loss:0.055612 acc:0.204000\n",
      "[epoch 24][step 205200] logloss:0.072465 l2_regular:0.000608 rmse:506.506470 total_loss:0.073072 acc:0.254000\n",
      "[epoch 24][step 205300] logloss:0.052694 l2_regular:0.000608 rmse:409.925018 total_loss:0.053302 acc:0.278000\n",
      "[epoch 24][step 205400] logloss:0.053263 l2_regular:0.000608 rmse:701.451782 total_loss:0.053871 acc:0.290000\n",
      "[epoch 24][step 205500] logloss:0.061330 l2_regular:0.000608 rmse:520.628479 total_loss:0.061938 acc:0.195000\n",
      "[epoch 24][step 205600] logloss:0.057677 l2_regular:0.000608 rmse:640.640625 total_loss:0.058285 acc:0.226000\n",
      "[epoch 24][step 205700] logloss:0.053209 l2_regular:0.000608 rmse:498.868286 total_loss:0.053817 acc:0.323000\n",
      "[epoch 24][step 205800] logloss:0.047516 l2_regular:0.000608 rmse:409.797974 total_loss:0.048124 acc:0.220000\n",
      "[epoch 24][step 205900] logloss:0.077917 l2_regular:0.000608 rmse:546.296204 total_loss:0.078525 acc:0.213000\n",
      "[epoch 24][step 206000] logloss:0.054895 l2_regular:0.000608 rmse:641.739136 total_loss:0.055503 acc:0.182000\n",
      "[epoch 24][step 206100] logloss:0.054139 l2_regular:0.000608 rmse:434.731659 total_loss:0.054746 acc:0.292000\n",
      "[epoch 24][step 206200] logloss:0.066257 l2_regular:0.000608 rmse:461.773163 total_loss:0.066865 acc:0.163000\n",
      "[epoch 24][step 206300] logloss:0.065075 l2_regular:0.000608 rmse:414.519073 total_loss:0.065683 acc:0.202000\n",
      "[epoch 24][step 206400] logloss:0.061834 l2_regular:0.000608 rmse:603.379517 total_loss:0.062441 acc:0.318000\n",
      "[epoch 24][step 206500] logloss:0.052453 l2_regular:0.000608 rmse:578.828308 total_loss:0.053060 acc:0.290000\n",
      "[epoch 24][step 206600] logloss:0.054640 l2_regular:0.000608 rmse:770.951416 total_loss:0.055248 acc:0.352000\n",
      "[epoch 24][step 206700] logloss:0.060485 l2_regular:0.000608 rmse:555.658752 total_loss:0.061093 acc:0.211000\n",
      "[epoch 24][step 206800] logloss:0.043037 l2_regular:0.000608 rmse:443.242340 total_loss:0.043644 acc:0.381000\n",
      "[epoch 24][step 206900] logloss:0.066479 l2_regular:0.000608 rmse:616.932373 total_loss:0.067087 acc:0.203000\n",
      "[epoch 24][step 207000] logloss:0.058631 l2_regular:0.000608 rmse:472.411041 total_loss:0.059239 acc:0.251000\n",
      "[epoch 24][step 207100] logloss:0.068319 l2_regular:0.000608 rmse:480.720551 total_loss:0.068927 acc:0.241000\n",
      "[epoch 24][step 207200] logloss:0.054308 l2_regular:0.000608 rmse:709.475037 total_loss:0.054916 acc:0.330000\n",
      "[epoch 24][step 207300] logloss:0.061010 l2_regular:0.000608 rmse:338.268066 total_loss:0.061618 acc:0.269000\n",
      "[epoch 24][step 207400] logloss:0.057438 l2_regular:0.000608 rmse:527.449402 total_loss:0.058046 acc:0.329000\n",
      "[epoch 24][step 207500] logloss:0.055600 l2_regular:0.000608 rmse:352.554230 total_loss:0.056208 acc:0.247000\n",
      "[epoch 24][step 207600] logloss:0.052966 l2_regular:0.000608 rmse:463.759003 total_loss:0.053573 acc:0.256000\n",
      "[epoch 24][step 207700] logloss:0.059450 l2_regular:0.000608 rmse:469.680847 total_loss:0.060057 acc:0.193000\n",
      "[epoch 24][step 207800] logloss:0.064166 l2_regular:0.000608 rmse:430.150940 total_loss:0.064774 acc:0.294000\n",
      "[epoch 24][step 207900] logloss:0.059935 l2_regular:0.000608 rmse:437.200867 total_loss:0.060543 acc:0.320000\n",
      "[epoch 24][step 208000] logloss:0.064612 l2_regular:0.000608 rmse:541.290222 total_loss:0.065220 acc:0.239000\n",
      "[epoch 24][step 208100] logloss:0.059178 l2_regular:0.000608 rmse:424.109375 total_loss:0.059785 acc:0.241000\n",
      "[epoch 24][step 208200] logloss:0.059050 l2_regular:0.000608 rmse:480.379517 total_loss:0.059657 acc:0.160000\n",
      "[epoch 24][step 208300] logloss:0.048834 l2_regular:0.000608 rmse:512.902649 total_loss:0.049442 acc:0.262000\n",
      "[epoch 24][step 208400] logloss:0.046061 l2_regular:0.000608 rmse:282.688110 total_loss:0.046669 acc:0.352000\n",
      "[epoch 24][step 208500] logloss:0.038744 l2_regular:0.000608 rmse:502.944824 total_loss:0.039352 acc:0.330000\n",
      "[epoch 24][step 208600] logloss:0.052950 l2_regular:0.000608 rmse:402.926727 total_loss:0.053558 acc:0.150000\n",
      "[epoch 24][step 208700] logloss:0.052946 l2_regular:0.000608 rmse:481.775818 total_loss:0.053554 acc:0.254000\n",
      "--------------epoch 24 finished —> total batch:8351---------------\n",
      "finished!\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    summary_writer=tf.summary.FileWriter('../tensorboard_summary',sess.graph)\n",
    "#     model_ckpt = tf.train.latest_checkpoint('../save_models/')\n",
    "#     print(model_ckpt)\n",
    "#     saver.restore(sess,model_ckpt)\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        batches = pd.read_csv(file,chunksize=batch_size)\n",
    "        total_batch = 0\n",
    "        for batch in batches:\n",
    "            total_batch +=1\n",
    "#             print(batch.iloc[:,:].info())\n",
    "            input_features = batch.iloc[:,1:75]\n",
    "            labels = batch.iloc[:,75:].values\n",
    "#             print(labels.shape)\n",
    "            labels_ = labels.copy()\n",
    "            labels_[:,32] = 0.\n",
    "#             print(labels_.shape)\n",
    "            repay_amt_ = batch.iloc[:,0].values\n",
    "            due_amt_ = batch.iloc[:,1].values\n",
    "            \n",
    "            _,cost_,l2_regular_,rmse_,total_loss_,acc,global_step_,merge_summary=sess.run(\n",
    "                            [optimizer,cost,l2_regular,rmse,total_loss,accuracy,global_step,summary],\n",
    "                            feed_dict= { x:input_features, y:labels, y_:labels_,\n",
    "                                        repay_amt:repay_amt_, due_amt:due_amt_})\n",
    "            summary_writer.add_summary(merge_summary,global_step_)\n",
    "            if global_step_%100==0:\n",
    "                print('[epoch %s][step %s]' % (epoch,global_step_),\n",
    "                     'logloss:%.6f' % cost_,\n",
    "                     'l2_regular:%.6f' % l2_regular_,\n",
    "                     'rmse:%.6f' % rmse_,\n",
    "                     'total_loss:%.6f' % total_loss_,\n",
    "                     'acc:%.6f' % acc)\n",
    "            \n",
    "            if global_step_%1000==0:\n",
    "                saver.save(sess,\"../save_models/mlp.ckpt\",global_step=global_step_)\n",
    "        print('--------------epoch %s finished —> total batch:%s---------------' % (epoch,total_batch))\n",
    "    print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../save_models/mlp.ckpt-208000\n",
      "[[0.0036499  0.0022646  0.00171818 ... 0.24219659 0.243577   0.07169892]\n",
      " [0.00201436 0.00127222 0.00101843 ... 0.26661873 0.2682285  0.06204899]\n",
      " [0.00257524 0.00164869 0.00132895 ... 0.2536152  0.2531959  0.06141805]\n",
      " ...\n",
      " [0.00681111 0.0046021  0.00380963 ... 0.20500575 0.19352931 0.09350574]\n",
      " [0.00898046 0.00614844 0.00509679 ... 0.18420663 0.17242315 0.08453646]\n",
      " [0.00668033 0.00397577 0.00280746 ... 0.21763565 0.23722588 0.2131144 ]]\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "test_set = pd.read_csv('./test_set.csv')\n",
    "test_set = test_set.iloc[:,2:]\n",
    "model_path = \"../save_models/mlp.ckpt-208000\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    saver = tf.train.import_meta_graph(model_path + \".meta\")\n",
    "    saver.restore(sess, model_path)\n",
    "    test_data= test_set.values\n",
    "    inputs = sess.graph.get_tensor_by_name('x:0')\n",
    "    output = sess.graph.get_tensor_by_name('output:0')\n",
    "    output=tf.nn.softmax(output)\n",
    "    prob = sess.run([output], feed_dict={inputs: test_data})\n",
    "    prob=prob[0]\n",
    "    print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(786845, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>auditing_date</th>\n",
       "      <th>due_amt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>498765</td>\n",
       "      <td>5431438</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>138.5903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34524</td>\n",
       "      <td>5443211</td>\n",
       "      <td>2019-03-15</td>\n",
       "      <td>208.0805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34524</td>\n",
       "      <td>5443211</td>\n",
       "      <td>2019-03-15</td>\n",
       "      <td>208.0805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34524</td>\n",
       "      <td>5443211</td>\n",
       "      <td>2019-03-15</td>\n",
       "      <td>208.0805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34524</td>\n",
       "      <td>5443211</td>\n",
       "      <td>2019-03-15</td>\n",
       "      <td>208.0805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  listing_id auditing_date   due_amt\n",
       "0   498765     5431438    2019-03-12  138.5903\n",
       "1    34524     5443211    2019-03-15  208.0805\n",
       "2    34524     5443211    2019-03-15  208.0805\n",
       "3    34524     5443211    2019-03-15  208.0805\n",
       "4    34524     5443211    2019-03-15  208.0805"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_info = pd.read_csv('../data_preprocess/sub_info.csv',parse_dates=['auditing_date'])\n",
    "sub_test = sub_info[sub_info['repay_amt'].isnull()][['user_id','listing_id','auditing_date','due_amt']]\n",
    "sub_test = sub_test.reset_index(drop=True)\n",
    "print(sub_test.shape)\n",
    "sub_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_cols = ['prob_%s' % i for i in range(pred.shape[1])]\n",
    "pred_df = pd.concat([sub_test,pd.DataFrame(pred,columns=prob_cols)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(786845, 37)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(786445, 37)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pred_df.drop_duplicates()\n",
    "pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>auditing_date</th>\n",
       "      <th>due_amt</th>\n",
       "      <th>prob_0</th>\n",
       "      <th>prob_1</th>\n",
       "      <th>prob_2</th>\n",
       "      <th>prob_3</th>\n",
       "      <th>prob_4</th>\n",
       "      <th>prob_5</th>\n",
       "      <th>...</th>\n",
       "      <th>prob_23</th>\n",
       "      <th>prob_24</th>\n",
       "      <th>prob_25</th>\n",
       "      <th>prob_26</th>\n",
       "      <th>prob_27</th>\n",
       "      <th>prob_28</th>\n",
       "      <th>prob_29</th>\n",
       "      <th>prob_30</th>\n",
       "      <th>prob_31</th>\n",
       "      <th>prob_32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>498765</td>\n",
       "      <td>5431438</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>138.5903</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014920</td>\n",
       "      <td>0.019251</td>\n",
       "      <td>0.025081</td>\n",
       "      <td>0.032046</td>\n",
       "      <td>0.055460</td>\n",
       "      <td>0.085526</td>\n",
       "      <td>0.108246</td>\n",
       "      <td>0.242197</td>\n",
       "      <td>0.243577</td>\n",
       "      <td>0.071699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34524</td>\n",
       "      <td>5443211</td>\n",
       "      <td>2019-03-15</td>\n",
       "      <td>208.0805</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012520</td>\n",
       "      <td>0.017017</td>\n",
       "      <td>0.021797</td>\n",
       "      <td>0.029373</td>\n",
       "      <td>0.052363</td>\n",
       "      <td>0.078141</td>\n",
       "      <td>0.115049</td>\n",
       "      <td>0.266619</td>\n",
       "      <td>0.268229</td>\n",
       "      <td>0.062049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34524</td>\n",
       "      <td>5443211</td>\n",
       "      <td>2019-03-15</td>\n",
       "      <td>208.0805</td>\n",
       "      <td>0.002575</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014274</td>\n",
       "      <td>0.019018</td>\n",
       "      <td>0.023963</td>\n",
       "      <td>0.031782</td>\n",
       "      <td>0.054975</td>\n",
       "      <td>0.079856</td>\n",
       "      <td>0.115032</td>\n",
       "      <td>0.253615</td>\n",
       "      <td>0.253196</td>\n",
       "      <td>0.061418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34524</td>\n",
       "      <td>5443211</td>\n",
       "      <td>2019-03-15</td>\n",
       "      <td>208.0805</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013448</td>\n",
       "      <td>0.018116</td>\n",
       "      <td>0.022887</td>\n",
       "      <td>0.030677</td>\n",
       "      <td>0.053725</td>\n",
       "      <td>0.078102</td>\n",
       "      <td>0.116618</td>\n",
       "      <td>0.261568</td>\n",
       "      <td>0.258567</td>\n",
       "      <td>0.061199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34524</td>\n",
       "      <td>5443211</td>\n",
       "      <td>2019-03-15</td>\n",
       "      <td>208.0805</td>\n",
       "      <td>0.002095</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012776</td>\n",
       "      <td>0.017292</td>\n",
       "      <td>0.022128</td>\n",
       "      <td>0.029723</td>\n",
       "      <td>0.052781</td>\n",
       "      <td>0.078738</td>\n",
       "      <td>0.114888</td>\n",
       "      <td>0.264713</td>\n",
       "      <td>0.266287</td>\n",
       "      <td>0.061655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  listing_id auditing_date   due_amt    prob_0    prob_1    prob_2  \\\n",
       "0   498765     5431438    2019-03-12  138.5903  0.003650  0.002265  0.001718   \n",
       "1    34524     5443211    2019-03-15  208.0805  0.002014  0.001272  0.001018   \n",
       "2    34524     5443211    2019-03-15  208.0805  0.002575  0.001649  0.001329   \n",
       "3    34524     5443211    2019-03-15  208.0805  0.002296  0.001458  0.001173   \n",
       "4    34524     5443211    2019-03-15  208.0805  0.002095  0.001325  0.001060   \n",
       "\n",
       "     prob_3    prob_4    prob_5  ...   prob_23   prob_24   prob_25   prob_26  \\\n",
       "0  0.001636  0.001779  0.001822  ...  0.014920  0.019251  0.025081  0.032046   \n",
       "1  0.001008  0.001130  0.001148  ...  0.012520  0.017017  0.021797  0.029373   \n",
       "2  0.001317  0.001471  0.001483  ...  0.014274  0.019018  0.023963  0.031782   \n",
       "3  0.001161  0.001304  0.001313  ...  0.013448  0.018116  0.022887  0.030677   \n",
       "4  0.001049  0.001174  0.001192  ...  0.012776  0.017292  0.022128  0.029723   \n",
       "\n",
       "    prob_27   prob_28   prob_29   prob_30   prob_31   prob_32  \n",
       "0  0.055460  0.085526  0.108246  0.242197  0.243577  0.071699  \n",
       "1  0.052363  0.078141  0.115049  0.266619  0.268229  0.062049  \n",
       "2  0.054975  0.079856  0.115032  0.253615  0.253196  0.061418  \n",
       "3  0.053725  0.078102  0.116618  0.261568  0.258567  0.061199  \n",
       "4  0.052781  0.078738  0.114888  0.264713  0.266287  0.061655  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pred_df.groupby(['user_id','listing_id','auditing_date','due_amt'])[prob_cols].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_example = pd.read_csv('../train_data/submission/submission.csv', parse_dates=['repay_date'])\n",
    "sub_df = sub_example.merge(pred_df.drop('user_id',axis=1), on='listing_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df['days'] = (sub_df['repay_date'] - sub_df['auditing_date']).dt.days\n",
    "pred_prob = sub_df[prob_cols].values\n",
    "pred_days = sub_df['days'].values\n",
    "prob_someone_day = [pred_prob[i][pred_days[i]] for i in range(pred_prob.shape[0])]\n",
    "sub_df['repay_amt'] = sub_df['due_amt'] * prob_someone_day\n",
    "\n",
    "\n",
    "sub_df[['listing_id', 'repay_date', 'repay_amt']].to_csv('./predict_df_mlp.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

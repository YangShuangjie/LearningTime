{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# source code modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.compat.python import (lrange, iterkeys, iteritems, lzip,\n",
    "                                       reduce, itervalues, zip, string_types,\n",
    "                                       range)\n",
    "from statsmodels.compat.collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import textwrap\n",
    "# from .table import SimpleTable\n",
    "# from .tableformatting import fmt_latex, fmt_txt\n",
    "from statsmodels.iolib.table import SimpleTable\n",
    "from statsmodels.iolib.tableformatting import fmt_latex, fmt_txt\n",
    "\n",
    "class Summary(object):\n",
    "    def __init__(self):\n",
    "        self.tables = []\n",
    "        self.settings = []\n",
    "        self.extra_txt = []\n",
    "        self.title = None\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.as_text()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(type(self)) + '\\n\"\"\"\\n' + self.__str__() + '\\n\"\"\"'\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        '''Display as HTML in IPython notebook.'''\n",
    "        return self.as_html()\n",
    "\n",
    "    def add_df(self, df, index=True, header=True, float_format='%.4f',\n",
    "               align='r'):\n",
    "        '''Add the contents of a DataFrame to summary table\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : DataFrame\n",
    "        header: bool\n",
    "            Reproduce the DataFrame column labels in summary table\n",
    "        index: bool\n",
    "            Reproduce the DataFrame row labels in summary table\n",
    "        float_format: string\n",
    "            Formatting to float data columns\n",
    "        align : string\n",
    "            Data alignment (l/c/r)\n",
    "        '''\n",
    "\n",
    "        settings = {'index': index, 'header': header,\n",
    "                    'float_format': float_format, 'align': align}\n",
    "        self.tables.append(df)\n",
    "        self.settings.append(settings)\n",
    "\n",
    "    def add_array(self, array, align='r', float_format=\"%.4f\"):\n",
    "        '''Add the contents of a Numpy array to summary table\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        array : numpy array (2D)\n",
    "        float_format: string\n",
    "            Formatting to array if type is float\n",
    "        align : string\n",
    "            Data alignment (l/c/r)\n",
    "        '''\n",
    "\n",
    "        table = pd.DataFrame(array)\n",
    "        self.add_df(table, index=False, header=False,\n",
    "                    float_format=float_format, align=align)\n",
    "\n",
    "    def add_dict(self, d, ncols=2, align='l', float_format=\"%.4f\"):\n",
    "        '''Add the contents of a Dict to summary table\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : dict\n",
    "            Keys and values are automatically coerced to strings with str().\n",
    "            Users are encouraged to format them before using add_dict.\n",
    "        ncols: int\n",
    "            Number of columns of the output table\n",
    "        align : string\n",
    "            Data alignment (l/c/r)\n",
    "        '''\n",
    "\n",
    "        keys = [_formatter(x, float_format) for x in iterkeys(d)]\n",
    "        vals = [_formatter(x, float_format) for x in itervalues(d)]\n",
    "        data = np.array(lzip(keys, vals))\n",
    "\n",
    "        if data.shape[0] % ncols != 0:\n",
    "            pad = ncols - (data.shape[0] % ncols)\n",
    "            data = np.vstack([data, np.array(pad * [['', '']])])\n",
    "\n",
    "        data = np.split(data, ncols)\n",
    "        data = reduce(lambda x, y: np.hstack([x, y]), data)\n",
    "        self.add_array(data, align=align)\n",
    "\n",
    "    def add_text(self, string):\n",
    "        '''Append a note to the bottom of the summary table. In ASCII tables,\n",
    "        the note will be wrapped to table width. Notes are not indendented.\n",
    "        '''\n",
    "        self.extra_txt.append(string)\n",
    "\n",
    "    def add_title(self, title=None, results=None):\n",
    "        '''Insert a title on top of the summary table. If a string is provided\n",
    "        in the title argument, that string is printed. If no title string is\n",
    "        provided but a results instance is provided, statsmodels attempts\n",
    "        to construct a useful title automatically.\n",
    "        '''\n",
    "        if isinstance(title, string_types):\n",
    "            self.title = title\n",
    "        else:\n",
    "            try:\n",
    "                model = results.model.__class__.__name__\n",
    "                if model in _model_types:\n",
    "                    model = _model_types[model]\n",
    "                self.title = 'Results: ' + model\n",
    "            except:\n",
    "                self.title = ''\n",
    "\n",
    "    def add_base(self, results, alpha=0.05, float_format=\"%.4f\", title=None,\n",
    "                 xname=None, yname=None):\n",
    "        '''Try to construct a basic summary instance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        results : Model results instance\n",
    "        alpha : float\n",
    "            significance level for the confidence intervals (optional)\n",
    "        float_formatting: string\n",
    "            Float formatting for summary of parameters (optional)\n",
    "        title : string\n",
    "            Title of the summary table (optional)\n",
    "        xname : List of strings of length equal to the number of parameters\n",
    "            Names of the independent variables (optional)\n",
    "        yname : string\n",
    "            Name of the dependent variable (optional)\n",
    "        '''\n",
    "\n",
    "        param = summary_params(results, alpha=alpha, use_t=results.use_t)\n",
    "        info = summary_model(results)\n",
    "        if xname is not None:\n",
    "            param.index = xname\n",
    "        if yname is not None:\n",
    "            info['Dependent Variable:'] = yname\n",
    "        self.add_dict(info, align='l')\n",
    "        self.add_df(param, float_format=float_format)\n",
    "        self.add_title(title=title, results=results)\n",
    "\n",
    "    def as_text(self):\n",
    "        '''Generate ASCII Summary Table\n",
    "        '''\n",
    "\n",
    "        tables = self.tables\n",
    "        settings = self.settings\n",
    "        title = self.title\n",
    "        extra_txt = self.extra_txt\n",
    "\n",
    "        pad_col, pad_index, widest = _measure_tables(tables, settings)\n",
    "\n",
    "        rule_equal = widest * '='\n",
    "        #TODO: this isn't used anywhere?\n",
    "        rule_dash = widest * '-'\n",
    "\n",
    "        simple_tables = _simple_tables(tables, settings, pad_col, pad_index)\n",
    "        tab = [x.as_text() for x in simple_tables]\n",
    "\n",
    "        tab = '\\n'.join(tab)\n",
    "        tab = tab.split('\\n')\n",
    "        tab[0] = rule_equal\n",
    "        tab.append(rule_equal)\n",
    "        tab = '\\n'.join(tab)\n",
    "\n",
    "        if title is not None:\n",
    "            title = title\n",
    "            if len(title) < widest:\n",
    "                title = ' ' * int(widest/2 - len(title)/2) + title\n",
    "        else:\n",
    "            title = ''\n",
    "\n",
    "        txt = [textwrap.wrap(x, widest) for x in extra_txt]\n",
    "        txt = ['\\n'.join(x) for x in txt]\n",
    "        txt = '\\n'.join(txt)\n",
    "\n",
    "        out = '\\n'.join([title, tab, txt])\n",
    "\n",
    "        return out\n",
    "\n",
    "    def as_html(self):\n",
    "        '''Generate HTML Summary Table\n",
    "        '''\n",
    "\n",
    "        tables = self.tables\n",
    "        settings = self.settings\n",
    "        #TODO: this isn't used anywhere\n",
    "        title = self.title\n",
    "\n",
    "        simple_tables = _simple_tables(tables, settings)\n",
    "        tab = [x.as_html() for x in simple_tables]\n",
    "        tab = '\\n'.join(tab)\n",
    "\n",
    "        return tab\n",
    "\n",
    "    def as_latex(self):\n",
    "        '''Generate LaTeX Summary Table\n",
    "        '''\n",
    "        tables = self.tables\n",
    "        settings = self.settings\n",
    "        title = self.title\n",
    "        if title is not None:\n",
    "            title = '\\\\caption{' + title + '} \\\\\\\\'\n",
    "        else:\n",
    "            title = '\\\\caption{}'\n",
    "\n",
    "        simple_tables = _simple_tables(tables, settings)\n",
    "        tab = [x.as_latex_tabular() for x in simple_tables]\n",
    "        tab = '\\n\\\\hline\\n'.join(tab)\n",
    "\n",
    "        out = '\\\\begin{table}', title, tab, '\\\\end{table}'\n",
    "        out = '\\n'.join(out)\n",
    "        return out\n",
    "    # I added the output method based on pd.DataFrame().to_excel/csv(). \n",
    "    # I merged  the results when they are output, mainly in order to make \n",
    "    #  the output be distinguishable and more beautiful when printing. \n",
    "    #  Maybe there are other better ways.\n",
    "    def to_excel(self,path=None):\n",
    "        tables = self.tables\n",
    "        import  os\n",
    "        cwd = os.getcwd()\n",
    "        if path:\n",
    "            path = path \n",
    "        else:\n",
    "            path = cwd + '\\\\summary_results.xlsx'\n",
    "        summ_df = pd.concat(tables,axis=0)\n",
    "        return summ_df.to_excel(path)\n",
    "    def to_csv(self,path=None):\n",
    "        tables = self.tables\n",
    "        import  os\n",
    "        cwd = os.getcwd()\n",
    "        if  path:\n",
    "            path = path \n",
    "        else:\n",
    "            path = cwd + '\\\\summary_results.csv'\n",
    "        summ_df = pd.concat(tables,axis=0)\n",
    "        return summ_df.to_csv(path)\n",
    "\n",
    "def _measure_tables(tables, settings):\n",
    "    '''Compare width of ascii tables in a list and calculate padding values.\n",
    "    We add space to each col_sep to get us as close as possible to the\n",
    "    width of the largest table. Then, we add a few spaces to the first\n",
    "    column to pad the rest.\n",
    "    '''\n",
    "\n",
    "    simple_tables = _simple_tables(tables, settings)\n",
    "    \n",
    "    #Bug1: If tables or settings is an empty list, \n",
    "             # then _simple_tables() will return [].\n",
    "             # that means length is also empty , \n",
    "             # so max() will raise an error. \n",
    "    #Bug2: If table[i] just has one column, '/nsep' will raise ZeroDivisionError. \n",
    "             # So I added exception capture codes as follows.\n",
    "\n",
    "    if simple_tables == []:\n",
    "        len_max = 0\n",
    "        pad_sep = None\n",
    "        pad_index = None\n",
    "    else:\n",
    "        tab = [x.as_text() for x in simple_tables]\n",
    "        length = [len(x.splitlines()[0]) for x in tab]\n",
    "        len_max = max(length)\n",
    "        pad_sep = []\n",
    "        pad_index = []\n",
    "        for i in range(len(tab)):\n",
    "            nsep = tables[i].shape[1] - 1\n",
    "            # I added the 'except' codes as follows  because nsep may be zero\n",
    "            try:\n",
    "                pad = int((len_max - length[i]) / nsep)\n",
    "            except (ZeroDivisionError):\n",
    "                pad = int((len_max - length[i]))\n",
    "            pad_sep.append(pad)\n",
    "            len_new = length[i] + nsep * pad\n",
    "            pad_index.append(len_max - len_new)\n",
    "\n",
    "    return pad_sep, pad_index, len_max\n",
    "\n",
    "\n",
    "# Useful stuff\n",
    "_model_types = {'OLS' : 'Ordinary least squares',\n",
    "                'GLS' : 'Generalized least squares',\n",
    "                'GLSAR' : 'Generalized least squares with AR(p)',\n",
    "                'WLS' : 'Weigthed least squares',\n",
    "                'RLM' : 'Robust linear model',\n",
    "                'NBin': 'Negative binomial model',\n",
    "                'GLM' : 'Generalized linear model'\n",
    "                }\n",
    "\n",
    "\n",
    "def summary_model(results):\n",
    "    '''Create a dict with information about the model\n",
    "    '''\n",
    "    def time_now(*args, **kwds):\n",
    "        now = datetime.datetime.now()\n",
    "        return now.strftime('%Y-%m-%d %H:%M')\n",
    "    info = OrderedDict()\n",
    "\n",
    "    # I added some informations of  Panel regression from the package linearmodels. \n",
    "    # Panel regression has some different attribute names, but it doesn't matter here.\n",
    "    info['Model:'] = lambda x: x.model.__class__.__name__\n",
    "    info['Model Family:'] = lambda x: x.family.__class.__name__\n",
    "    info['Link Function:'] = lambda x: x.family.link.__class__.__name__\n",
    "    info['Dependent Variable:'] = lambda x: x.model.endog_names\n",
    "    # 1\n",
    "    info['Dependent Variable:'] = lambda x: x.model.dependent.vars[0]\n",
    "\n",
    "    info['Date:'] = time_now\n",
    "    info['No. Observations:'] = lambda x: \"%#6d\" % x.nobs\n",
    "    info['Df Model:'] = lambda x: \"%#6d\" % x.df_model\n",
    "    info['Df Residuals:'] = lambda x: \"%#6d\" % x.df_resid\n",
    "    info['Converged:'] = lambda x: x.mle_retvals['converged']\n",
    "    info['No. Iterations:'] = lambda x: x.mle_retvals['iterations']\n",
    "    info['Method:'] = lambda x: x.method\n",
    "    info['Norm:'] = lambda x: x.fit_options['norm']\n",
    "    info['Scale Est.:'] = lambda x: x.fit_options['scale_est']\n",
    "    info['Cov. Type:'] = lambda x: x.fit_options['cov']\n",
    "    # 2\n",
    "    #I add the x.cov_type because there is no attribute fit_options like OLS model\n",
    "    info['Covariance Type:'] = lambda x: x.cov_type\n",
    "    info['Covariance Type:'] = lambda x: x._cov_type\n",
    "\n",
    "    info['R-squared:'] = lambda x: \"%#8.3f\" % x.rsquared\n",
    "    info['Adj. R-squared:'] = lambda x: \"%#8.3f\" % x.rsquared_adj\n",
    "    info['Pseudo R-squared:'] = lambda x: \"%#8.3f\" % x.prsquared\n",
    "    info['AIC:'] = lambda x: \"%8.4f\" % x.aic\n",
    "    info['BIC:'] = lambda x: \"%8.4f\" % x.bic\n",
    "    info['Log-Likelihood:'] = lambda x: \"%#8.5g\" % x.llf\n",
    "    # 3\n",
    "    info['Log-Likelihood:'] = lambda x: \"%#8.5g\" % x.loglike\n",
    "\n",
    "    info['LL-Null:'] = lambda x: \"%#8.5g\" % x.llnull\n",
    "    info['LLR p-value:'] = lambda x: \"%#8.5g\" % x.llr_pvalue\n",
    "    info['Deviance:'] = lambda x: \"%#8.5g\" % x.deviance\n",
    "    info['Pearson chi2:'] = lambda x: \"%#6.3g\" % x.pearson_chi2\n",
    "    info['F-statistic:'] = lambda x: \"%#8.4g\" % x.fvalue\n",
    "    # 4\n",
    "    info['F-statistic:'] = lambda x: \"%#8.4g\" % x.f_statistic.stat\n",
    "\n",
    "    info['Prob (F-statistic):'] = lambda x: \"%#6.3g\" % x.f_pvalue\n",
    "    # 5\n",
    "    info['Prob (F-statistic):'] = lambda x: \"%#6.3g\" % x.f_statistic.pval\n",
    "\n",
    "    info['Scale:'] = lambda x: \"%#8.5g\" % x.scale\n",
    "    # 6 \n",
    "    info['Effects:'] = lambda x: ','.join(['%#8s' % i for i in x.included_effects])\n",
    "   \n",
    "    out = OrderedDict()\n",
    "    for key, func in iteritems(info):\n",
    "        try:\n",
    "            out[key] = func(results)\n",
    "        # NOTE: some models don't have loglike defined (RLM), so that's NIE\n",
    "        except (AttributeError, KeyError, NotImplementedError):\n",
    "            pass\n",
    "    return out\n",
    "\n",
    "\n",
    "def summary_params(results, yname=None, xname=None, alpha=.05, use_t=True,\n",
    "                   skip_header=False, float_format=\"%.4f\"):\n",
    "    '''create a summary table of parameters from results instance\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    res : results instance\n",
    "        some required information is directly taken from the result\n",
    "        instance\n",
    "    yname : string or None\n",
    "        optional name for the endogenous variable, default is \"y\"\n",
    "    xname : list of strings or None\n",
    "        optional names for the exogenous variables, default is \"var_xx\"\n",
    "    alpha : float\n",
    "        significance level for the confidence intervals\n",
    "    use_t : bool\n",
    "        indicator whether the p-values are based on the Student-t\n",
    "        distribution (if True) or on the normal distribution (if False)\n",
    "    skip_headers : bool\n",
    "        If false (default), then the header row is added. If true, then no\n",
    "        header row is added.\n",
    "    float_format : string\n",
    "        float formatting options (e.g. \".3g\")\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    params_table : SimpleTable instance\n",
    "    '''\n",
    "    from linearmodels.panel.results import PanelEffectsResults\n",
    "    from linearmodels.panel.results import RandomEffectsResults \n",
    "    from linearmodels.panel.results import PanelResults\n",
    "\n",
    "    res_tuple = (PanelEffectsResults,PanelResults,RandomEffectsResults)\n",
    "\n",
    "    if isinstance(results, tuple):\n",
    "        results, params, std_err, tvalues, pvalues, conf_int = results\n",
    "    # else:\n",
    "    #     params = results.params\n",
    "    #     bse = results.bse\n",
    "    #     tvalues = results.tvalues\n",
    "    #     pvalues = results.pvalues\n",
    "    #     conf_int = results.conf_int(alpha)\n",
    "   \n",
    "   # I added Panel results whose some attributes name are different.\n",
    "   # So I modified the code as follows.\n",
    "\n",
    "    elif isinstance(results,res_tuple):\n",
    "        bse = results.std_errors\n",
    "        tvalues = results.tstats\n",
    "        conf_int = results.conf_int(1-alpha)\n",
    "    else:\n",
    "        bse = results.bse\n",
    "        tvalues = results.tvalues\n",
    "        conf_int = results.conf_int(alpha) \n",
    "    params = results.params\n",
    "    pvalues = results.pvalues\n",
    "\n",
    "    data = np.array([params, bse, tvalues, pvalues]).T\n",
    "    data = np.hstack([data, conf_int])\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "    if use_t:\n",
    "        data.columns = ['Coef.', 'Std.Err.', 't', 'P>|t|',\n",
    "                        '[' + str(alpha/2), str(1-alpha/2) + ']']\n",
    "    else:\n",
    "        data.columns = ['Coef.', 'Std.Err.', 'z', 'P>|z|',\n",
    "                        '[' + str(alpha/2), str(1-alpha/2) + ']']\n",
    "\n",
    "    if not xname:\n",
    "        # data.index = results.model.exog_names\n",
    "        try:\n",
    "            data.index = results.model.exog_names\n",
    "        except (AttributeError):\n",
    "            data.index = results.model.exog.vars\n",
    "    else:\n",
    "        data.index = xname\n",
    "\n",
    "    return data\n",
    "\n",
    "# The following function just can stack standard errors,but  we\n",
    "    #  usually use t statistics in reality. I modified the function to \n",
    "    # support one of standard errors, t or pvalues by parameter 'show'.\n",
    "\n",
    "    # Bug: There exists different names for intercept item in different models,\n",
    "    # for example, an OLS model named it 'Intercept' while 'const' in logit models.\n",
    "    # So I also added a function to uniform the name to facilitate the data merge.\n",
    "\n",
    "## Vertical summary instance for multiple models\n",
    "# def _col_params(result, float_format='%.4f', stars=True):\n",
    "#     '''Stack coefficients and standard errors in single column\n",
    "#     '''\n",
    "\n",
    "#     # Extract parameters\n",
    "#     res = summary_params(result)\n",
    "#     # Format float\n",
    "#     for col in res.columns[:2]:\n",
    "#         res[col] = res[col].apply(lambda x: float_format % x)\n",
    "#     # Std.Errors in parentheses\n",
    "#     res.ix[:, 1] = '(' + res.ix[:, 1] + ')'\n",
    "#     # Significance stars\n",
    "#     if stars:\n",
    "#         idx = res.ix[:, 3] < .1\n",
    "#         res.ix[idx, 0] = res.ix[idx, 0] + '*'\n",
    "#         idx = res.ix[:, 3] < .05\n",
    "#         res.ix[idx, 0] = res.ix[idx, 0] + '*'\n",
    "#         idx = res.ix[:, 3] < .01\n",
    "#         res.ix[idx, 0] = res.ix[idx, 0] + '*'\n",
    "#     # Stack Coefs and Std.Errors\n",
    "#     res = res.ix[:, :2]\n",
    "#     res = res.stack()\n",
    "#     res = pd.DataFrame(res)\n",
    "#     res.columns = [str(result.model.endog_names)]\n",
    "def _col_params(result, float_format='%.4f', stars=True,show='t'):\n",
    "    '''Stack coefficients and standard errors in single column\n",
    "    '''\n",
    "      #I add the parameter 'show' equals 't' to display tvalues by default,\n",
    "      #'p' for pvalues and 'se' for std.err are alternative.\n",
    "    \n",
    "    # Extract parameters\n",
    "    res = summary_params(result)\n",
    "    # Format float\n",
    "    # Note that scientific number will be formatted to 'str' type though '%.4f'\n",
    "    for col in res.columns[:3]:\n",
    "        res[col] = res[col].apply(lambda x: float_format % x)\n",
    "    res.iloc[:,3] = np.around(res.iloc[:,3],4)\n",
    "    \n",
    "    # Significance stars\n",
    "    # .ix method will be depreciated,so .loc is used.\n",
    "    if stars:\n",
    "        idx = res.iloc[:, 3] < .1\n",
    "        res.loc[res.index[idx], res.columns[0]] += '*'\n",
    "        idx = res.iloc[:, 3] < .05\n",
    "        res.loc[res.index[idx], res.columns[0]] += '*'\n",
    "        idx = res.iloc[:, 3] < .01\n",
    "        res.loc[res.index[idx], res.columns[0]] += '*'\n",
    "    # Std.Errors or tvalues or  pvalues in parentheses\n",
    "    res.iloc[:,3] = res.iloc[:,3].apply(lambda x: float_format % x) # pvalues to str\n",
    "    res.iloc[:, 1] = '(' + res.iloc[:, 1] + ')'\n",
    "    res.iloc[:, 2] = '(' + res.iloc[:, 2] + ')'\n",
    "    res.iloc[:, 3] = '(' + res.iloc[:, 3] + ')'\n",
    "\n",
    "    # Stack Coefs and Std.Errors or pvalues\n",
    "    if show is 't':\n",
    "        res = res.iloc[:,[0,2]]\n",
    "    elif show is 'se':\n",
    "        res = res.iloc[:, :2]\n",
    "    elif show is 'p':\n",
    "        res = res.iloc[:,[0,3]]\n",
    "    res = res.stack()\n",
    "    res = pd.DataFrame(res)\n",
    "    try:\n",
    "        res.columns = [str(result.model.endog_names)]\n",
    "    except (AttributeError):\n",
    "        res.columns = result.model.dependent.vars\n",
    "    \n",
    "    # I added the index name transfromation function \n",
    "    # to deal with MultiIndex and single level index.\n",
    "    def _Intercept_2const(df):\n",
    "        from pandas.core.indexes.multi import MultiIndex\n",
    "        if df.index.contains('Intercept'):\n",
    "            if isinstance(df.index,MultiIndex):\n",
    "                new_index = []\n",
    "                for i in df.index.values:\n",
    "                    i = list(i)\n",
    "                    if 'Intercept' in i:\n",
    "                        i[i.index('Intercept')] = 'const'\n",
    "                    new_index.append(i)\n",
    "                multi_index = lzip(*new_index)\n",
    "                df.index = MultiIndex.from_arrays(multi_index)\n",
    "            else:\n",
    "                index_list = df.index.tolist()\n",
    "                idx = index_list.index('Intercept')\n",
    "                index_list[idx] = 'const'\n",
    "                df.index = index_list\n",
    "        return df\n",
    "    return _Intercept_2const(res)\n",
    "\n",
    "# def _col_info(result, info_dict=None):\n",
    "#     '''Stack model info in a column\n",
    "#     '''\n",
    "#     if info_dict is None:\n",
    "#         info_dict = {}\n",
    "#     out = []\n",
    "#     index = []\n",
    "#     for i in info_dict:\n",
    "#         if isinstance(info_dict[i], dict):\n",
    "#             # this is a specific model info_dict, but not for this result...\n",
    "#             continue\n",
    "#         try:\n",
    "#             out.append(info_dict[i](result))\n",
    "#         except:\n",
    "#             out.append('')\n",
    "#         index.append(i)\n",
    "#     out = pd.DataFrame({str(result.model.endog_names): out}, index=index)\n",
    "#     return out\n",
    "   \n",
    "   # I modified the above function,main work is that \n",
    "   # I rename the parameter 'info_dict' to 'more_info',which is a list not a dict.\n",
    "   # Besides, I build a default dict to contain some model information \n",
    "   # from summary_model(), that will be printed by default and \n",
    "   # users can append other statistics by more_info parameter.\n",
    "def _col_info(result, more_info=None):\n",
    "    '''Stack model info in a column\n",
    "    '''\n",
    "    model_info = summary_model(result)\n",
    "    default_info_ = OrderedDict()\n",
    "    default_info_['Model:'] = lambda x: x.get('Model:')\n",
    "    default_info_['No. Observations:'] = lambda x: x.get('No. Observations:')\n",
    "    default_info_['R-squared:'] = lambda x: x.get('R-squared:')\n",
    "    default_info_['Adj. R-squared:'] = lambda x: x.get('Adj. R-squared:')                    \n",
    "    default_info_['Pseudo R-squared:'] = lambda x: x.get('Pseudo R-squared:')\n",
    "    default_info_['F-statistic:'] = lambda x: x.get('F-statistic:')\n",
    "    default_info_['Covariance Type:'] = lambda x: x.get('Covariance Type:')\n",
    "    default_info_['Eeffects:'] = lambda x: x.get('Effects:')\n",
    "    default_info_['Covariance Type:'] = lambda x: x.get('Covariance Type:')\n",
    "\n",
    "    default_info = default_info_.copy()\n",
    "    for k,v in default_info_.items():\n",
    "        if v(model_info):\n",
    "            default_info[k] = v(model_info)\n",
    "        else:\n",
    "            default_info.pop(k) # pop the item whose value is none.\n",
    "            \n",
    "    if more_info is None:\n",
    "        more_info = default_info\n",
    "    else:\n",
    "        if not isinstance(more_info,list):\n",
    "            more_info = [more_info]\n",
    "        for i in more_info:\n",
    "            try:\n",
    "                default_info[i] = getattr(result,i)\n",
    "            except (AttributeError, KeyError, NotImplementedError) as e:\n",
    "                raise e\n",
    "        more_info = default_info\n",
    "    try:\n",
    "        out = pd.DataFrame(more_info, index=[result.model.endog_names]).T\n",
    "    except (AttributeError):\n",
    "        out = pd.DataFrame(more_info, index=result.model.dependent.vars).T\n",
    "    return out\n",
    "\n",
    "# def _make_unique(list_of_names):\n",
    "#     if len(set(list_of_names)) == len(list_of_names):\n",
    "#         return list_of_names\n",
    "#     # pandas does not like it if multiple columns have the same names\n",
    "#     from collections import defaultdict\n",
    "#     name_counter = defaultdict(str)\n",
    "#     header = []\n",
    "#     for _name in list_of_names:\n",
    "#         name_counter[_name] += \"I\"\n",
    "#         header.append(_name+\" \" + name_counter[_name])\n",
    "#     return header\n",
    "\n",
    "   # Above function has a flaw that non-duplicated names will be add a suffix.\n",
    "   # And the time when endog_names duplicate four or more times ,the y \n",
    "   # names will be like 'y IIII' or 'y IIIIII...'.So I used the Arabic numerals.\n",
    "def _make_unique(list_of_names):\n",
    "    if len(set(list_of_names)) == len(list_of_names):\n",
    "        return list_of_names\n",
    "    # pandas does not like it if multiple columns have the same names\n",
    "    from collections import defaultdict\n",
    "    dic_of_names = defaultdict(list)\n",
    "    for i,v in enumerate(list_of_names):\n",
    "        dic_of_names[v].append(i)\n",
    "    for v in  dic_of_names.values():\n",
    "        if len(v)>1:\n",
    "            c = 0\n",
    "            for i in v:\n",
    "                c += 1\n",
    "                list_of_names[i] += '_%i' % c\n",
    "    return list_of_names\n",
    "\n",
    "   # The following function is the most critical to work.\n",
    "   # In this function  I added the parameters 'show' and 'title',\n",
    "   # and changed the default value of 'stars' into 'True',\n",
    "   # Then  I changed the dict parameter 'info_dict' as a list one named 'more_info'.\n",
    "   # Finally I put 'const'  at the first location by default in regressor_order.\n",
    "\n",
    "   # Bug: np.unique() will disrupt the original order of list,\n",
    "   # this can result in index confusion.\n",
    "\n",
    "# def summary_col(results, float_format='%.4f', model_names=[], stars=False,\n",
    "#                 info_dict=None, regressor_order=[]): \n",
    "def summary_col(results, float_format='%.4f', model_names=[], stars=True,\n",
    "                more_info=None, regressor_order=[],show='t',title=None): \n",
    "    # I added the parameter 'show' and changed the default of 'stars' into 'True',\n",
    "    # then renamed the dict parameter 'info_dict' as a list one 'more_info'\n",
    "    # finally assigned the regressor_order a initial value ['const']\n",
    "    \"\"\"\n",
    "    Summarize multiple results instances side-by-side (coefs and SEs)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    results : statsmodels results instance or list of result instances\n",
    "    float_format : string\n",
    "        float format for coefficients and standard errors\n",
    "        Default : '%.4f'\n",
    "    model_names : list of strings of length len(results) if the names are not\n",
    "        unique, a roman number will be appended to all model names\n",
    "    stars : bool\n",
    "        print significance stars\n",
    "    info_dict : dict\n",
    "        dict of lambda functions to be applied to results instances to retrieve\n",
    "        model info. To use specific information for different models, add a\n",
    "        (nested) info_dict with model name as the key.\n",
    "        Example: `info_dict = {\"N\":..., \"R2\": ..., \"OLS\":{\"R2\":...}}` would\n",
    "        only show `R2` for OLS regression models, but additionally `N` for\n",
    "        all other results.\n",
    "        Default : None (use the info_dict specified in\n",
    "        result.default_model_infos, if this property exists)\n",
    "    regressor_order : list of strings\n",
    "        list of names of the regressors in the desired order. All regressors\n",
    "        not specified will be appended to the end of the list.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not isinstance(results, list):\n",
    "        results = [results]\n",
    "\n",
    "    cols = [_col_params(x, stars=stars, float_format=float_format,show=show) for x in\n",
    "            results]\n",
    "\n",
    "    # Unique column names (pandas has problems merging otherwise)\n",
    "    if model_names:\n",
    "        colnames = _make_unique(model_names)\n",
    "    else:\n",
    "        colnames = _make_unique([x.columns[0] for x in cols])\n",
    "    for i in range(len(cols)):\n",
    "        cols[i].columns = [colnames[i]]\n",
    "\n",
    "    merg = lambda x, y: x.merge(y, how='outer', right_index=True,\n",
    "                                left_index=True)\n",
    "    summ = reduce(merg, cols)\n",
    "\n",
    "    # if regressor_order:\n",
    "    if not regressor_order:\n",
    "        regressor_order = ['const']\n",
    "    \n",
    "    varnames = summ.index.get_level_values(0).tolist()\n",
    "    ordered = [x for x in regressor_order if x in varnames]\n",
    "    unordered = [x for x in varnames if x not in regressor_order + ['']]\n",
    "    \n",
    "    # Note: np.unique can disrupt the original order  of list 'unordered'.\n",
    "    # Then pd.Series().unique()  works well.\n",
    "    \n",
    "    # order = ordered + list(np.unique(unordered))\n",
    "    order = ordered + list(pd.Series(unordered).unique())\n",
    "\n",
    "    f = lambda idx: sum([[x + 'coef', x + 'stde'] for x in idx], [])\n",
    "    # summ.index = f(np.unique(varnames))\n",
    "    summ.index = f(pd.Series(varnames).unique())\n",
    "    summ = summ.reindex(f(order))\n",
    "    summ.index = [x[:-4] for x in summ.index]\n",
    "\n",
    "    idx = pd.Series(lrange(summ.shape[0])) % 2 == 1\n",
    "    summ.index = np.where(idx, '', summ.index.get_level_values(0))\n",
    "    summ = summ.fillna('')\n",
    "    \n",
    "    # add infos about the models.\n",
    "#     if info_dict:\n",
    "#         cols = [_col_info(x, info_dict.get(x.model.__class__.__name__,\n",
    "#                                            info_dict)) for x in results]\n",
    "#     else:\n",
    "#         cols = [_col_info(x, getattr(x, \"default_model_infos\", None)) for x in\n",
    "#                 results]\n",
    "    cols = [_col_info(x,more_info=more_info) for x in results]\n",
    "    \n",
    "    # use unique column names, otherwise the merge will not succeed\n",
    "    for df , name in zip(cols, _make_unique([df.columns[0] for df in cols])):\n",
    "        df.columns = [name]\n",
    "    merg = lambda x, y: x.merge(y, how='outer', right_index=True,\n",
    "                                left_index=True)\n",
    "    info = reduce(merg, cols)\n",
    "    info.columns = summ.columns\n",
    "    info = info.fillna('')\n",
    "#     dat = pd.DataFrame(np.vstack([summ, info]))  # pd.concat better, but error\n",
    "#     dat.columns = summ.columns\n",
    "#     dat.index = pd.Index(summ.index.tolist() + info.index.tolist())\n",
    "#     summ = dat\n",
    "\n",
    "#     summ = summ.fillna('')\n",
    "\n",
    "#     smry = Summary()\n",
    "#     smry.add_df(summ, header=True, align='l')\n",
    "#     smry.add_text('Standard errors in parentheses.')\n",
    "#     if stars:\n",
    "#         smry.add_text('* p<.1, ** p<.05, ***p<.01')*p<.01')\n",
    "#     return smry\n",
    "\n",
    "    if show is 't':\n",
    "        note = ['\\t t statistics in parentheses.']\n",
    "    if show is 'se':\n",
    "        note = ['\\t Std. error in parentheses.']\n",
    "    if show is 'p':\n",
    "        note = ['\\t pvalues in parentheses.']\n",
    "    if stars:\n",
    "        note +=  ['\\t * p<.1, ** p<.05, ***p<.01']\n",
    "    #Here  I tried two ways to put extra text in index-location \n",
    "    # or columns-location,finally found the former is better.\n",
    "#     note_df = pd.DataFrame(note,index=['note']+['']*(len(note)-1),columns=[summ.columns[0]])\n",
    "    note_df = pd.DataFrame([ ],index=['note:']+note,columns=summ.columns).fillna('')\n",
    "#     summ_all = pd.concat([summ,info,note_df],axis=0)\n",
    "    \n",
    "    # I construct a title DataFrame and adjust the location of title corresponding to the length of columns. \n",
    "    if title is not None:\n",
    "        title = str(title)\n",
    "    else:\n",
    "        title = '\\t Results Summary'\n",
    "        \n",
    "    # Here I tried to construct a title DataFrame and \n",
    "    # adjust the location of title corresponding to the length of columns. \n",
    "    # But I failed because of not good printing effect.\n",
    "\n",
    "    # col_len = len(summ.columns)\n",
    "    # fake_data = ['']*col_len\n",
    "    # if col_len % 2 == 1:\n",
    "    #     from math  import ceil\n",
    "    #     i = ceil(col_len/2)\n",
    "    # else:\n",
    "    #     i = int(col_len/2)\n",
    "    # fake_data[i-1] = title\n",
    "    # title_df = pd.DataFrame([fake_data],index=[''],columns=summ.columns).fillna('')\n",
    "    title_df = pd.DataFrame([],index=[title],columns=summ.columns).fillna('')\n",
    "    \n",
    "    smry = Summary()\n",
    "    smry.add_df(title_df,header=False,align='l')\n",
    "    smry.add_df(summ, header=True, align='l')\n",
    "    smry.add_df(info, header=False, align='l')\n",
    "    smry.add_df(note_df, header=False, align='l')\n",
    "    return smry\n",
    "\n",
    "\n",
    "\n",
    "def _formatter(element, float_format='%.4f'):\n",
    "    try:\n",
    "        out = float_format % element\n",
    "    except:\n",
    "        out = str(element)\n",
    "    return out.strip()\n",
    "\n",
    "\n",
    "def _df_to_simpletable(df, align='r', float_format=\"%.4f\", header=True,\n",
    "                       index=True, table_dec_above='-', table_dec_below=None,\n",
    "                       header_dec_below='-', pad_col=0, pad_index=0):\n",
    "    dat = df.copy()\n",
    "    dat = dat.applymap(lambda x: _formatter(x, float_format))\n",
    "    if header:\n",
    "        headers = [str(x) for x in dat.columns.tolist()]\n",
    "    else:\n",
    "        headers = None\n",
    "    if index:\n",
    "        stubs = [str(x) + int(pad_index) * ' ' for x in dat.index.tolist()]\n",
    "    else:\n",
    "        dat.ix[:, 0] = [str(x) + int(pad_index) * ' ' for x in dat.ix[:, 0]]\n",
    "        stubs = None\n",
    "    st = SimpleTable(np.array(dat), headers=headers, stubs=stubs,\n",
    "                     ltx_fmt=fmt_latex, txt_fmt=fmt_txt)\n",
    "    st.output_formats['latex']['data_aligns'] = align\n",
    "    st.output_formats['txt']['data_aligns'] = align\n",
    "    st.output_formats['txt']['table_dec_above'] = table_dec_above\n",
    "    st.output_formats['txt']['table_dec_below'] = table_dec_below\n",
    "    st.output_formats['txt']['header_dec_below'] = header_dec_below\n",
    "    st.output_formats['txt']['colsep'] = ' ' * int(pad_col + 1)\n",
    "    return st\n",
    "\n",
    "\n",
    "def _simple_tables(tables, settings, pad_col=None, pad_index=None):\n",
    "    simple_tables = []\n",
    "    float_format = '%.4f'\n",
    "    if pad_col is None:\n",
    "        pad_col = [0] * len(tables)\n",
    "    if pad_index is None:\n",
    "        pad_index = [0] * len(tables)\n",
    "    for i, v in enumerate(tables):\n",
    "        index = settings[i]['index']\n",
    "        header = settings[i]['header']\n",
    "        align = settings[i]['align']\n",
    "        simple_tables.append(_df_to_simpletable(v, align=align,\n",
    "                                                float_format=float_format,\n",
    "                                                header=header, index=index,\n",
    "                                                pad_col=pad_col[i],\n",
    "                                                pad_index=pad_index[i]))\n",
    "    return simple_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.402801\n",
      "         Iterations 7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "dat = sm.datasets.get_rdataset(\"Guerry\", \"HistData\").data\n",
    "res_ols = smf.ols('Lottery ~ Literacy + np.log(Pop1831)', data=dat).fit()\n",
    "\n",
    "spector_data = sm.datasets.spector.load()\n",
    "spector_data.exog = sm.add_constant(spector_data.exog)\n",
    "logit_mod = sm.Logit(spector_data.endog, spector_data.exog)\n",
    "res_logit = logit_mod.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "                 Coef.   Std.Err.    t    P>|t|   [0.025   0.975] \n",
      "------------------------------------------------------------------\n",
      "Intercept       246.4341  35.2325  6.9945 0.0000 176.3581 316.5102\n",
      "Literacy         -0.4889   0.1276 -3.8320 0.0002  -0.7427  -0.2352\n",
      "np.log(Pop1831) -31.3114   5.9768 -5.2388 0.0000 -43.1990 -19.4238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'------------------------------------------------------------------\\n                 Coef.   Std.Err.    t    P>|t|   [0.025   0.975] \\n------------------------------------------------------------------\\nIntercept       246.4341  35.2325  6.9945 0.0000 176.3581 316.5102\\nLiteracy         -0.4889   0.1276 -3.8320 0.0002  -0.7427  -0.2352\\nnp.log(Pop1831) -31.3114   5.9768 -5.2388 0.0000 -43.1990 -19.4238'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_df = res_ols.summary2().tables[1]\n",
    "df_2st = _df_to_simpletable(params_df)\n",
    "print(df_2st)\n",
    "df_2st.as_text()#.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Results: Ordinary least squares\n",
      "==================================================================\n",
      "Model:               OLS              Adj. R-squared:     0.333   \n",
      "Dependent Variable:  Lottery          AIC:                765.6463\n",
      "Date:                2018-07-08 04:05 BIC:                773.0094\n",
      "No. Observations:    86               Log-Likelihood:     -379.82 \n",
      "Df Model:            2                F-statistic:        22.20   \n",
      "Df Residuals:        83               Prob (F-statistic): 1.90e-08\n",
      "R-squared:           0.348            Scale:              416.02  \n",
      "------------------------------------------------------------------\n",
      "                 Coef.   Std.Err.    t    P>|t|   [0.025   0.975] \n",
      "------------------------------------------------------------------\n",
      "Intercept       246.4341  35.2325  6.9945 0.0000 176.3581 316.5102\n",
      "Literacy         -0.4889   0.1276 -3.8320 0.0002  -0.7427  -0.2352\n",
      "np.log(Pop1831) -31.3114   5.9768 -5.2388 0.0000 -43.1990 -19.4238\n",
      "------------------------------------------------------------------\n",
      "Omnibus:              3.713         Durbin-Watson:           2.019\n",
      "Prob(Omnibus):        0.156         Jarque-Bera (JB):        3.394\n",
      "Skew:                 -0.487        Prob(JB):                0.183\n",
      "Kurtosis:             3.003         Condition No.:           702  \n",
      "==================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Model:', 'OLS'),\n",
       "             ('Dependent Variable:', 'Lottery'),\n",
       "             ('Date:', '2018-07-08 04:05'),\n",
       "             ('No. Observations:', '    86'),\n",
       "             ('Df Model:', '     2'),\n",
       "             ('Df Residuals:', '    83'),\n",
       "             ('Covariance Type:', 'nonrobust'),\n",
       "             ('R-squared:', '   0.348'),\n",
       "             ('Adj. R-squared:', '   0.333'),\n",
       "             ('AIC:', '765.6463'),\n",
       "             ('BIC:', '773.0094'),\n",
       "             ('Log-Likelihood:', ' -379.82'),\n",
       "             ('F-statistic:', '   22.20'),\n",
       "             ('Prob (F-statistic):', '1.90e-08'),\n",
       "             ('Scale:', '  416.02')])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(res_ols.summary2())\n",
    "res_ols.summary().as_text\n",
    "summary_model(res_ols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:244: DomainWarning: The inverse_power link function does not respect the domain of the Gamma family.\n",
      "  DomainWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.402801\n",
      "         Iterations 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\vector_ar\\var_model.py:461: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  params = np.linalg.lstsq(z, y_sample)[0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "dat = sm.datasets.get_rdataset(\"Guerry\", \"HistData\").data\n",
    "res_ols = smf.ols('Lottery ~ Literacy + np.log(Pop1831)', data=dat).fit()\n",
    "\n",
    "import statsmodels.api as sm\n",
    "data = sm.datasets.scotland.load()\n",
    "data.exog = sm.add_constant(data.exog)\n",
    "gamma_model = sm.GLM(data.endog, data.exog, family=sm.families.Gamma())\n",
    "res_glm = gamma_model.fit()\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "data = sm.datasets.get_rdataset('epil', package='MASS').data\n",
    "fam = sm.families.Poisson()\n",
    "ind = sm.cov_struct.Exchangeable()\n",
    "mod = smf.gee(\"y ~ age + trt + base\", \"subject\", data,\n",
    "              cov_struct=ind, family=fam)\n",
    "res_gee = mod.fit()\n",
    "\n",
    "spector_data = sm.datasets.spector.load()\n",
    "spector_data.exog = sm.add_constant(spector_data.exog)\n",
    "logit_mod = sm.Logit(spector_data.endog, spector_data.exog)\n",
    "res_logit = logit_mod.fit()\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.api import VAR, DynamicVAR\n",
    "mdata = sm.datasets.macrodata.load_pandas().data\n",
    "dates = mdata[['year', 'quarter']].astype(int).astype(str)\n",
    "quarterly = dates[\"year\"] + \"Q\" + dates[\"quarter\"]\n",
    "from statsmodels.tsa.base.datetools import dates_from_str\n",
    "quarterly = dates_from_str(quarterly)\n",
    "mdata = mdata[['realgdp','realcons','realinv']]\n",
    "mdata.index = pandas.DatetimeIndex(quarterly)\n",
    "data = np.log(mdata).diff().dropna()\n",
    "model = VAR(data)\n",
    "res_var = model.fit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Summary in module statsmodels.iolib.summary2 object:\n",
      "\n",
      "class Summary(builtins.object)\n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  add_array(self, array, align='r', float_format='%.4f')\n",
      " |      Add the contents of a Numpy array to summary table\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      array : numpy array (2D)\n",
      " |      float_format: string\n",
      " |          Formatting to array if type is float\n",
      " |      align : string\n",
      " |          Data alignment (l/c/r)\n",
      " |  \n",
      " |  add_base(self, results, alpha=0.05, float_format='%.4f', title=None, xname=None, yname=None)\n",
      " |      Try to construct a basic summary instance.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      results : Model results instance\n",
      " |      alpha : float\n",
      " |          significance level for the confidence intervals (optional)\n",
      " |      float_formatting: string\n",
      " |          Float formatting for summary of parameters (optional)\n",
      " |      title : string\n",
      " |          Title of the summary table (optional)\n",
      " |      xname : List of strings of length equal to the number of parameters\n",
      " |          Names of the independent variables (optional)\n",
      " |      yname : string\n",
      " |          Name of the dependent variable (optional)\n",
      " |  \n",
      " |  add_df(self, df, index=True, header=True, float_format='%.4f', align='r')\n",
      " |      Add the contents of a DataFrame to summary table\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      df : DataFrame\n",
      " |      header: bool\n",
      " |          Reproduce the DataFrame column labels in summary table\n",
      " |      index: bool\n",
      " |          Reproduce the DataFrame row labels in summary table\n",
      " |      float_format: string\n",
      " |          Formatting to float data columns\n",
      " |      align : string\n",
      " |          Data alignment (l/c/r)\n",
      " |  \n",
      " |  add_dict(self, d, ncols=2, align='l', float_format='%.4f')\n",
      " |      Add the contents of a Dict to summary table\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      d : dict\n",
      " |          Keys and values are automatically coerced to strings with str().\n",
      " |          Users are encouraged to format them before using add_dict.\n",
      " |      ncols: int\n",
      " |          Number of columns of the output table\n",
      " |      align : string\n",
      " |          Data alignment (l/c/r)\n",
      " |  \n",
      " |  add_text(self, string)\n",
      " |      Append a note to the bottom of the summary table. In ASCII tables,\n",
      " |      the note will be wrapped to table width. Notes are not indendented.\n",
      " |  \n",
      " |  add_title(self, title=None, results=None)\n",
      " |      Insert a title on top of the summary table. If a string is provided\n",
      " |      in the title argument, that string is printed. If no title string is\n",
      " |      provided but a results instance is provided, statsmodels attempts\n",
      " |      to construct a useful title automatically.\n",
      " |  \n",
      " |  as_html(self)\n",
      " |      Generate HTML Summary Table\n",
      " |  \n",
      " |  as_latex(self)\n",
      " |      Generate LaTeX Summary Table\n",
      " |  \n",
      " |  as_text(self)\n",
      " |      Generate ASCII Summary Table\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from statsmodels.iolib.summary2 import summary_col\n",
    "res_list = [res_ols,res_glm,res_gee,res_logit]\n",
    "import pandas as pd\n",
    "# print(summary_col(res_list,model_names=['y']*4,show='p'))\n",
    "summary_col(res_list,model_names=['y']*4).to_excel('C:\\\\Users\\\\win10\\\\Desktop\\\\1.xls')\n",
    "help(res_ols.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([_col_params(res_ols),_col_params(res_logit)],axis=1)\n",
    "df.index = df.index.droplevel(1)\n",
    "\n",
    "max_index = max([len(i) for i in df.index])\n",
    "len_y = []\n",
    "for j in df.columns:\n",
    "    len_y_ = [len(str(i)) for i in df[j]] \n",
    "    len_y.append(len_y_)\n",
    "data = ['='* max(i) for i in len_y]\n",
    "row = pd.DataFrame(data).T\n",
    "row.index = ['='*max_index]\n",
    "row.columns= df.columns\n",
    "row2 = pd.DataFrame([32,43],columns=['y'])\n",
    "res_df = pd.concat([df,row,row2],axis=0)\n",
    "# .to_csv('C:\\\\Users\\\\win10\\\\Desktop\\\\ex.csv')\n",
    "extra = pd.DataFrame([],index=['Standard errors in parentheses.','* p<.1, ** p<.05, ***p<.01'],\n",
    "                    columns=[res_df.columns[0]])\n",
    "res_df = pd.concat([res_df,extra],axis=0)\n",
    "res_df.to_csv('C:\\\\Users\\\\win10\\\\Desktop\\\\ex1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
